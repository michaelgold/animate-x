<!DOCTYPE html>
<!-- saved from url=(0045)https://arxiv.org/html/2410.10306v1#bib.bib69 -->
<html lang="en" data-theme="light"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<title>Animate-X: Universal Character Image Animation with Enhanced Motion Representation</title>
<!--Generated on Mon Oct 14 09:27:14 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport">
<link href="./animate-x_files/bootstrap.min.css" rel="stylesheet" type="text/css">
<link href="./animate-x_files/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css">
<link href="./animate-x_files/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css">
<link href="./animate-x_files/latexml_styles.css" rel="stylesheet" type="text/css">
<script src="./animate-x_files/bootstrap.bundle.min.js"></script><script src="chrome-extension://idnnbdplmphpflfnlkomgpfbpcgelopg/inpage.js" id="xverse-wallet-provider" data-is-priority="true"></script>
<script src="./animate-x_files/html2canvas.min.js"></script>
<script src="./animate-x_files/addons_new.js"></script>
<script src="./animate-x_files/feedbackOverlay.js"></script>
<!--<base href="/html/2410.10306v1/">--><base href="."><link rel="stylesheet" href="./animate-x_files/rwr5zpx.css"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-16x16.png" sizes="16x16"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png" sizes="32x32"></head>
<body><header class="mob_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
        <img alt="logo" class="logomark" role="presentation" width="100" src="./animate-x_files/arxiv-logomark-small-white.svg">
        <span class="sr-only">Back to arXiv</span>
      </a>
    </div>

    <!--TOC, dark mode, links-->
    <div class="html-header-nav">
      <!--back to abstract-->
      
        <a class="nav-link ar5iv-footer-button hover-effect" aria-label="Back to abstract page" href="https://arxiv.org/abs/2410.10306v1">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 512 512" fill="#ffffff" aria-hidden="true">
            <path d="M502.6 278.6c12.5-12.5 12.5-32.8 0-45.3l-128-128c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L402.7 224 192 224c-17.7 0-32 14.3-32 32s14.3 32 32 32l210.7 0-73.4 73.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0l128-128zM160 96c17.7 0 32-14.3 32-32s-14.3-32-32-32L96 32C43 32 0 75 0 128L0 384c0 53 43 96 96 96l64 0c17.7 0 32-14.3 32-32s-14.3-32-32-32l-64 0c-17.7 0-32-14.3-32-32l0-256c0-17.7 14.3-32 32-32l64 0z"></path>
        </svg>
        </a>
      <!--dark mode-->
      <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode" aria-label="System preference">
        <label id="automatic-tog" class="toggle-icon" title="Switch to light mode" for="__palette_3">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9h-1.9M20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69m-9.15 3.96h2.3L12 9l-1.15 3.65Z"></path></svg>
        </label>
        <label id="light-tog" class="toggle-icon" title="Switch to dark mode" for="__palette_1" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
        <label id="dark-tog" class="toggle-icon" title="Switch to system preference" for="__palette_2" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
      </a>
      <!--nav-->
      <button class="navbar-toggler ar5iv-footer-button" type="button" data-bs-theme="dark" data-bs-toggle="collapse" aria-expanded="false" data-bs-target=".ltx_page_main &gt;.ltx_TOC.mobile" aria-controls="navbarSupportedContent" aria-label="Toggle navigation" style="border:none; margin-right: 0em;">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 448 512" aria-hidden="true" role="img" fill="#ffffff"><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"></path></svg>
      </button>
    </div>
    </header><header class="desktop_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
          <img alt="logo" class="logo" role="presentation" width="100" src="./animate-x_files/arxiv-logo-one-color-white.svg">
          <span class="sr-only">Back to arXiv</span>
      </a>
    </div>
    <div class="html-header-message" role="banner">
        <p>This is <strong>experimental HTML</strong> to improve accessibility. We invite you to report rendering errors. <span class="sr-only">Use Alt+Y to toggle on accessible reporting links and Alt+Shift+Y to toggle off.</span> Learn more <a href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">about this project</a> and <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">help improve conversions</a>.
        </p>
    </div>
    <nav class="html-header-nav">
      <a class="ar5iv-footer-button hover-effect" href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">Why HTML?</a>
      <a class="ar5iv-footer-button hover-effect" target="_blank" href="https://arxiv.org/html/2410.10306v1/#myForm" onclick="event.preventDefault(); var modal = document.getElementById(&#39;myForm&#39;); modal.style.display = &#39;block&#39;; bugReportState.setInitiateWay(&#39;Header&#39;);">Report Issue</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/abs/2410.10306v1">Back to Abstract</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/pdf/2410.10306v1" target="_blank">Download PDF</a>
      <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode">
        <label id="automatic-tog" class="toggle-icon" title="Switch to light mode" for="__palette_3">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9h-1.9M20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69m-9.15 3.96h2.3L12 9l-1.15 3.65Z"></path></svg>
        </label>
        <label id="light-tog" class="toggle-icon" title="Switch to dark mode" for="__palette_1" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
        <label id="dark-tog" class="toggle-icon" title="Switch to system preference" for="__palette_2" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
      </a>
    </nav></header>

<div class="ltx_page_main" id="main">
<nav class="ltx_TOC active" aria-labelledby="toc_header"><h2 id="toc_header" class="sr-only">Table of Contents</h2>

      <div id="listIcon" type="button" class="hide">
          <svg width="17px" height="17px" viewBox="0 0 512 512" style="pointer-events: none;">
          <path d="M40 48C26.7 48 16 58.7 16 72v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V72c0-13.3-10.7-24-24-24H40zM192 64c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zM16 232v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V232c0-13.3-10.7-24-24-24H40c-13.3 0-24 10.7-24 24zM40 368c-13.3 0-24 10.7-24 24v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V392c0-13.3-10.7-24-24-24H40z"></path>
          </svg>
      </div>
      <div id="arrowIcon" type="button">
          <svg width="17px" height="17px" viewBox="0 0 448 512" style="pointer-events: none;">
          <path d="M9.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.2 288 416 288c17.7 0 32-14.3 32-32s-14.3-32-32-32l-306.7 0L214.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"></path>
          </svg>
      </div><ol class="ltx_toclist"><li class="ltx_tocentry ltx_tocentry_section">
    <a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#abstract" title="Abstract">
      <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref"></span>
        Abstract
      </span>
    </a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#S1" title="In Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#S2" title="In Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#S2.SS1" title="In 2 Related Work ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Diffusion models for image/video generation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#S2.SS2" title="In 2 Related Work ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Pose-guided character motion transfer</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#S3" title="In Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Method</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#S3.SS1" title="In 3 Method ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Preliminaries of latent diffusion model</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#S3.SS2" title="In 3 Method ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Pose Indicator</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#S3.SS3" title="In 3 Method ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Framework and Implement Details</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#S3.SS4" title="In 3 Method ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span><math alttext="A^{2}" class="ltx_Math" display="inline"><semantics><msup><mi>A</mi><mn>2</mn></msup><annotation-xml encoding="MathML-Content"><apply><csymbol cd="ambiguous">superscript</csymbol><ci>𝐴</ci><cn type="integer">2</cn></apply></annotation-xml><annotation encoding="application/x-tex">A^{2}</annotation><annotation encoding="application/x-llamapun">italic_A start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_typewriter">Bench</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#S4" title="In Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#S4.SS1" title="In 4 Experiments ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Experimental Settings</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#S4.SS2" title="In 4 Experiments ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Experimental Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#S4.SS3" title="In 4 Experiments ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Ablation Study</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#S5" title="In Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusions</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#A1" title="In Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Network Details</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#A2" title="In Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Benchmark Details</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#A2.SS1" title="In Appendix B Benchmark Details ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.1 </span>Evaluation Metric</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#A2.SS2" title="In Appendix B Benchmark Details ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.2 </span>Data Details</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#A3" title="In Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C </span>User Study</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#A4" title="In Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D </span>Additional Experimental Results</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#A4.SS1" title="In Appendix D Additional Experimental Results ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D.1 </span>More qualitative results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#A4.SS2" title="In Appendix D Additional Experimental Results ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D.2 </span>More quantitative results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#A4.SS3" title="In Appendix D Additional Experimental Results ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D.3 </span>Robustness</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#A4.SS4" title="In Appendix D Additional Experimental Results ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D.4 </span>More ablation study</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#A5" title="In Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E </span>Discussion</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#A5.SS1" title="In Appendix E Discussion ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E.1 </span>Limitation and Future Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#A5.SS2" title="In Appendix E Discussion ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E.2 </span>Ethical Considerations</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
    <a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib" title="References">
      <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref"></span>
        References
      </span>
    </a></li></ol></nav>

<div class="ltx_page_content"><div id="target-section" class="section"><a id="license-tr" href="https://info.arxiv.org/help/license/index.html#licenses-available">License: arXiv.org perpetual non-exclusive license</a><div id="watermark-tr">arXiv:2410.10306v1 [cs.CV] 14 Oct 2024</div></div>
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Animate-X: Universal Character Image Animation with Enhanced Motion Representation</h1><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Shuai Tan<sup class="ltx_sup" id="id13.12.id1"><span class="ltx_text ltx_font_italic" id="id13.12.id1.1">1∗</span></sup>,  Biao Gong<sup class="ltx_sup" id="id14.13.id2"><span class="ltx_text ltx_font_italic" id="id14.13.id2.1">1†</span></sup>,  Xiang Wang<sup class="ltx_sup" id="id15.14.id3"><span class="ltx_text ltx_font_italic" id="id15.14.id3.1">2</span></sup>,  Shiwei Zhang<sup class="ltx_sup" id="id16.15.id4"><span class="ltx_text ltx_font_italic" id="id16.15.id4.1">2</span></sup>,  
<br class="ltx_break">
<br class="ltx_break"><span class="ltx_text ltx_font_bold" id="id9.9.5">

Dandan Zheng<sup class="ltx_sup" id="id9.9.5.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="id9.9.5.1.1">1</span></sup>,  Ruobing Zheng<sup class="ltx_sup" id="id9.9.5.2"><span class="ltx_text ltx_font_medium ltx_font_italic" id="id9.9.5.2.1">1</span></sup>,  Kecheng Zheng<sup class="ltx_sup" id="id9.9.5.3"><span class="ltx_text ltx_font_medium ltx_font_italic" id="id9.9.5.3.1">1</span></sup>,  Jingdong Chen<sup class="ltx_sup" id="id9.9.5.4"><span class="ltx_text ltx_font_medium ltx_font_italic" id="id9.9.5.4.1">1</span></sup>,  Ming Yang<sup class="ltx_sup" id="id9.9.5.5"><span class="ltx_text ltx_font_medium ltx_font_italic" id="id9.9.5.5.1">1</span></sup>
</span>
<br class="ltx_break">
<sup class="ltx_sup" id="id17.16.id5"><span class="ltx_text ltx_font_italic" id="id17.16.id5.1">1</span></sup>Ant Group <sup class="ltx_sup" id="id18.17.id6"><span class="ltx_text ltx_font_italic" id="id18.17.id6.1">2</span></sup>Alibaba Group 
<br class="ltx_break"><span class="ltx_text ltx_font_typewriter" id="id19.18.id7">{tanshuai2001,a.biao.gong}@gmail.com,

<br class="ltx_break">{xiaolao.wx,zhangjin.zsw}@alibaba-inc.com,{yuandan.zdd,
<br class="ltx_break">zhengruobing.zrb,zhengkecheng.zkc,jingdongchen.cjd,m.yang}@antgroup.com


<br class="ltx_break">Project Page: <a class="ltx_ref ltx_url" href="https://lucaria-academy.github.io/Animate-X/" title="">https://lucaria-academy.github.io/Animate-X/</a>
</span>
</span></span>
</div><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_abstract" id="abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="id12.1">Character image animation, which generates high-quality videos from a reference image and target pose sequence, has seen significant progress in recent years. However, most existing methods only apply to human figures, which usually do not generalize well on anthropomorphic characters commonly used in industries like gaming and entertainment. Our in-depth analysis suggests to attribute this limitation to their insufficient modeling of motion, which is unable to comprehend the movement pattern of the driving video, thus imposing a pose sequence rigidly onto the target character. To this end, this paper proposes <span class="ltx_text ltx_font_typewriter" id="id12.1.1">Animate-X</span>, a universal animation framework based on LDM for various character types (collectively named <span class="ltx_text ltx_font_typewriter" id="id12.1.2">X</span>), including anthropomorphic characters. To enhance motion representation, we introduce the Pose Indicator, which captures comprehensive motion pattern from the driving video through both implicit and explicit manner. The former leverages CLIP visual features of a driving video to extract its gist of motion, like the overall movement pattern and temporal relations among motions, while the latter strengthens the generalization of LDM by simulating possible inputs in advance that may arise during inference. Moreover, we introduce a new Animated Anthropomorphic Benchmark (<math alttext="A^{2}" class="ltx_Math" display="inline" id="id12.1.m1.1"><semantics id="id12.1.m1.1a"><msup id="id12.1.m1.1.1" xref="id12.1.m1.1.1.cmml"><mi id="id12.1.m1.1.1.2" xref="id12.1.m1.1.1.2.cmml">A</mi><mn id="id12.1.m1.1.1.3" xref="id12.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="id12.1.m1.1b"><apply id="id12.1.m1.1.1.cmml" xref="id12.1.m1.1.1"><csymbol cd="ambiguous" id="id12.1.m1.1.1.1.cmml" xref="id12.1.m1.1.1">superscript</csymbol><ci id="id12.1.m1.1.1.2.cmml" xref="id12.1.m1.1.1.2">𝐴</ci><cn id="id12.1.m1.1.1.3.cmml" type="integer" xref="id12.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id12.1.m1.1c">A^{2}</annotation><annotation encoding="application/x-llamapun" id="id12.1.m1.1d">italic_A start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_typewriter" id="id12.1.3">Bench</span>) to evaluate the performance of <span class="ltx_text ltx_font_typewriter" id="id12.1.4">Animate-X</span> on universal and widely applicable animation images. Extensive experiments demonstrate the superiority and effectiveness of <span class="ltx_text ltx_font_typewriter" id="id12.1.5">Animate-X</span> compared to state-of-the-art methods.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><math alttext="*" class="ltx_Math" display="inline" id="footnote1.m1.1"><semantics id="footnote1.m1.1b"><mo id="footnote1.m1.1.1" xref="footnote1.m1.1.1.cmml">∗</mo><annotation-xml encoding="MathML-Content" id="footnote1.m1.1c"><times id="footnote1.m1.1.1.cmml" xref="footnote1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="footnote1.m1.1d">*</annotation><annotation encoding="application/x-llamapun" id="footnote1.m1.1e">∗</annotation></semantics></math> Work done during internship at Ant Group.</span></span></span><span class="ltx_note ltx_role_footnote" id="footnote1a"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><math alttext="\dagger" class="ltx_Math" display="inline" id="footnote1a.m1.1"><semantics id="footnote1a.m1.1b"><mo id="footnote1a.m1.1.1" xref="footnote1a.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="footnote1a.m1.1c"><ci id="footnote1a.m1.1.1.cmml" xref="footnote1a.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote1a.m1.1d">\dagger</annotation><annotation encoding="application/x-llamapun" id="footnote1a.m1.1e">†</annotation></semantics></math>  Project lead and corresponding author.</span></span></span>
<figure class="ltx_figure" id="S0.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="383" id="S0.F1.1.g1" src="./animate-x_files/x1.png" width="830">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Animations produced by <span class="ltx_text ltx_font_typewriter" id="S0.F1.4.1">Animate-X</span> which extends beyond human to anthropomorphic characters with various body structures, <span class="ltx_text ltx_font_italic" id="S0.F1.5.2">e.g.</span>, without limbs, from games, animations, and posters.
</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Character image animation&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Yang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib70" title="">2018</a>); Zablotskaia et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib76" title="">2019b</a>)</cite> is a compelling and challenging task that aims to generate lifelike, high-quality videos from a reference image and a target pose sequence. A modern image animation method shall ideally <span class="ltx_text ltx_font_italic" id="S1.p1.1.1">balance</span> the identity preservation and motion consistency, which contributes to the promise of broad utilization&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Hu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib21" title="">2023</a>); Xu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib68" title="">2023a</a>); Chang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib9" title="">2023a</a>); Jiang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib25" title="">2022</a>)</cite>.
The phenomenal successes of GAN&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Goodfellow et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib13" title="">2014</a>); Yu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib72" title="">2023</a>); Zhang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib80" title="">2022b</a>)</cite> and generative diffusion models&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Ho et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib19" title="">2022</a>; <a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib18" title="">2020</a>); Guo et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib16" title="">2023</a>)</cite> have reshaped the performance of character animation generation.
Nevertheless, most existing methods only apply to the human-specific character domain. In practice, the concept of <span class="ltx_text ltx_font_italic" id="S1.p1.1.2">“character”</span> encompasses a much broader concept than human, including anthropomorphic figures in cartoons and games, collectively referred to as <span class="ltx_text ltx_font_typewriter" id="S1.p1.1.3">X</span>, which are often more desirable in gaming, film, short videos, etc.
The difficulty in extending current models to these domains can be attributed to two main factors: (1) the predominantly human-centered nature of available datasets, and (2) the limited generalization capabilities of current motion representations.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">The limitations are clearly evidenced for non-human characters in Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#S4.F5" title="Figure 5 ‣ 4.1 Experimental Settings ‣ 4 Experiments ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">5</span></a>. To replicate the given poses, the diffusion models trained on human dance video datasets tend to introduce unrelated human characteristics which may not make sense to reference figures, resulting in abnormal distortions. In other words, these models treat identity preservation and motion consistency as <span class="ltx_text ltx_font_italic" id="S1.p2.1.1">conflicting</span> goals and struggle to balance them, while motion control often prevails.
This issue is particularly pronounced for non-human anthropomorphic characters, whose body structures often differ from human anatomy—such as disproportionately large heads or the absence of arms, as shown in Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#S0.F1" title="Figure 1 ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">1</span></a>.
The primary cause is that the motion representations extracted merely from pose conditions are hard to generalize to a broad range of common cartoon characters with unique physical characteristics, leading to their excessive sacrifices in identity preservation in favor of strict pose consistency, which is an unsensible trade-off between these <span class="ltx_text ltx_font_italic" id="S1.p2.1.2">conflicting</span> goals.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">To address this issue, the natural approach is to enhance the flexibility of motion representations without discarding current pose condition, which can prevent the model from making unsensible trade-offs between overly precise poses and low fidelity to reference images. To this end, we identify two key limitations of existing methods. <span class="ltx_text ltx_font_bold" id="S1.p3.1.1">First</span>, the simple 2D pose skeletons, constructed by connecting sparse keypoints, lack of image-level details and therefore cannot capture the essence of the reference video, such as motion-induced deformations (e.g., body part overlap and occlusion) and overall motion patterns.
<span class="ltx_text ltx_font_bold" id="S1.p3.1.2">Second</span>, the self-driven reconstruction strategy aligns reference and pose skeletons by body shape, simplifying animation but ignoring shape differences during inference.
These inspire us to design the new Pose Indicator from both implicit and explicit perspectives.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S1.p4">
<p class="ltx_p" id="S1.p4.2">In this paper, we propose <span class="ltx_text ltx_font_typewriter" id="S1.p4.2.1">Animate-X</span> for animating any character <span class="ltx_text ltx_font_typewriter" id="S1.p4.2.2">X</span>. Sparked by generative diffusion models&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Rombach et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib39" title="">2022</a>)</cite>, we employ a 3D-UNet&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Blattmann et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib5" title="">2023</a>)</cite> as the denoising network and provide it with motion feature and figure identity as condition.
To fully capture the gist of motion from the driving video, we introduce the Pose Indicator, which consists of the Implicit Pose Indicator (IPI) and the Explicit Pose Indicator (EPI).
Specifically, IPI extracts implicit motion-related features with the assistance of CLIP image feature, isolating essential motion patterns and relations that cannot be directly represented by the pose skeletons from the driving video. Meanwhile, EPI enhances the representation and understanding of the pose encoder by simulating real-world misalignments between the reference image and driven poses during training, strengthening the ability to generate explicit pose features. With the combined power of implicit and explicit features, <span class="ltx_text ltx_font_typewriter" id="S1.p4.2.3">Animate-X</span> demonstrates strong character generalization and pose robustness, enabling general <span class="ltx_text ltx_font_typewriter" id="S1.p4.2.4">X</span> character animation even though it is trained solely on human datasets. Moreover, we introduce a new <span class="ltx_text ltx_font_bold" id="S1.p4.2.5">A</span>nimated <span class="ltx_text ltx_font_bold" id="S1.p4.2.6">A</span>nthropomorphic <span class="ltx_text ltx_font_bold" id="S1.p4.2.7">Bench</span>mark (<math alttext="A^{2}" class="ltx_Math" display="inline" id="S1.p4.1.m1.1"><semantics id="S1.p4.1.m1.1a"><msup id="S1.p4.1.m1.1.1" xref="S1.p4.1.m1.1.1.cmml"><mi id="S1.p4.1.m1.1.1.2" xref="S1.p4.1.m1.1.1.2.cmml">A</mi><mn id="S1.p4.1.m1.1.1.3" xref="S1.p4.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S1.p4.1.m1.1b"><apply id="S1.p4.1.m1.1.1.cmml" xref="S1.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S1.p4.1.m1.1.1.1.cmml" xref="S1.p4.1.m1.1.1">superscript</csymbol><ci id="S1.p4.1.m1.1.1.2.cmml" xref="S1.p4.1.m1.1.1.2">𝐴</ci><cn id="S1.p4.1.m1.1.1.3.cmml" type="integer" xref="S1.p4.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.1.m1.1c">A^{2}</annotation><annotation encoding="application/x-llamapun" id="S1.p4.1.m1.1d">italic_A start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_typewriter" id="S1.p4.2.8">Bench</span>), which includes 500 anthropomorphic characters along with corresponding dance videos, to evaluate the performance of <span class="ltx_text ltx_font_typewriter" id="S1.p4.2.9">Animate-X</span> on other types of characters. Extensive experiments on both public human animation datasets and <math alttext="A^{2}" class="ltx_Math" display="inline" id="S1.p4.2.m2.1"><semantics id="S1.p4.2.m2.1a"><msup id="S1.p4.2.m2.1.1" xref="S1.p4.2.m2.1.1.cmml"><mi id="S1.p4.2.m2.1.1.2" xref="S1.p4.2.m2.1.1.2.cmml">A</mi><mn id="S1.p4.2.m2.1.1.3" xref="S1.p4.2.m2.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S1.p4.2.m2.1b"><apply id="S1.p4.2.m2.1.1.cmml" xref="S1.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S1.p4.2.m2.1.1.1.cmml" xref="S1.p4.2.m2.1.1">superscript</csymbol><ci id="S1.p4.2.m2.1.1.2.cmml" xref="S1.p4.2.m2.1.1.2">𝐴</ci><cn id="S1.p4.2.m2.1.1.3.cmml" type="integer" xref="S1.p4.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.2.m2.1c">A^{2}</annotation><annotation encoding="application/x-llamapun" id="S1.p4.2.m2.1d">italic_A start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_typewriter" id="S1.p4.2.10">Bench</span> demonstrate that <span class="ltx_text ltx_font_typewriter" id="S1.p4.2.11">Animate-X</span> outperforms state-of-the-art methods in preserving identity and maintaining motion consistency in animating <span class="ltx_text ltx_font_typewriter" id="S1.p4.2.12">X</span>. Main contributions summarized as follows:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S1.p5">
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">We present <span class="ltx_text ltx_font_typewriter" id="S1.I1.i1.p1.1.1">Animate-X</span>, which facilitates image-conditioned pose-guided video generation with high generalizability, particularly for attractive anthropomorphic characters. To the best of our knowledge, this is the first work to animate generic cartoon images without the need for strict pose alignment.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">The rethinking about the motion inspire us to propose Pose Indicator, which extracts motion representation suitable for anthropomorphic characters in both implicit and explicit manner, enhancing the robustness of <span class="ltx_text ltx_font_typewriter" id="S1.I1.i2.p1.1.1">Animate-X</span>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.2">Since the popular datasets only contain human video with limited character diversity, we present a new <math alttext="A^{2}" class="ltx_Math" display="inline" id="S1.I1.i3.p1.1.m1.1"><semantics id="S1.I1.i3.p1.1.m1.1a"><msup id="S1.I1.i3.p1.1.m1.1.1" xref="S1.I1.i3.p1.1.m1.1.1.cmml"><mi id="S1.I1.i3.p1.1.m1.1.1.2" xref="S1.I1.i3.p1.1.m1.1.1.2.cmml">A</mi><mn id="S1.I1.i3.p1.1.m1.1.1.3" xref="S1.I1.i3.p1.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S1.I1.i3.p1.1.m1.1b"><apply id="S1.I1.i3.p1.1.m1.1.1.cmml" xref="S1.I1.i3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S1.I1.i3.p1.1.m1.1.1.1.cmml" xref="S1.I1.i3.p1.1.m1.1.1">superscript</csymbol><ci id="S1.I1.i3.p1.1.m1.1.1.2.cmml" xref="S1.I1.i3.p1.1.m1.1.1.2">𝐴</ci><cn id="S1.I1.i3.p1.1.m1.1.1.3.cmml" type="integer" xref="S1.I1.i3.p1.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.i3.p1.1.m1.1c">A^{2}</annotation><annotation encoding="application/x-llamapun" id="S1.I1.i3.p1.1.m1.1d">italic_A start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_typewriter" id="S1.I1.i3.p1.2.1">Bench</span>, specifically for evaluating performance on anthropomorphic characters. Extensive experiments demonstrate that our <span class="ltx_text ltx_font_typewriter" id="S1.I1.i3.p1.2.2">Animate-X</span> outperforms the competing methods quantitatively and qualitatively on both <math alttext="A^{2}" class="ltx_Math" display="inline" id="S1.I1.i3.p1.2.m2.1"><semantics id="S1.I1.i3.p1.2.m2.1a"><msup id="S1.I1.i3.p1.2.m2.1.1" xref="S1.I1.i3.p1.2.m2.1.1.cmml"><mi id="S1.I1.i3.p1.2.m2.1.1.2" xref="S1.I1.i3.p1.2.m2.1.1.2.cmml">A</mi><mn id="S1.I1.i3.p1.2.m2.1.1.3" xref="S1.I1.i3.p1.2.m2.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S1.I1.i3.p1.2.m2.1b"><apply id="S1.I1.i3.p1.2.m2.1.1.cmml" xref="S1.I1.i3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S1.I1.i3.p1.2.m2.1.1.1.cmml" xref="S1.I1.i3.p1.2.m2.1.1">superscript</csymbol><ci id="S1.I1.i3.p1.2.m2.1.1.2.cmml" xref="S1.I1.i3.p1.2.m2.1.1.2">𝐴</ci><cn id="S1.I1.i3.p1.2.m2.1.1.3.cmml" type="integer" xref="S1.I1.i3.p1.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.i3.p1.2.m2.1c">A^{2}</annotation><annotation encoding="application/x-llamapun" id="S1.I1.i3.p1.2.m2.1d">italic_A start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_typewriter" id="S1.I1.i3.p1.2.3">Bench</span> and current human animation benchmark.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Diffusion models for image/video generation</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">In recent years, diffusion models&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Song et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib47" title="">2021</a>); Ho et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib18" title="">2020</a>)</cite> have demonstrated strong generative capabilities, pushing image generation technique towards a daily productivity tool&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Nichol et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib32" title="">2022</a>); Ramesh et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib37" title="">2022</a>); Mou et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib31" title="">2023</a>); Huang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib22" title="">2023</a>); Zhang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib77" title="">2023a</a>); Liu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib29" title="">2023</a>)</cite>. Pioneering works such as DALL-E 2&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Ramesh et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib37" title="">2022</a>)</cite> and Imagen&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Saharia et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib40" title="">2022</a>)</cite> have showcased the extraordinary potential of diffusion models for high-quality image synthesis.
Notable contributions, including Stable Diffusion&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Rombach et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib39" title="">2022</a>)</cite>, have well balanced scalability and efficiency, making diffusion-based image generation accessible and versatile across various applications. On the video generation front, diffusion models are making amazing progress&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Singer et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib46" title="">2023</a>); Wang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib57" title="">2023a</a>; <a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib62" title="">2024c</a>); Wu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib66" title="">2023</a>); Chai et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib8" title="">2023</a>); Ceylan et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib7" title="">2023</a>); Guo et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib16" title="">2023</a>); Zhou et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib85" title="">2022</a>); An et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib1" title="">2023</a>); Xing et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib67" title="">2023</a>); Qing et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib35" title="">2023</a>); Yuan et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib74" title="">2023</a>); Tan et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib52" title="">2024d</a>); Gong et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib12" title="">2024</a>)</cite>. These methods joint spatio-temporal modeling to generate realistic motion dynamics and ensure temporal consistency, marking a substantial step forward in generative models for video content.
In this work, we aim to tackle the character-centered image animation task, a dedicated of conditional video generation. Our approach
enables the transformation of static images into dynamic animations by conditioning on desired motion. This innovation bridges the gap between image and video generation, highlights the versatility and adaptability of diffusion models in creating engaging visual narratives.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Pose-guided character motion transfer</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">Character image animation aims to transfer motion from the source character to the target identity&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Zhang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib82" title="">2024</a>); Chang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib10" title="">2023b</a>)</cite>, which has experienced an impressive journey to improve animation quality and versatility. Early works&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Li et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib28" title="">2019</a>); Siarohin et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib43" title="">2019b</a>; <a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib45" title="">2021b</a>); Zhao &amp; Zhang (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib84" title="">2022b</a>); Tan et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib49" title="">2024a</a>); Wang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib63" title="">2022</a>); Tan et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib51" title="">2024c</a>; <a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib50" title="">b</a>; <a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib48" title="">2023</a>)</cite> predominantly utilize Generative Adversarial Networks (GANs) to generate animated human images. However, these GAN-based models are often confronted by
the emergence of various artifacts in the generated outputs. With the advent of diffusion models, researchers&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Shen et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib41" title="">2024</a>); Zhu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib86" title="">2024</a>)</cite> explored how to go beyond GANs. One effort is Disco&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Wang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib58" title="">2023b</a>)</cite>, which leverages ControlNet&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Zhang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib78" title="">2023b</a>)</cite> to facilitate human dance generation, demonstrating the potential of diffusion models in generating dynamic human poses. Following this, MagicAnimate&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Xu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib69" title="">2023b</a>)</cite> and Animate Anyone&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Hu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib21" title="">2023</a>)</cite> introduce transformer-based temporal attention modules&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Vaswani (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib56" title="">2017</a>)</cite>, enhancing the temporal consistency of animations and resulting in more smooth movement transitions.
Sparked by the
linear time efficiency of Mamba &nbsp;<cite class="ltx_cite ltx_citemacro_cite">Gu &amp; Dao (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib14" title="">2023</a>); Gu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib15" title="">2021</a>)</cite> conceptually merges the merits of parallelism and non-locality, Unianimate&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Wang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib61" title="">2024b</a>)</cite> resorts to it resorts to Mamba for efficient temporal modeling.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">While these approaches have improved the realism of the animations, a notable limitation remains: most current methods require strict alignment between a reference image and driving video. This restricts their applicability in the scenarios where poses cannot be easily extracted, such as anthropomorphic characters, often resulting in bizarre and unsatisfactory outputs.
In contrast, our approach adopts a robust and flexible motion representation to mitigate the dependence on pose alignment. This enables the generation of high-quality animations even in cases where previous methods struggle with non-alignable poses. In this manner, our method enhances the versatility and applicability of character image animation across a broad range of contexts (<span class="ltx_text ltx_font_typewriter" id="S2.SS2.p2.1.1">X</span> character).</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S2.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="605" id="S2.F2.g1" src="./animate-x_files/x2.png" width="813">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>(a) The overview of our <span class="ltx_text ltx_font_typewriter" id="S2.F2.38.1">Animate-X</span>. Given a reference image <math alttext="I^{r}" class="ltx_Math" display="inline" id="S2.F2.18.m1.1"><semantics id="S2.F2.18.m1.1b"><msup id="S2.F2.18.m1.1.1" xref="S2.F2.18.m1.1.1.cmml"><mi id="S2.F2.18.m1.1.1.2" xref="S2.F2.18.m1.1.1.2.cmml">I</mi><mi id="S2.F2.18.m1.1.1.3" xref="S2.F2.18.m1.1.1.3.cmml">r</mi></msup><annotation-xml encoding="MathML-Content" id="S2.F2.18.m1.1c"><apply id="S2.F2.18.m1.1.1.cmml" xref="S2.F2.18.m1.1.1"><csymbol cd="ambiguous" id="S2.F2.18.m1.1.1.1.cmml" xref="S2.F2.18.m1.1.1">superscript</csymbol><ci id="S2.F2.18.m1.1.1.2.cmml" xref="S2.F2.18.m1.1.1.2">𝐼</ci><ci id="S2.F2.18.m1.1.1.3.cmml" xref="S2.F2.18.m1.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.18.m1.1d">I^{r}</annotation><annotation encoding="application/x-llamapun" id="S2.F2.18.m1.1e">italic_I start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT</annotation></semantics></math>, we first extract CLIP image feature <math alttext="f^{r}_{\varphi}" class="ltx_Math" display="inline" id="S2.F2.19.m2.1"><semantics id="S2.F2.19.m2.1b"><msubsup id="S2.F2.19.m2.1.1" xref="S2.F2.19.m2.1.1.cmml"><mi id="S2.F2.19.m2.1.1.2.2" xref="S2.F2.19.m2.1.1.2.2.cmml">f</mi><mi id="S2.F2.19.m2.1.1.3" xref="S2.F2.19.m2.1.1.3.cmml">φ</mi><mi id="S2.F2.19.m2.1.1.2.3" xref="S2.F2.19.m2.1.1.2.3.cmml">r</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.F2.19.m2.1c"><apply id="S2.F2.19.m2.1.1.cmml" xref="S2.F2.19.m2.1.1"><csymbol cd="ambiguous" id="S2.F2.19.m2.1.1.1.cmml" xref="S2.F2.19.m2.1.1">subscript</csymbol><apply id="S2.F2.19.m2.1.1.2.cmml" xref="S2.F2.19.m2.1.1"><csymbol cd="ambiguous" id="S2.F2.19.m2.1.1.2.1.cmml" xref="S2.F2.19.m2.1.1">superscript</csymbol><ci id="S2.F2.19.m2.1.1.2.2.cmml" xref="S2.F2.19.m2.1.1.2.2">𝑓</ci><ci id="S2.F2.19.m2.1.1.2.3.cmml" xref="S2.F2.19.m2.1.1.2.3">𝑟</ci></apply><ci id="S2.F2.19.m2.1.1.3.cmml" xref="S2.F2.19.m2.1.1.3">𝜑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.19.m2.1d">f^{r}_{\varphi}</annotation><annotation encoding="application/x-llamapun" id="S2.F2.19.m2.1e">italic_f start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_φ end_POSTSUBSCRIPT</annotation></semantics></math> and latent feature <math alttext="f^{r}_{e}" class="ltx_Math" display="inline" id="S2.F2.20.m3.1"><semantics id="S2.F2.20.m3.1b"><msubsup id="S2.F2.20.m3.1.1" xref="S2.F2.20.m3.1.1.cmml"><mi id="S2.F2.20.m3.1.1.2.2" xref="S2.F2.20.m3.1.1.2.2.cmml">f</mi><mi id="S2.F2.20.m3.1.1.3" xref="S2.F2.20.m3.1.1.3.cmml">e</mi><mi id="S2.F2.20.m3.1.1.2.3" xref="S2.F2.20.m3.1.1.2.3.cmml">r</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.F2.20.m3.1c"><apply id="S2.F2.20.m3.1.1.cmml" xref="S2.F2.20.m3.1.1"><csymbol cd="ambiguous" id="S2.F2.20.m3.1.1.1.cmml" xref="S2.F2.20.m3.1.1">subscript</csymbol><apply id="S2.F2.20.m3.1.1.2.cmml" xref="S2.F2.20.m3.1.1"><csymbol cd="ambiguous" id="S2.F2.20.m3.1.1.2.1.cmml" xref="S2.F2.20.m3.1.1">superscript</csymbol><ci id="S2.F2.20.m3.1.1.2.2.cmml" xref="S2.F2.20.m3.1.1.2.2">𝑓</ci><ci id="S2.F2.20.m3.1.1.2.3.cmml" xref="S2.F2.20.m3.1.1.2.3">𝑟</ci></apply><ci id="S2.F2.20.m3.1.1.3.cmml" xref="S2.F2.20.m3.1.1.3">𝑒</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.20.m3.1d">f^{r}_{e}</annotation><annotation encoding="application/x-llamapun" id="S2.F2.20.m3.1e">italic_f start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT</annotation></semantics></math> via CLIP image encoder <math alttext="\Phi" class="ltx_Math" display="inline" id="S2.F2.21.m4.1"><semantics id="S2.F2.21.m4.1b"><mi id="S2.F2.21.m4.1.1" mathvariant="normal" xref="S2.F2.21.m4.1.1.cmml">Φ</mi><annotation-xml encoding="MathML-Content" id="S2.F2.21.m4.1c"><ci id="S2.F2.21.m4.1.1.cmml" xref="S2.F2.21.m4.1.1">Φ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.21.m4.1d">\Phi</annotation><annotation encoding="application/x-llamapun" id="S2.F2.21.m4.1e">roman_Φ</annotation></semantics></math> and VAE encoder <math alttext="\mathcal{E}" class="ltx_Math" display="inline" id="S2.F2.22.m5.1"><semantics id="S2.F2.22.m5.1b"><mi class="ltx_font_mathcaligraphic" id="S2.F2.22.m5.1.1" xref="S2.F2.22.m5.1.1.cmml">ℰ</mi><annotation-xml encoding="MathML-Content" id="S2.F2.22.m5.1c"><ci id="S2.F2.22.m5.1.1.cmml" xref="S2.F2.22.m5.1.1">ℰ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.22.m5.1d">\mathcal{E}</annotation><annotation encoding="application/x-llamapun" id="S2.F2.22.m5.1e">caligraphic_E</annotation></semantics></math>.
The proposed Implicit Pose Indicator (<span class="ltx_text ltx_font_bold" id="S2.F2.39.2">IPI</span>) and Explicit Pose Indicator (<span class="ltx_text ltx_font_bold" id="S2.F2.40.3">EPI</span>)
produce motion feature <math alttext="f_{i}" class="ltx_Math" display="inline" id="S2.F2.23.m6.1"><semantics id="S2.F2.23.m6.1b"><msub id="S2.F2.23.m6.1.1" xref="S2.F2.23.m6.1.1.cmml"><mi id="S2.F2.23.m6.1.1.2" xref="S2.F2.23.m6.1.1.2.cmml">f</mi><mi id="S2.F2.23.m6.1.1.3" xref="S2.F2.23.m6.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.F2.23.m6.1c"><apply id="S2.F2.23.m6.1.1.cmml" xref="S2.F2.23.m6.1.1"><csymbol cd="ambiguous" id="S2.F2.23.m6.1.1.1.cmml" xref="S2.F2.23.m6.1.1">subscript</csymbol><ci id="S2.F2.23.m6.1.1.2.cmml" xref="S2.F2.23.m6.1.1.2">𝑓</ci><ci id="S2.F2.23.m6.1.1.3.cmml" xref="S2.F2.23.m6.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.23.m6.1d">f_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.F2.23.m6.1e">italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> and pose feature <math alttext="f_{e}" class="ltx_Math" display="inline" id="S2.F2.24.m7.1"><semantics id="S2.F2.24.m7.1b"><msub id="S2.F2.24.m7.1.1" xref="S2.F2.24.m7.1.1.cmml"><mi id="S2.F2.24.m7.1.1.2" xref="S2.F2.24.m7.1.1.2.cmml">f</mi><mi id="S2.F2.24.m7.1.1.3" xref="S2.F2.24.m7.1.1.3.cmml">e</mi></msub><annotation-xml encoding="MathML-Content" id="S2.F2.24.m7.1c"><apply id="S2.F2.24.m7.1.1.cmml" xref="S2.F2.24.m7.1.1"><csymbol cd="ambiguous" id="S2.F2.24.m7.1.1.1.cmml" xref="S2.F2.24.m7.1.1">subscript</csymbol><ci id="S2.F2.24.m7.1.1.2.cmml" xref="S2.F2.24.m7.1.1.2">𝑓</ci><ci id="S2.F2.24.m7.1.1.3.cmml" xref="S2.F2.24.m7.1.1.3">𝑒</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.24.m7.1d">f_{e}</annotation><annotation encoding="application/x-llamapun" id="S2.F2.24.m7.1e">italic_f start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT</annotation></semantics></math>, respectively. <math alttext="f_{e}" class="ltx_Math" display="inline" id="S2.F2.25.m8.1"><semantics id="S2.F2.25.m8.1b"><msub id="S2.F2.25.m8.1.1" xref="S2.F2.25.m8.1.1.cmml"><mi id="S2.F2.25.m8.1.1.2" xref="S2.F2.25.m8.1.1.2.cmml">f</mi><mi id="S2.F2.25.m8.1.1.3" xref="S2.F2.25.m8.1.1.3.cmml">e</mi></msub><annotation-xml encoding="MathML-Content" id="S2.F2.25.m8.1c"><apply id="S2.F2.25.m8.1.1.cmml" xref="S2.F2.25.m8.1.1"><csymbol cd="ambiguous" id="S2.F2.25.m8.1.1.1.cmml" xref="S2.F2.25.m8.1.1">subscript</csymbol><ci id="S2.F2.25.m8.1.1.2.cmml" xref="S2.F2.25.m8.1.1.2">𝑓</ci><ci id="S2.F2.25.m8.1.1.3.cmml" xref="S2.F2.25.m8.1.1.3">𝑒</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.25.m8.1d">f_{e}</annotation><annotation encoding="application/x-llamapun" id="S2.F2.25.m8.1e">italic_f start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT</annotation></semantics></math> is concatenated with the noised input <math alttext="\epsilon" class="ltx_Math" display="inline" id="S2.F2.26.m9.1"><semantics id="S2.F2.26.m9.1b"><mi id="S2.F2.26.m9.1.1" xref="S2.F2.26.m9.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S2.F2.26.m9.1c"><ci id="S2.F2.26.m9.1.1.cmml" xref="S2.F2.26.m9.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.26.m9.1d">\epsilon</annotation><annotation encoding="application/x-llamapun" id="S2.F2.26.m9.1e">italic_ϵ</annotation></semantics></math> along the channel dimension, then further concatenated with <math alttext="f^{r}_{e}" class="ltx_Math" display="inline" id="S2.F2.27.m10.1"><semantics id="S2.F2.27.m10.1b"><msubsup id="S2.F2.27.m10.1.1" xref="S2.F2.27.m10.1.1.cmml"><mi id="S2.F2.27.m10.1.1.2.2" xref="S2.F2.27.m10.1.1.2.2.cmml">f</mi><mi id="S2.F2.27.m10.1.1.3" xref="S2.F2.27.m10.1.1.3.cmml">e</mi><mi id="S2.F2.27.m10.1.1.2.3" xref="S2.F2.27.m10.1.1.2.3.cmml">r</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.F2.27.m10.1c"><apply id="S2.F2.27.m10.1.1.cmml" xref="S2.F2.27.m10.1.1"><csymbol cd="ambiguous" id="S2.F2.27.m10.1.1.1.cmml" xref="S2.F2.27.m10.1.1">subscript</csymbol><apply id="S2.F2.27.m10.1.1.2.cmml" xref="S2.F2.27.m10.1.1"><csymbol cd="ambiguous" id="S2.F2.27.m10.1.1.2.1.cmml" xref="S2.F2.27.m10.1.1">superscript</csymbol><ci id="S2.F2.27.m10.1.1.2.2.cmml" xref="S2.F2.27.m10.1.1.2.2">𝑓</ci><ci id="S2.F2.27.m10.1.1.2.3.cmml" xref="S2.F2.27.m10.1.1.2.3">𝑟</ci></apply><ci id="S2.F2.27.m10.1.1.3.cmml" xref="S2.F2.27.m10.1.1.3">𝑒</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.27.m10.1d">f^{r}_{e}</annotation><annotation encoding="application/x-llamapun" id="S2.F2.27.m10.1e">italic_f start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT</annotation></semantics></math> along the temporal dimension. This serves as the input to the diffusion model <math alttext="\epsilon_{\theta}" class="ltx_Math" display="inline" id="S2.F2.28.m11.1"><semantics id="S2.F2.28.m11.1b"><msub id="S2.F2.28.m11.1.1" xref="S2.F2.28.m11.1.1.cmml"><mi id="S2.F2.28.m11.1.1.2" xref="S2.F2.28.m11.1.1.2.cmml">ϵ</mi><mi id="S2.F2.28.m11.1.1.3" xref="S2.F2.28.m11.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S2.F2.28.m11.1c"><apply id="S2.F2.28.m11.1.1.cmml" xref="S2.F2.28.m11.1.1"><csymbol cd="ambiguous" id="S2.F2.28.m11.1.1.1.cmml" xref="S2.F2.28.m11.1.1">subscript</csymbol><ci id="S2.F2.28.m11.1.1.2.cmml" xref="S2.F2.28.m11.1.1.2">italic-ϵ</ci><ci id="S2.F2.28.m11.1.1.3.cmml" xref="S2.F2.28.m11.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.28.m11.1d">\epsilon_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S2.F2.28.m11.1e">italic_ϵ start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math> for progressive denoising. During the denoising process, <math alttext="f^{r}_{\varphi}" class="ltx_Math" display="inline" id="S2.F2.29.m12.1"><semantics id="S2.F2.29.m12.1b"><msubsup id="S2.F2.29.m12.1.1" xref="S2.F2.29.m12.1.1.cmml"><mi id="S2.F2.29.m12.1.1.2.2" xref="S2.F2.29.m12.1.1.2.2.cmml">f</mi><mi id="S2.F2.29.m12.1.1.3" xref="S2.F2.29.m12.1.1.3.cmml">φ</mi><mi id="S2.F2.29.m12.1.1.2.3" xref="S2.F2.29.m12.1.1.2.3.cmml">r</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.F2.29.m12.1c"><apply id="S2.F2.29.m12.1.1.cmml" xref="S2.F2.29.m12.1.1"><csymbol cd="ambiguous" id="S2.F2.29.m12.1.1.1.cmml" xref="S2.F2.29.m12.1.1">subscript</csymbol><apply id="S2.F2.29.m12.1.1.2.cmml" xref="S2.F2.29.m12.1.1"><csymbol cd="ambiguous" id="S2.F2.29.m12.1.1.2.1.cmml" xref="S2.F2.29.m12.1.1">superscript</csymbol><ci id="S2.F2.29.m12.1.1.2.2.cmml" xref="S2.F2.29.m12.1.1.2.2">𝑓</ci><ci id="S2.F2.29.m12.1.1.2.3.cmml" xref="S2.F2.29.m12.1.1.2.3">𝑟</ci></apply><ci id="S2.F2.29.m12.1.1.3.cmml" xref="S2.F2.29.m12.1.1.3">𝜑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.29.m12.1d">f^{r}_{\varphi}</annotation><annotation encoding="application/x-llamapun" id="S2.F2.29.m12.1e">italic_f start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_φ end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="f_{i}" class="ltx_Math" display="inline" id="S2.F2.30.m13.1"><semantics id="S2.F2.30.m13.1b"><msub id="S2.F2.30.m13.1.1" xref="S2.F2.30.m13.1.1.cmml"><mi id="S2.F2.30.m13.1.1.2" xref="S2.F2.30.m13.1.1.2.cmml">f</mi><mi id="S2.F2.30.m13.1.1.3" xref="S2.F2.30.m13.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.F2.30.m13.1c"><apply id="S2.F2.30.m13.1.1.cmml" xref="S2.F2.30.m13.1.1"><csymbol cd="ambiguous" id="S2.F2.30.m13.1.1.1.cmml" xref="S2.F2.30.m13.1.1">subscript</csymbol><ci id="S2.F2.30.m13.1.1.2.cmml" xref="S2.F2.30.m13.1.1.2">𝑓</ci><ci id="S2.F2.30.m13.1.1.3.cmml" xref="S2.F2.30.m13.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.30.m13.1d">f_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.F2.30.m13.1e">italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> provide appearance condition from <math alttext="I^{r}" class="ltx_Math" display="inline" id="S2.F2.31.m14.1"><semantics id="S2.F2.31.m14.1b"><msup id="S2.F2.31.m14.1.1" xref="S2.F2.31.m14.1.1.cmml"><mi id="S2.F2.31.m14.1.1.2" xref="S2.F2.31.m14.1.1.2.cmml">I</mi><mi id="S2.F2.31.m14.1.1.3" xref="S2.F2.31.m14.1.1.3.cmml">r</mi></msup><annotation-xml encoding="MathML-Content" id="S2.F2.31.m14.1c"><apply id="S2.F2.31.m14.1.1.cmml" xref="S2.F2.31.m14.1.1"><csymbol cd="ambiguous" id="S2.F2.31.m14.1.1.1.cmml" xref="S2.F2.31.m14.1.1">superscript</csymbol><ci id="S2.F2.31.m14.1.1.2.cmml" xref="S2.F2.31.m14.1.1.2">𝐼</ci><ci id="S2.F2.31.m14.1.1.3.cmml" xref="S2.F2.31.m14.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.31.m14.1d">I^{r}</annotation><annotation encoding="application/x-llamapun" id="S2.F2.31.m14.1e">italic_I start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT</annotation></semantics></math> and motion condition from <math alttext="I^{d}_{1:F}" class="ltx_Math" display="inline" id="S2.F2.32.m15.1"><semantics id="S2.F2.32.m15.1b"><msubsup id="S2.F2.32.m15.1.1" xref="S2.F2.32.m15.1.1.cmml"><mi id="S2.F2.32.m15.1.1.2.2" xref="S2.F2.32.m15.1.1.2.2.cmml">I</mi><mrow id="S2.F2.32.m15.1.1.3" xref="S2.F2.32.m15.1.1.3.cmml"><mn id="S2.F2.32.m15.1.1.3.2" xref="S2.F2.32.m15.1.1.3.2.cmml">1</mn><mo id="S2.F2.32.m15.1.1.3.1" lspace="0.278em" rspace="0.278em" xref="S2.F2.32.m15.1.1.3.1.cmml">:</mo><mi id="S2.F2.32.m15.1.1.3.3" xref="S2.F2.32.m15.1.1.3.3.cmml">F</mi></mrow><mi id="S2.F2.32.m15.1.1.2.3" xref="S2.F2.32.m15.1.1.2.3.cmml">d</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.F2.32.m15.1c"><apply id="S2.F2.32.m15.1.1.cmml" xref="S2.F2.32.m15.1.1"><csymbol cd="ambiguous" id="S2.F2.32.m15.1.1.1.cmml" xref="S2.F2.32.m15.1.1">subscript</csymbol><apply id="S2.F2.32.m15.1.1.2.cmml" xref="S2.F2.32.m15.1.1"><csymbol cd="ambiguous" id="S2.F2.32.m15.1.1.2.1.cmml" xref="S2.F2.32.m15.1.1">superscript</csymbol><ci id="S2.F2.32.m15.1.1.2.2.cmml" xref="S2.F2.32.m15.1.1.2.2">𝐼</ci><ci id="S2.F2.32.m15.1.1.2.3.cmml" xref="S2.F2.32.m15.1.1.2.3">𝑑</ci></apply><apply id="S2.F2.32.m15.1.1.3.cmml" xref="S2.F2.32.m15.1.1.3"><ci id="S2.F2.32.m15.1.1.3.1.cmml" xref="S2.F2.32.m15.1.1.3.1">:</ci><cn id="S2.F2.32.m15.1.1.3.2.cmml" type="integer" xref="S2.F2.32.m15.1.1.3.2">1</cn><ci id="S2.F2.32.m15.1.1.3.3.cmml" xref="S2.F2.32.m15.1.1.3.3">𝐹</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.32.m15.1d">I^{d}_{1:F}</annotation><annotation encoding="application/x-llamapun" id="S2.F2.32.m15.1e">italic_I start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 : italic_F end_POSTSUBSCRIPT</annotation></semantics></math>.
At last, a VAE decoder <math alttext="\mathcal{D}" class="ltx_Math" display="inline" id="S2.F2.33.m16.1"><semantics id="S2.F2.33.m16.1b"><mi class="ltx_font_mathcaligraphic" id="S2.F2.33.m16.1.1" xref="S2.F2.33.m16.1.1.cmml">𝒟</mi><annotation-xml encoding="MathML-Content" id="S2.F2.33.m16.1c"><ci id="S2.F2.33.m16.1.1.cmml" xref="S2.F2.33.m16.1.1">𝒟</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.33.m16.1d">\mathcal{D}</annotation><annotation encoding="application/x-llamapun" id="S2.F2.33.m16.1e">caligraphic_D</annotation></semantics></math> is adopted to map the generated latent representation <math alttext="z_{0}" class="ltx_Math" display="inline" id="S2.F2.34.m17.1"><semantics id="S2.F2.34.m17.1b"><msub id="S2.F2.34.m17.1.1" xref="S2.F2.34.m17.1.1.cmml"><mi id="S2.F2.34.m17.1.1.2" xref="S2.F2.34.m17.1.1.2.cmml">z</mi><mn id="S2.F2.34.m17.1.1.3" xref="S2.F2.34.m17.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S2.F2.34.m17.1c"><apply id="S2.F2.34.m17.1.1.cmml" xref="S2.F2.34.m17.1.1"><csymbol cd="ambiguous" id="S2.F2.34.m17.1.1.1.cmml" xref="S2.F2.34.m17.1.1">subscript</csymbol><ci id="S2.F2.34.m17.1.1.2.cmml" xref="S2.F2.34.m17.1.1.2">𝑧</ci><cn id="S2.F2.34.m17.1.1.3.cmml" type="integer" xref="S2.F2.34.m17.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.34.m17.1d">z_{0}</annotation><annotation encoding="application/x-llamapun" id="S2.F2.34.m17.1e">italic_z start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math> to the animation video. (b) The detailed structure of Implicit Pose Indicator. (c) The pipeline of pose transformation by Explicit Pose Indicator.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Method</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.p1">
<p class="ltx_p" id="S3.p1.2">In this work, we aim to generate an animated video that
maintains consistency in identity with a reference image <math alttext="I^{r}" class="ltx_Math" display="inline" id="S3.p1.1.m1.1"><semantics id="S3.p1.1.m1.1a"><msup id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml"><mi id="S3.p1.1.m1.1.1.2" xref="S3.p1.1.m1.1.1.2.cmml">I</mi><mi id="S3.p1.1.m1.1.1.3" xref="S3.p1.1.m1.1.1.3.cmml">r</mi></msup><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><apply id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.p1.1.m1.1.1.1.cmml" xref="S3.p1.1.m1.1.1">superscript</csymbol><ci id="S3.p1.1.m1.1.1.2.cmml" xref="S3.p1.1.m1.1.1.2">𝐼</ci><ci id="S3.p1.1.m1.1.1.3.cmml" xref="S3.p1.1.m1.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">I^{r}</annotation><annotation encoding="application/x-llamapun" id="S3.p1.1.m1.1d">italic_I start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT</annotation></semantics></math> and body movement with a driving video <math alttext="I^{d}_{1:F}" class="ltx_Math" display="inline" id="S3.p1.2.m2.1"><semantics id="S3.p1.2.m2.1a"><msubsup id="S3.p1.2.m2.1.1" xref="S3.p1.2.m2.1.1.cmml"><mi id="S3.p1.2.m2.1.1.2.2" xref="S3.p1.2.m2.1.1.2.2.cmml">I</mi><mrow id="S3.p1.2.m2.1.1.3" xref="S3.p1.2.m2.1.1.3.cmml"><mn id="S3.p1.2.m2.1.1.3.2" xref="S3.p1.2.m2.1.1.3.2.cmml">1</mn><mo id="S3.p1.2.m2.1.1.3.1" lspace="0.278em" rspace="0.278em" xref="S3.p1.2.m2.1.1.3.1.cmml">:</mo><mi id="S3.p1.2.m2.1.1.3.3" xref="S3.p1.2.m2.1.1.3.3.cmml">F</mi></mrow><mi id="S3.p1.2.m2.1.1.2.3" xref="S3.p1.2.m2.1.1.2.3.cmml">d</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.p1.2.m2.1b"><apply id="S3.p1.2.m2.1.1.cmml" xref="S3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.p1.2.m2.1.1.1.cmml" xref="S3.p1.2.m2.1.1">subscript</csymbol><apply id="S3.p1.2.m2.1.1.2.cmml" xref="S3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.p1.2.m2.1.1.2.1.cmml" xref="S3.p1.2.m2.1.1">superscript</csymbol><ci id="S3.p1.2.m2.1.1.2.2.cmml" xref="S3.p1.2.m2.1.1.2.2">𝐼</ci><ci id="S3.p1.2.m2.1.1.2.3.cmml" xref="S3.p1.2.m2.1.1.2.3">𝑑</ci></apply><apply id="S3.p1.2.m2.1.1.3.cmml" xref="S3.p1.2.m2.1.1.3"><ci id="S3.p1.2.m2.1.1.3.1.cmml" xref="S3.p1.2.m2.1.1.3.1">:</ci><cn id="S3.p1.2.m2.1.1.3.2.cmml" type="integer" xref="S3.p1.2.m2.1.1.3.2">1</cn><ci id="S3.p1.2.m2.1.1.3.3.cmml" xref="S3.p1.2.m2.1.1.3.3">𝐹</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.2.m2.1c">I^{d}_{1:F}</annotation><annotation encoding="application/x-llamapun" id="S3.p1.2.m2.1d">italic_I start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 : italic_F end_POSTSUBSCRIPT</annotation></semantics></math>.
Different from previous works, our primary objective is to animate a general characters beyond human, particularly like anthropomorphic ones, which has broader applications in entertainment industry.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Preliminaries of latent diffusion model</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">A diffusion model (DM) operates by learning a probabilistic process that models data generation through noise. To mitigate the heavy computational load of traditional pixel-based diffusion models in high-dimensional RGB spaces, latent diffusion models (LDMs)&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Rombach et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib39" title="">2022</a>)</cite> propose to shift the process into a lower-dimensional latent space using a pre-trained variational autoencoder (VAE)&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Kingma (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib27" title="">2013</a>)</cite>. It encodes the input data into a compressed latent representation <math alttext="z_{0}" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.1"><semantics id="S3.SS1.p1.1.m1.1a"><msub id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml"><mi id="S3.SS1.p1.1.m1.1.1.2" xref="S3.SS1.p1.1.m1.1.1.2.cmml">z</mi><mn id="S3.SS1.p1.1.m1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><apply id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.2">𝑧</ci><cn id="S3.SS1.p1.1.m1.1.1.3.cmml" type="integer" xref="S3.SS1.p1.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">z_{0}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.1.m1.1d">italic_z start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math>. Gaussian noise is then incrementally added to this latent representation over several steps, reducing computational requirements while maintaining the generative capabilities of the model. The process can be formalized as:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S3.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="q(\mathbf{z}_{t}|\mathbf{z}_{t-1})=\mathcal{N}(\mathbf{z}_{t};\sqrt{1-\beta_{t%
}}\mathbf{z}_{t-1},\beta_{t}\mathbf{I})," class="ltx_Math" display="block" id="S3.E1.m1.1"><semantics id="S3.E1.m1.1a"><mrow id="S3.E1.m1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><mrow id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><mrow id="S3.E1.m1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.3.cmml">q</mi><mo id="S3.E1.m1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S3.E1.m1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E1.m1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E1.m1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.cmml"><msub id="S3.E1.m1.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.1.1.2.2" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.2.cmml">𝐳</mi><mi id="S3.E1.m1.1.1.1.1.1.1.1.1.2.3" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.3.cmml">t</mi></msub><mo fence="false" id="S3.E1.m1.1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.cmml">|</mo><msub id="S3.E1.m1.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.1.1.3.2" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3.2.cmml">𝐳</mi><mrow id="S3.E1.m1.1.1.1.1.1.1.1.1.3.3" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3.3.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.1.1.3.3.2" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3.3.2.cmml">t</mi><mo id="S3.E1.m1.1.1.1.1.1.1.1.1.3.3.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3.3.1.cmml">−</mo><mn id="S3.E1.m1.1.1.1.1.1.1.1.1.3.3.3" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3.3.3.cmml">1</mn></mrow></msub></mrow><mo id="S3.E1.m1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E1.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.1.1.1.1.5" xref="S3.E1.m1.1.1.1.1.5.cmml">=</mo><mrow id="S3.E1.m1.1.1.1.1.4" xref="S3.E1.m1.1.1.1.1.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.1.1.1.1.4.5" xref="S3.E1.m1.1.1.1.1.4.5.cmml">𝒩</mi><mo id="S3.E1.m1.1.1.1.1.4.4" xref="S3.E1.m1.1.1.1.1.4.4.cmml">⁢</mo><mrow id="S3.E1.m1.1.1.1.1.4.3.3" xref="S3.E1.m1.1.1.1.1.4.3.4.cmml"><mo id="S3.E1.m1.1.1.1.1.4.3.3.4" stretchy="false" xref="S3.E1.m1.1.1.1.1.4.3.4.cmml">(</mo><msub id="S3.E1.m1.1.1.1.1.2.1.1.1" xref="S3.E1.m1.1.1.1.1.2.1.1.1.cmml"><mi id="S3.E1.m1.1.1.1.1.2.1.1.1.2" xref="S3.E1.m1.1.1.1.1.2.1.1.1.2.cmml">𝐳</mi><mi id="S3.E1.m1.1.1.1.1.2.1.1.1.3" xref="S3.E1.m1.1.1.1.1.2.1.1.1.3.cmml">t</mi></msub><mo id="S3.E1.m1.1.1.1.1.4.3.3.5" xref="S3.E1.m1.1.1.1.1.4.3.4.cmml">;</mo><mrow id="S3.E1.m1.1.1.1.1.3.2.2.2" xref="S3.E1.m1.1.1.1.1.3.2.2.2.cmml"><msqrt id="S3.E1.m1.1.1.1.1.3.2.2.2.2" xref="S3.E1.m1.1.1.1.1.3.2.2.2.2.cmml"><mrow id="S3.E1.m1.1.1.1.1.3.2.2.2.2.2" xref="S3.E1.m1.1.1.1.1.3.2.2.2.2.2.cmml"><mn id="S3.E1.m1.1.1.1.1.3.2.2.2.2.2.2" xref="S3.E1.m1.1.1.1.1.3.2.2.2.2.2.2.cmml">1</mn><mo id="S3.E1.m1.1.1.1.1.3.2.2.2.2.2.1" xref="S3.E1.m1.1.1.1.1.3.2.2.2.2.2.1.cmml">−</mo><msub id="S3.E1.m1.1.1.1.1.3.2.2.2.2.2.3" xref="S3.E1.m1.1.1.1.1.3.2.2.2.2.2.3.cmml"><mi id="S3.E1.m1.1.1.1.1.3.2.2.2.2.2.3.2" xref="S3.E1.m1.1.1.1.1.3.2.2.2.2.2.3.2.cmml">β</mi><mi id="S3.E1.m1.1.1.1.1.3.2.2.2.2.2.3.3" xref="S3.E1.m1.1.1.1.1.3.2.2.2.2.2.3.3.cmml">t</mi></msub></mrow></msqrt><mo id="S3.E1.m1.1.1.1.1.3.2.2.2.1" xref="S3.E1.m1.1.1.1.1.3.2.2.2.1.cmml">⁢</mo><msub id="S3.E1.m1.1.1.1.1.3.2.2.2.3" xref="S3.E1.m1.1.1.1.1.3.2.2.2.3.cmml"><mi id="S3.E1.m1.1.1.1.1.3.2.2.2.3.2" xref="S3.E1.m1.1.1.1.1.3.2.2.2.3.2.cmml">𝐳</mi><mrow id="S3.E1.m1.1.1.1.1.3.2.2.2.3.3" xref="S3.E1.m1.1.1.1.1.3.2.2.2.3.3.cmml"><mi id="S3.E1.m1.1.1.1.1.3.2.2.2.3.3.2" xref="S3.E1.m1.1.1.1.1.3.2.2.2.3.3.2.cmml">t</mi><mo id="S3.E1.m1.1.1.1.1.3.2.2.2.3.3.1" xref="S3.E1.m1.1.1.1.1.3.2.2.2.3.3.1.cmml">−</mo><mn id="S3.E1.m1.1.1.1.1.3.2.2.2.3.3.3" xref="S3.E1.m1.1.1.1.1.3.2.2.2.3.3.3.cmml">1</mn></mrow></msub></mrow><mo id="S3.E1.m1.1.1.1.1.4.3.3.6" xref="S3.E1.m1.1.1.1.1.4.3.4.cmml">,</mo><mrow id="S3.E1.m1.1.1.1.1.4.3.3.3" xref="S3.E1.m1.1.1.1.1.4.3.3.3.cmml"><msub id="S3.E1.m1.1.1.1.1.4.3.3.3.2" xref="S3.E1.m1.1.1.1.1.4.3.3.3.2.cmml"><mi id="S3.E1.m1.1.1.1.1.4.3.3.3.2.2" xref="S3.E1.m1.1.1.1.1.4.3.3.3.2.2.cmml">β</mi><mi id="S3.E1.m1.1.1.1.1.4.3.3.3.2.3" xref="S3.E1.m1.1.1.1.1.4.3.3.3.2.3.cmml">t</mi></msub><mo id="S3.E1.m1.1.1.1.1.4.3.3.3.1" xref="S3.E1.m1.1.1.1.1.4.3.3.3.1.cmml">⁢</mo><mi id="S3.E1.m1.1.1.1.1.4.3.3.3.3" xref="S3.E1.m1.1.1.1.1.4.3.3.3.3.cmml">𝐈</mi></mrow><mo id="S3.E1.m1.1.1.1.1.4.3.3.7" stretchy="false" xref="S3.E1.m1.1.1.1.1.4.3.4.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E1.m1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.1b"><apply id="S3.E1.m1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1"><eq id="S3.E1.m1.1.1.1.1.5.cmml" xref="S3.E1.m1.1.1.1.1.5"></eq><apply id="S3.E1.m1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1"><times id="S3.E1.m1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.2"></times><ci id="S3.E1.m1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.3">𝑞</ci><apply id="S3.E1.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1">conditional</csymbol><apply id="S3.E1.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.2">𝐳</ci><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.3">𝑡</ci></apply><apply id="S3.E1.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3.2">𝐳</ci><apply id="S3.E1.m1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3.3"><minus id="S3.E1.m1.1.1.1.1.1.1.1.1.3.3.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3.3.1"></minus><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.3.3.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3.3.2">𝑡</ci><cn id="S3.E1.m1.1.1.1.1.1.1.1.1.3.3.3.cmml" type="integer" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3.3.3">1</cn></apply></apply></apply></apply><apply id="S3.E1.m1.1.1.1.1.4.cmml" xref="S3.E1.m1.1.1.1.1.4"><times id="S3.E1.m1.1.1.1.1.4.4.cmml" xref="S3.E1.m1.1.1.1.1.4.4"></times><ci id="S3.E1.m1.1.1.1.1.4.5.cmml" xref="S3.E1.m1.1.1.1.1.4.5">𝒩</ci><list id="S3.E1.m1.1.1.1.1.4.3.4.cmml" xref="S3.E1.m1.1.1.1.1.4.3.3"><apply id="S3.E1.m1.1.1.1.1.2.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.2.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.2.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.2.1.1.1">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.2.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.2.1.1.1.2">𝐳</ci><ci id="S3.E1.m1.1.1.1.1.2.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.2.1.1.1.3">𝑡</ci></apply><apply id="S3.E1.m1.1.1.1.1.3.2.2.2.cmml" xref="S3.E1.m1.1.1.1.1.3.2.2.2"><times id="S3.E1.m1.1.1.1.1.3.2.2.2.1.cmml" xref="S3.E1.m1.1.1.1.1.3.2.2.2.1"></times><apply id="S3.E1.m1.1.1.1.1.3.2.2.2.2.cmml" xref="S3.E1.m1.1.1.1.1.3.2.2.2.2"><root id="S3.E1.m1.1.1.1.1.3.2.2.2.2a.cmml" xref="S3.E1.m1.1.1.1.1.3.2.2.2.2"></root><apply id="S3.E1.m1.1.1.1.1.3.2.2.2.2.2.cmml" xref="S3.E1.m1.1.1.1.1.3.2.2.2.2.2"><minus id="S3.E1.m1.1.1.1.1.3.2.2.2.2.2.1.cmml" xref="S3.E1.m1.1.1.1.1.3.2.2.2.2.2.1"></minus><cn id="S3.E1.m1.1.1.1.1.3.2.2.2.2.2.2.cmml" type="integer" xref="S3.E1.m1.1.1.1.1.3.2.2.2.2.2.2">1</cn><apply id="S3.E1.m1.1.1.1.1.3.2.2.2.2.2.3.cmml" xref="S3.E1.m1.1.1.1.1.3.2.2.2.2.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.3.2.2.2.2.2.3.1.cmml" xref="S3.E1.m1.1.1.1.1.3.2.2.2.2.2.3">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.3.2.2.2.2.2.3.2.cmml" xref="S3.E1.m1.1.1.1.1.3.2.2.2.2.2.3.2">𝛽</ci><ci id="S3.E1.m1.1.1.1.1.3.2.2.2.2.2.3.3.cmml" xref="S3.E1.m1.1.1.1.1.3.2.2.2.2.2.3.3">𝑡</ci></apply></apply></apply><apply id="S3.E1.m1.1.1.1.1.3.2.2.2.3.cmml" xref="S3.E1.m1.1.1.1.1.3.2.2.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.3.2.2.2.3.1.cmml" xref="S3.E1.m1.1.1.1.1.3.2.2.2.3">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.3.2.2.2.3.2.cmml" xref="S3.E1.m1.1.1.1.1.3.2.2.2.3.2">𝐳</ci><apply id="S3.E1.m1.1.1.1.1.3.2.2.2.3.3.cmml" xref="S3.E1.m1.1.1.1.1.3.2.2.2.3.3"><minus id="S3.E1.m1.1.1.1.1.3.2.2.2.3.3.1.cmml" xref="S3.E1.m1.1.1.1.1.3.2.2.2.3.3.1"></minus><ci id="S3.E1.m1.1.1.1.1.3.2.2.2.3.3.2.cmml" xref="S3.E1.m1.1.1.1.1.3.2.2.2.3.3.2">𝑡</ci><cn id="S3.E1.m1.1.1.1.1.3.2.2.2.3.3.3.cmml" type="integer" xref="S3.E1.m1.1.1.1.1.3.2.2.2.3.3.3">1</cn></apply></apply></apply><apply id="S3.E1.m1.1.1.1.1.4.3.3.3.cmml" xref="S3.E1.m1.1.1.1.1.4.3.3.3"><times id="S3.E1.m1.1.1.1.1.4.3.3.3.1.cmml" xref="S3.E1.m1.1.1.1.1.4.3.3.3.1"></times><apply id="S3.E1.m1.1.1.1.1.4.3.3.3.2.cmml" xref="S3.E1.m1.1.1.1.1.4.3.3.3.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.4.3.3.3.2.1.cmml" xref="S3.E1.m1.1.1.1.1.4.3.3.3.2">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.4.3.3.3.2.2.cmml" xref="S3.E1.m1.1.1.1.1.4.3.3.3.2.2">𝛽</ci><ci id="S3.E1.m1.1.1.1.1.4.3.3.3.2.3.cmml" xref="S3.E1.m1.1.1.1.1.4.3.3.3.2.3">𝑡</ci></apply><ci id="S3.E1.m1.1.1.1.1.4.3.3.3.3.cmml" xref="S3.E1.m1.1.1.1.1.4.3.3.3.3">𝐈</ci></apply></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.1c">q(\mathbf{z}_{t}|\mathbf{z}_{t-1})=\mathcal{N}(\mathbf{z}_{t};\sqrt{1-\beta_{t%
}}\mathbf{z}_{t-1},\beta_{t}\mathbf{I}),</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.1d">italic_q ( bold_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | bold_z start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT ) = caligraphic_N ( bold_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ; square-root start_ARG 1 - italic_β start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG bold_z start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT , italic_β start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT bold_I ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.p1.9">where <math alttext="\beta_{t}\in(0,1)" class="ltx_Math" display="inline" id="S3.SS1.p1.2.m1.2"><semantics id="S3.SS1.p1.2.m1.2a"><mrow id="S3.SS1.p1.2.m1.2.3" xref="S3.SS1.p1.2.m1.2.3.cmml"><msub id="S3.SS1.p1.2.m1.2.3.2" xref="S3.SS1.p1.2.m1.2.3.2.cmml"><mi id="S3.SS1.p1.2.m1.2.3.2.2" xref="S3.SS1.p1.2.m1.2.3.2.2.cmml">β</mi><mi id="S3.SS1.p1.2.m1.2.3.2.3" xref="S3.SS1.p1.2.m1.2.3.2.3.cmml">t</mi></msub><mo id="S3.SS1.p1.2.m1.2.3.1" xref="S3.SS1.p1.2.m1.2.3.1.cmml">∈</mo><mrow id="S3.SS1.p1.2.m1.2.3.3.2" xref="S3.SS1.p1.2.m1.2.3.3.1.cmml"><mo id="S3.SS1.p1.2.m1.2.3.3.2.1" stretchy="false" xref="S3.SS1.p1.2.m1.2.3.3.1.cmml">(</mo><mn id="S3.SS1.p1.2.m1.1.1" xref="S3.SS1.p1.2.m1.1.1.cmml">0</mn><mo id="S3.SS1.p1.2.m1.2.3.3.2.2" xref="S3.SS1.p1.2.m1.2.3.3.1.cmml">,</mo><mn id="S3.SS1.p1.2.m1.2.2" xref="S3.SS1.p1.2.m1.2.2.cmml">1</mn><mo id="S3.SS1.p1.2.m1.2.3.3.2.3" stretchy="false" xref="S3.SS1.p1.2.m1.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m1.2b"><apply id="S3.SS1.p1.2.m1.2.3.cmml" xref="S3.SS1.p1.2.m1.2.3"><in id="S3.SS1.p1.2.m1.2.3.1.cmml" xref="S3.SS1.p1.2.m1.2.3.1"></in><apply id="S3.SS1.p1.2.m1.2.3.2.cmml" xref="S3.SS1.p1.2.m1.2.3.2"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m1.2.3.2.1.cmml" xref="S3.SS1.p1.2.m1.2.3.2">subscript</csymbol><ci id="S3.SS1.p1.2.m1.2.3.2.2.cmml" xref="S3.SS1.p1.2.m1.2.3.2.2">𝛽</ci><ci id="S3.SS1.p1.2.m1.2.3.2.3.cmml" xref="S3.SS1.p1.2.m1.2.3.2.3">𝑡</ci></apply><interval closure="open" id="S3.SS1.p1.2.m1.2.3.3.1.cmml" xref="S3.SS1.p1.2.m1.2.3.3.2"><cn id="S3.SS1.p1.2.m1.1.1.cmml" type="integer" xref="S3.SS1.p1.2.m1.1.1">0</cn><cn id="S3.SS1.p1.2.m1.2.2.cmml" type="integer" xref="S3.SS1.p1.2.m1.2.2">1</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m1.2c">\beta_{t}\in(0,1)</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.2.m1.2d">italic_β start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ∈ ( 0 , 1 )</annotation></semantics></math> represents the noise schedule. As <math alttext="t\in{1,2,...,\mathcal{T}}" class="ltx_Math" display="inline" id="S3.SS1.p1.3.m2.4"><semantics id="S3.SS1.p1.3.m2.4a"><mrow id="S3.SS1.p1.3.m2.4.5" xref="S3.SS1.p1.3.m2.4.5.cmml"><mi id="S3.SS1.p1.3.m2.4.5.2" xref="S3.SS1.p1.3.m2.4.5.2.cmml">t</mi><mo id="S3.SS1.p1.3.m2.4.5.1" xref="S3.SS1.p1.3.m2.4.5.1.cmml">∈</mo><mrow id="S3.SS1.p1.3.m2.4.5.3.2" xref="S3.SS1.p1.3.m2.4.5.3.1.cmml"><mn id="S3.SS1.p1.3.m2.1.1" xref="S3.SS1.p1.3.m2.1.1.cmml">1</mn><mo id="S3.SS1.p1.3.m2.4.5.3.2.1" xref="S3.SS1.p1.3.m2.4.5.3.1.cmml">,</mo><mn id="S3.SS1.p1.3.m2.2.2" xref="S3.SS1.p1.3.m2.2.2.cmml">2</mn><mo id="S3.SS1.p1.3.m2.4.5.3.2.2" xref="S3.SS1.p1.3.m2.4.5.3.1.cmml">,</mo><mi id="S3.SS1.p1.3.m2.3.3" mathvariant="normal" xref="S3.SS1.p1.3.m2.3.3.cmml">…</mi><mo id="S3.SS1.p1.3.m2.4.5.3.2.3" xref="S3.SS1.p1.3.m2.4.5.3.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.3.m2.4.4" xref="S3.SS1.p1.3.m2.4.4.cmml">𝒯</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m2.4b"><apply id="S3.SS1.p1.3.m2.4.5.cmml" xref="S3.SS1.p1.3.m2.4.5"><in id="S3.SS1.p1.3.m2.4.5.1.cmml" xref="S3.SS1.p1.3.m2.4.5.1"></in><ci id="S3.SS1.p1.3.m2.4.5.2.cmml" xref="S3.SS1.p1.3.m2.4.5.2">𝑡</ci><list id="S3.SS1.p1.3.m2.4.5.3.1.cmml" xref="S3.SS1.p1.3.m2.4.5.3.2"><cn id="S3.SS1.p1.3.m2.1.1.cmml" type="integer" xref="S3.SS1.p1.3.m2.1.1">1</cn><cn id="S3.SS1.p1.3.m2.2.2.cmml" type="integer" xref="S3.SS1.p1.3.m2.2.2">2</cn><ci id="S3.SS1.p1.3.m2.3.3.cmml" xref="S3.SS1.p1.3.m2.3.3">…</ci><ci id="S3.SS1.p1.3.m2.4.4.cmml" xref="S3.SS1.p1.3.m2.4.4">𝒯</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m2.4c">t\in{1,2,...,\mathcal{T}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.3.m2.4d">italic_t ∈ 1 , 2 , … , caligraphic_T</annotation></semantics></math> increases, the cumulative noise applied to the original <math alttext="\mathbf{z}_{0}" class="ltx_Math" display="inline" id="S3.SS1.p1.4.m3.1"><semantics id="S3.SS1.p1.4.m3.1a"><msub id="S3.SS1.p1.4.m3.1.1" xref="S3.SS1.p1.4.m3.1.1.cmml"><mi id="S3.SS1.p1.4.m3.1.1.2" xref="S3.SS1.p1.4.m3.1.1.2.cmml">𝐳</mi><mn id="S3.SS1.p1.4.m3.1.1.3" xref="S3.SS1.p1.4.m3.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m3.1b"><apply id="S3.SS1.p1.4.m3.1.1.cmml" xref="S3.SS1.p1.4.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m3.1.1.1.cmml" xref="S3.SS1.p1.4.m3.1.1">subscript</csymbol><ci id="S3.SS1.p1.4.m3.1.1.2.cmml" xref="S3.SS1.p1.4.m3.1.1.2">𝐳</ci><cn id="S3.SS1.p1.4.m3.1.1.3.cmml" type="integer" xref="S3.SS1.p1.4.m3.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m3.1c">\mathbf{z}_{0}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.4.m3.1d">bold_z start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math> intensifies, causing <math alttext="\mathbf{z}_{t}" class="ltx_Math" display="inline" id="S3.SS1.p1.5.m4.1"><semantics id="S3.SS1.p1.5.m4.1a"><msub id="S3.SS1.p1.5.m4.1.1" xref="S3.SS1.p1.5.m4.1.1.cmml"><mi id="S3.SS1.p1.5.m4.1.1.2" xref="S3.SS1.p1.5.m4.1.1.2.cmml">𝐳</mi><mi id="S3.SS1.p1.5.m4.1.1.3" xref="S3.SS1.p1.5.m4.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m4.1b"><apply id="S3.SS1.p1.5.m4.1.1.cmml" xref="S3.SS1.p1.5.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m4.1.1.1.cmml" xref="S3.SS1.p1.5.m4.1.1">subscript</csymbol><ci id="S3.SS1.p1.5.m4.1.1.2.cmml" xref="S3.SS1.p1.5.m4.1.1.2">𝐳</ci><ci id="S3.SS1.p1.5.m4.1.1.3.cmml" xref="S3.SS1.p1.5.m4.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m4.1c">\mathbf{z}_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.5.m4.1d">bold_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> to progressively resemble random Gaussian noise.
Compared to the forward diffusion process, the reverse denoising process <math alttext="p_{\theta}" class="ltx_Math" display="inline" id="S3.SS1.p1.6.m5.1"><semantics id="S3.SS1.p1.6.m5.1a"><msub id="S3.SS1.p1.6.m5.1.1" xref="S3.SS1.p1.6.m5.1.1.cmml"><mi id="S3.SS1.p1.6.m5.1.1.2" xref="S3.SS1.p1.6.m5.1.1.2.cmml">p</mi><mi id="S3.SS1.p1.6.m5.1.1.3" xref="S3.SS1.p1.6.m5.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m5.1b"><apply id="S3.SS1.p1.6.m5.1.1.cmml" xref="S3.SS1.p1.6.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.6.m5.1.1.1.cmml" xref="S3.SS1.p1.6.m5.1.1">subscript</csymbol><ci id="S3.SS1.p1.6.m5.1.1.2.cmml" xref="S3.SS1.p1.6.m5.1.1.2">𝑝</ci><ci id="S3.SS1.p1.6.m5.1.1.3.cmml" xref="S3.SS1.p1.6.m5.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m5.1c">p_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.6.m5.1d">italic_p start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math> aims to reconstruct the clean sample <math alttext="\mathbf{z}_{0}" class="ltx_Math" display="inline" id="S3.SS1.p1.7.m6.1"><semantics id="S3.SS1.p1.7.m6.1a"><msub id="S3.SS1.p1.7.m6.1.1" xref="S3.SS1.p1.7.m6.1.1.cmml"><mi id="S3.SS1.p1.7.m6.1.1.2" xref="S3.SS1.p1.7.m6.1.1.2.cmml">𝐳</mi><mn id="S3.SS1.p1.7.m6.1.1.3" xref="S3.SS1.p1.7.m6.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.7.m6.1b"><apply id="S3.SS1.p1.7.m6.1.1.cmml" xref="S3.SS1.p1.7.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.7.m6.1.1.1.cmml" xref="S3.SS1.p1.7.m6.1.1">subscript</csymbol><ci id="S3.SS1.p1.7.m6.1.1.2.cmml" xref="S3.SS1.p1.7.m6.1.1.2">𝐳</ci><cn id="S3.SS1.p1.7.m6.1.1.3.cmml" type="integer" xref="S3.SS1.p1.7.m6.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.7.m6.1c">\mathbf{z}_{0}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.7.m6.1d">bold_z start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math> from the noisy input <math alttext="\mathbf{z}_{t}" class="ltx_Math" display="inline" id="S3.SS1.p1.8.m7.1"><semantics id="S3.SS1.p1.8.m7.1a"><msub id="S3.SS1.p1.8.m7.1.1" xref="S3.SS1.p1.8.m7.1.1.cmml"><mi id="S3.SS1.p1.8.m7.1.1.2" xref="S3.SS1.p1.8.m7.1.1.2.cmml">𝐳</mi><mi id="S3.SS1.p1.8.m7.1.1.3" xref="S3.SS1.p1.8.m7.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.8.m7.1b"><apply id="S3.SS1.p1.8.m7.1.1.cmml" xref="S3.SS1.p1.8.m7.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.8.m7.1.1.1.cmml" xref="S3.SS1.p1.8.m7.1.1">subscript</csymbol><ci id="S3.SS1.p1.8.m7.1.1.2.cmml" xref="S3.SS1.p1.8.m7.1.1.2">𝐳</ci><ci id="S3.SS1.p1.8.m7.1.1.3.cmml" xref="S3.SS1.p1.8.m7.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.8.m7.1c">\mathbf{z}_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.8.m7.1d">bold_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math>. We represent the denoising step <math alttext="p(\mathbf{z}{t-1}|\mathbf{z}t)" class="ltx_Math" display="inline" id="S3.SS1.p1.9.m8.1"><semantics id="S3.SS1.p1.9.m8.1a"><mrow id="S3.SS1.p1.9.m8.1.1" xref="S3.SS1.p1.9.m8.1.1.cmml"><mi id="S3.SS1.p1.9.m8.1.1.3" xref="S3.SS1.p1.9.m8.1.1.3.cmml">p</mi><mo id="S3.SS1.p1.9.m8.1.1.2" xref="S3.SS1.p1.9.m8.1.1.2.cmml">⁢</mo><mrow id="S3.SS1.p1.9.m8.1.1.1.1" xref="S3.SS1.p1.9.m8.1.1.1.1.1.cmml"><mo id="S3.SS1.p1.9.m8.1.1.1.1.2" stretchy="false" xref="S3.SS1.p1.9.m8.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS1.p1.9.m8.1.1.1.1.1" xref="S3.SS1.p1.9.m8.1.1.1.1.1.cmml"><mrow id="S3.SS1.p1.9.m8.1.1.1.1.1.2" xref="S3.SS1.p1.9.m8.1.1.1.1.1.2.cmml"><mi id="S3.SS1.p1.9.m8.1.1.1.1.1.2.2" xref="S3.SS1.p1.9.m8.1.1.1.1.1.2.2.cmml">𝐳</mi><mo id="S3.SS1.p1.9.m8.1.1.1.1.1.2.1" xref="S3.SS1.p1.9.m8.1.1.1.1.1.2.1.cmml">⁢</mo><mi id="S3.SS1.p1.9.m8.1.1.1.1.1.2.3" xref="S3.SS1.p1.9.m8.1.1.1.1.1.2.3.cmml">t</mi></mrow><mo id="S3.SS1.p1.9.m8.1.1.1.1.1.1" xref="S3.SS1.p1.9.m8.1.1.1.1.1.1.cmml">−</mo><mrow id="S3.SS1.p1.9.m8.1.1.1.1.1.3" xref="S3.SS1.p1.9.m8.1.1.1.1.1.3.cmml"><mn id="S3.SS1.p1.9.m8.1.1.1.1.1.3.2" xref="S3.SS1.p1.9.m8.1.1.1.1.1.3.2.cmml">1</mn><mo fence="false" id="S3.SS1.p1.9.m8.1.1.1.1.1.3.1" xref="S3.SS1.p1.9.m8.1.1.1.1.1.3.1.cmml">|</mo><mrow id="S3.SS1.p1.9.m8.1.1.1.1.1.3.3" xref="S3.SS1.p1.9.m8.1.1.1.1.1.3.3.cmml"><mi id="S3.SS1.p1.9.m8.1.1.1.1.1.3.3.2" xref="S3.SS1.p1.9.m8.1.1.1.1.1.3.3.2.cmml">𝐳</mi><mo id="S3.SS1.p1.9.m8.1.1.1.1.1.3.3.1" xref="S3.SS1.p1.9.m8.1.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="S3.SS1.p1.9.m8.1.1.1.1.1.3.3.3" xref="S3.SS1.p1.9.m8.1.1.1.1.1.3.3.3.cmml">t</mi></mrow></mrow></mrow><mo id="S3.SS1.p1.9.m8.1.1.1.1.3" stretchy="false" xref="S3.SS1.p1.9.m8.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.9.m8.1b"><apply id="S3.SS1.p1.9.m8.1.1.cmml" xref="S3.SS1.p1.9.m8.1.1"><times id="S3.SS1.p1.9.m8.1.1.2.cmml" xref="S3.SS1.p1.9.m8.1.1.2"></times><ci id="S3.SS1.p1.9.m8.1.1.3.cmml" xref="S3.SS1.p1.9.m8.1.1.3">𝑝</ci><apply id="S3.SS1.p1.9.m8.1.1.1.1.1.cmml" xref="S3.SS1.p1.9.m8.1.1.1.1"><minus id="S3.SS1.p1.9.m8.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.9.m8.1.1.1.1.1.1"></minus><apply id="S3.SS1.p1.9.m8.1.1.1.1.1.2.cmml" xref="S3.SS1.p1.9.m8.1.1.1.1.1.2"><times id="S3.SS1.p1.9.m8.1.1.1.1.1.2.1.cmml" xref="S3.SS1.p1.9.m8.1.1.1.1.1.2.1"></times><ci id="S3.SS1.p1.9.m8.1.1.1.1.1.2.2.cmml" xref="S3.SS1.p1.9.m8.1.1.1.1.1.2.2">𝐳</ci><ci id="S3.SS1.p1.9.m8.1.1.1.1.1.2.3.cmml" xref="S3.SS1.p1.9.m8.1.1.1.1.1.2.3">𝑡</ci></apply><apply id="S3.SS1.p1.9.m8.1.1.1.1.1.3.cmml" xref="S3.SS1.p1.9.m8.1.1.1.1.1.3"><csymbol cd="latexml" id="S3.SS1.p1.9.m8.1.1.1.1.1.3.1.cmml" xref="S3.SS1.p1.9.m8.1.1.1.1.1.3.1">conditional</csymbol><cn id="S3.SS1.p1.9.m8.1.1.1.1.1.3.2.cmml" type="integer" xref="S3.SS1.p1.9.m8.1.1.1.1.1.3.2">1</cn><apply id="S3.SS1.p1.9.m8.1.1.1.1.1.3.3.cmml" xref="S3.SS1.p1.9.m8.1.1.1.1.1.3.3"><times id="S3.SS1.p1.9.m8.1.1.1.1.1.3.3.1.cmml" xref="S3.SS1.p1.9.m8.1.1.1.1.1.3.3.1"></times><ci id="S3.SS1.p1.9.m8.1.1.1.1.1.3.3.2.cmml" xref="S3.SS1.p1.9.m8.1.1.1.1.1.3.3.2">𝐳</ci><ci id="S3.SS1.p1.9.m8.1.1.1.1.1.3.3.3.cmml" xref="S3.SS1.p1.9.m8.1.1.1.1.1.3.3.3">𝑡</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.9.m8.1c">p(\mathbf{z}{t-1}|\mathbf{z}t)</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.9.m8.1d">italic_p ( bold_z italic_t - 1 | bold_z italic_t )</annotation></semantics></math> as follows:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S3.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="p_{\theta}(\mathbf{z}_{t-1}|\mathbf{z}_{t})=\mathcal{N}(\mathbf{z}_{t-1};\bm{%
\mu}_{\theta}(\mathbf{z}_{t},t),\bm{\Sigma}_{\theta}(\mathbf{z}_{t},t))," class="ltx_Math" display="block" id="S3.E2.m1.3"><semantics id="S3.E2.m1.3a"><mrow id="S3.E2.m1.3.3.1" xref="S3.E2.m1.3.3.1.1.cmml"><mrow id="S3.E2.m1.3.3.1.1" xref="S3.E2.m1.3.3.1.1.cmml"><mrow id="S3.E2.m1.3.3.1.1.1" xref="S3.E2.m1.3.3.1.1.1.cmml"><msub id="S3.E2.m1.3.3.1.1.1.3" xref="S3.E2.m1.3.3.1.1.1.3.cmml"><mi id="S3.E2.m1.3.3.1.1.1.3.2" xref="S3.E2.m1.3.3.1.1.1.3.2.cmml">p</mi><mi id="S3.E2.m1.3.3.1.1.1.3.3" xref="S3.E2.m1.3.3.1.1.1.3.3.cmml">θ</mi></msub><mo id="S3.E2.m1.3.3.1.1.1.2" xref="S3.E2.m1.3.3.1.1.1.2.cmml">⁢</mo><mrow id="S3.E2.m1.3.3.1.1.1.1.1" xref="S3.E2.m1.3.3.1.1.1.1.1.1.cmml"><mo id="S3.E2.m1.3.3.1.1.1.1.1.2" stretchy="false" xref="S3.E2.m1.3.3.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.3.3.1.1.1.1.1.1" xref="S3.E2.m1.3.3.1.1.1.1.1.1.cmml"><msub id="S3.E2.m1.3.3.1.1.1.1.1.1.2" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.cmml"><mi id="S3.E2.m1.3.3.1.1.1.1.1.1.2.2" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.2.cmml">𝐳</mi><mrow id="S3.E2.m1.3.3.1.1.1.1.1.1.2.3" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.3.cmml"><mi id="S3.E2.m1.3.3.1.1.1.1.1.1.2.3.2" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.3.2.cmml">t</mi><mo id="S3.E2.m1.3.3.1.1.1.1.1.1.2.3.1" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.3.1.cmml">−</mo><mn id="S3.E2.m1.3.3.1.1.1.1.1.1.2.3.3" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.3.3.cmml">1</mn></mrow></msub><mo fence="false" id="S3.E2.m1.3.3.1.1.1.1.1.1.1" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.cmml">|</mo><msub id="S3.E2.m1.3.3.1.1.1.1.1.1.3" xref="S3.E2.m1.3.3.1.1.1.1.1.1.3.cmml"><mi id="S3.E2.m1.3.3.1.1.1.1.1.1.3.2" xref="S3.E2.m1.3.3.1.1.1.1.1.1.3.2.cmml">𝐳</mi><mi id="S3.E2.m1.3.3.1.1.1.1.1.1.3.3" xref="S3.E2.m1.3.3.1.1.1.1.1.1.3.3.cmml">t</mi></msub></mrow><mo id="S3.E2.m1.3.3.1.1.1.1.1.3" stretchy="false" xref="S3.E2.m1.3.3.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.3.3.1.1.5" xref="S3.E2.m1.3.3.1.1.5.cmml">=</mo><mrow id="S3.E2.m1.3.3.1.1.4" xref="S3.E2.m1.3.3.1.1.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.3.3.1.1.4.5" xref="S3.E2.m1.3.3.1.1.4.5.cmml">𝒩</mi><mo id="S3.E2.m1.3.3.1.1.4.4" xref="S3.E2.m1.3.3.1.1.4.4.cmml">⁢</mo><mrow id="S3.E2.m1.3.3.1.1.4.3.3" xref="S3.E2.m1.3.3.1.1.4.3.4.cmml"><mo id="S3.E2.m1.3.3.1.1.4.3.3.4" stretchy="false" xref="S3.E2.m1.3.3.1.1.4.3.4.cmml">(</mo><msub id="S3.E2.m1.3.3.1.1.2.1.1.1" xref="S3.E2.m1.3.3.1.1.2.1.1.1.cmml"><mi id="S3.E2.m1.3.3.1.1.2.1.1.1.2" xref="S3.E2.m1.3.3.1.1.2.1.1.1.2.cmml">𝐳</mi><mrow id="S3.E2.m1.3.3.1.1.2.1.1.1.3" xref="S3.E2.m1.3.3.1.1.2.1.1.1.3.cmml"><mi id="S3.E2.m1.3.3.1.1.2.1.1.1.3.2" xref="S3.E2.m1.3.3.1.1.2.1.1.1.3.2.cmml">t</mi><mo id="S3.E2.m1.3.3.1.1.2.1.1.1.3.1" xref="S3.E2.m1.3.3.1.1.2.1.1.1.3.1.cmml">−</mo><mn id="S3.E2.m1.3.3.1.1.2.1.1.1.3.3" xref="S3.E2.m1.3.3.1.1.2.1.1.1.3.3.cmml">1</mn></mrow></msub><mo id="S3.E2.m1.3.3.1.1.4.3.3.5" xref="S3.E2.m1.3.3.1.1.4.3.4.cmml">;</mo><mrow id="S3.E2.m1.3.3.1.1.3.2.2.2" xref="S3.E2.m1.3.3.1.1.3.2.2.2.cmml"><msub id="S3.E2.m1.3.3.1.1.3.2.2.2.3" xref="S3.E2.m1.3.3.1.1.3.2.2.2.3.cmml"><mi id="S3.E2.m1.3.3.1.1.3.2.2.2.3.2" xref="S3.E2.m1.3.3.1.1.3.2.2.2.3.2.cmml">𝝁</mi><mi id="S3.E2.m1.3.3.1.1.3.2.2.2.3.3" xref="S3.E2.m1.3.3.1.1.3.2.2.2.3.3.cmml">θ</mi></msub><mo id="S3.E2.m1.3.3.1.1.3.2.2.2.2" xref="S3.E2.m1.3.3.1.1.3.2.2.2.2.cmml">⁢</mo><mrow id="S3.E2.m1.3.3.1.1.3.2.2.2.1.1" xref="S3.E2.m1.3.3.1.1.3.2.2.2.1.2.cmml"><mo id="S3.E2.m1.3.3.1.1.3.2.2.2.1.1.2" stretchy="false" xref="S3.E2.m1.3.3.1.1.3.2.2.2.1.2.cmml">(</mo><msub id="S3.E2.m1.3.3.1.1.3.2.2.2.1.1.1" xref="S3.E2.m1.3.3.1.1.3.2.2.2.1.1.1.cmml"><mi id="S3.E2.m1.3.3.1.1.3.2.2.2.1.1.1.2" xref="S3.E2.m1.3.3.1.1.3.2.2.2.1.1.1.2.cmml">𝐳</mi><mi id="S3.E2.m1.3.3.1.1.3.2.2.2.1.1.1.3" xref="S3.E2.m1.3.3.1.1.3.2.2.2.1.1.1.3.cmml">t</mi></msub><mo id="S3.E2.m1.3.3.1.1.3.2.2.2.1.1.3" xref="S3.E2.m1.3.3.1.1.3.2.2.2.1.2.cmml">,</mo><mi id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml">t</mi><mo id="S3.E2.m1.3.3.1.1.3.2.2.2.1.1.4" stretchy="false" xref="S3.E2.m1.3.3.1.1.3.2.2.2.1.2.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.3.3.1.1.4.3.3.6" xref="S3.E2.m1.3.3.1.1.4.3.4.cmml">,</mo><mrow id="S3.E2.m1.3.3.1.1.4.3.3.3" xref="S3.E2.m1.3.3.1.1.4.3.3.3.cmml"><msub id="S3.E2.m1.3.3.1.1.4.3.3.3.3" xref="S3.E2.m1.3.3.1.1.4.3.3.3.3.cmml"><mi id="S3.E2.m1.3.3.1.1.4.3.3.3.3.2" xref="S3.E2.m1.3.3.1.1.4.3.3.3.3.2.cmml">𝚺</mi><mi id="S3.E2.m1.3.3.1.1.4.3.3.3.3.3" xref="S3.E2.m1.3.3.1.1.4.3.3.3.3.3.cmml">θ</mi></msub><mo id="S3.E2.m1.3.3.1.1.4.3.3.3.2" xref="S3.E2.m1.3.3.1.1.4.3.3.3.2.cmml">⁢</mo><mrow id="S3.E2.m1.3.3.1.1.4.3.3.3.1.1" xref="S3.E2.m1.3.3.1.1.4.3.3.3.1.2.cmml"><mo id="S3.E2.m1.3.3.1.1.4.3.3.3.1.1.2" stretchy="false" xref="S3.E2.m1.3.3.1.1.4.3.3.3.1.2.cmml">(</mo><msub id="S3.E2.m1.3.3.1.1.4.3.3.3.1.1.1" xref="S3.E2.m1.3.3.1.1.4.3.3.3.1.1.1.cmml"><mi id="S3.E2.m1.3.3.1.1.4.3.3.3.1.1.1.2" xref="S3.E2.m1.3.3.1.1.4.3.3.3.1.1.1.2.cmml">𝐳</mi><mi id="S3.E2.m1.3.3.1.1.4.3.3.3.1.1.1.3" xref="S3.E2.m1.3.3.1.1.4.3.3.3.1.1.1.3.cmml">t</mi></msub><mo id="S3.E2.m1.3.3.1.1.4.3.3.3.1.1.3" xref="S3.E2.m1.3.3.1.1.4.3.3.3.1.2.cmml">,</mo><mi id="S3.E2.m1.2.2" xref="S3.E2.m1.2.2.cmml">t</mi><mo id="S3.E2.m1.3.3.1.1.4.3.3.3.1.1.4" stretchy="false" xref="S3.E2.m1.3.3.1.1.4.3.3.3.1.2.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.3.3.1.1.4.3.3.7" stretchy="false" xref="S3.E2.m1.3.3.1.1.4.3.4.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E2.m1.3.3.1.2" xref="S3.E2.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.3b"><apply id="S3.E2.m1.3.3.1.1.cmml" xref="S3.E2.m1.3.3.1"><eq id="S3.E2.m1.3.3.1.1.5.cmml" xref="S3.E2.m1.3.3.1.1.5"></eq><apply id="S3.E2.m1.3.3.1.1.1.cmml" xref="S3.E2.m1.3.3.1.1.1"><times id="S3.E2.m1.3.3.1.1.1.2.cmml" xref="S3.E2.m1.3.3.1.1.1.2"></times><apply id="S3.E2.m1.3.3.1.1.1.3.cmml" xref="S3.E2.m1.3.3.1.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.1.1.1.3.1.cmml" xref="S3.E2.m1.3.3.1.1.1.3">subscript</csymbol><ci id="S3.E2.m1.3.3.1.1.1.3.2.cmml" xref="S3.E2.m1.3.3.1.1.1.3.2">𝑝</ci><ci id="S3.E2.m1.3.3.1.1.1.3.3.cmml" xref="S3.E2.m1.3.3.1.1.1.3.3">𝜃</ci></apply><apply id="S3.E2.m1.3.3.1.1.1.1.1.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1"><csymbol cd="latexml" id="S3.E2.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1">conditional</csymbol><apply id="S3.E2.m1.3.3.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.1.1.1.1.1.1.2.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E2.m1.3.3.1.1.1.1.1.1.2.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.2">𝐳</ci><apply id="S3.E2.m1.3.3.1.1.1.1.1.1.2.3.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.3"><minus id="S3.E2.m1.3.3.1.1.1.1.1.1.2.3.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.3.1"></minus><ci id="S3.E2.m1.3.3.1.1.1.1.1.1.2.3.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.3.2">𝑡</ci><cn id="S3.E2.m1.3.3.1.1.1.1.1.1.2.3.3.cmml" type="integer" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.3.3">1</cn></apply></apply><apply id="S3.E2.m1.3.3.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.1.1.1.1.1.1.3.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E2.m1.3.3.1.1.1.1.1.1.3.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.3.2">𝐳</ci><ci id="S3.E2.m1.3.3.1.1.1.1.1.1.3.3.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.3.3">𝑡</ci></apply></apply></apply><apply id="S3.E2.m1.3.3.1.1.4.cmml" xref="S3.E2.m1.3.3.1.1.4"><times id="S3.E2.m1.3.3.1.1.4.4.cmml" xref="S3.E2.m1.3.3.1.1.4.4"></times><ci id="S3.E2.m1.3.3.1.1.4.5.cmml" xref="S3.E2.m1.3.3.1.1.4.5">𝒩</ci><list id="S3.E2.m1.3.3.1.1.4.3.4.cmml" xref="S3.E2.m1.3.3.1.1.4.3.3"><apply id="S3.E2.m1.3.3.1.1.2.1.1.1.cmml" xref="S3.E2.m1.3.3.1.1.2.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.1.1.2.1.1.1.1.cmml" xref="S3.E2.m1.3.3.1.1.2.1.1.1">subscript</csymbol><ci id="S3.E2.m1.3.3.1.1.2.1.1.1.2.cmml" xref="S3.E2.m1.3.3.1.1.2.1.1.1.2">𝐳</ci><apply id="S3.E2.m1.3.3.1.1.2.1.1.1.3.cmml" xref="S3.E2.m1.3.3.1.1.2.1.1.1.3"><minus id="S3.E2.m1.3.3.1.1.2.1.1.1.3.1.cmml" xref="S3.E2.m1.3.3.1.1.2.1.1.1.3.1"></minus><ci id="S3.E2.m1.3.3.1.1.2.1.1.1.3.2.cmml" xref="S3.E2.m1.3.3.1.1.2.1.1.1.3.2">𝑡</ci><cn id="S3.E2.m1.3.3.1.1.2.1.1.1.3.3.cmml" type="integer" xref="S3.E2.m1.3.3.1.1.2.1.1.1.3.3">1</cn></apply></apply><apply id="S3.E2.m1.3.3.1.1.3.2.2.2.cmml" xref="S3.E2.m1.3.3.1.1.3.2.2.2"><times id="S3.E2.m1.3.3.1.1.3.2.2.2.2.cmml" xref="S3.E2.m1.3.3.1.1.3.2.2.2.2"></times><apply id="S3.E2.m1.3.3.1.1.3.2.2.2.3.cmml" xref="S3.E2.m1.3.3.1.1.3.2.2.2.3"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.1.1.3.2.2.2.3.1.cmml" xref="S3.E2.m1.3.3.1.1.3.2.2.2.3">subscript</csymbol><ci id="S3.E2.m1.3.3.1.1.3.2.2.2.3.2.cmml" xref="S3.E2.m1.3.3.1.1.3.2.2.2.3.2">𝝁</ci><ci id="S3.E2.m1.3.3.1.1.3.2.2.2.3.3.cmml" xref="S3.E2.m1.3.3.1.1.3.2.2.2.3.3">𝜃</ci></apply><interval closure="open" id="S3.E2.m1.3.3.1.1.3.2.2.2.1.2.cmml" xref="S3.E2.m1.3.3.1.1.3.2.2.2.1.1"><apply id="S3.E2.m1.3.3.1.1.3.2.2.2.1.1.1.cmml" xref="S3.E2.m1.3.3.1.1.3.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.1.1.3.2.2.2.1.1.1.1.cmml" xref="S3.E2.m1.3.3.1.1.3.2.2.2.1.1.1">subscript</csymbol><ci id="S3.E2.m1.3.3.1.1.3.2.2.2.1.1.1.2.cmml" xref="S3.E2.m1.3.3.1.1.3.2.2.2.1.1.1.2">𝐳</ci><ci id="S3.E2.m1.3.3.1.1.3.2.2.2.1.1.1.3.cmml" xref="S3.E2.m1.3.3.1.1.3.2.2.2.1.1.1.3">𝑡</ci></apply><ci id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1">𝑡</ci></interval></apply><apply id="S3.E2.m1.3.3.1.1.4.3.3.3.cmml" xref="S3.E2.m1.3.3.1.1.4.3.3.3"><times id="S3.E2.m1.3.3.1.1.4.3.3.3.2.cmml" xref="S3.E2.m1.3.3.1.1.4.3.3.3.2"></times><apply id="S3.E2.m1.3.3.1.1.4.3.3.3.3.cmml" xref="S3.E2.m1.3.3.1.1.4.3.3.3.3"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.1.1.4.3.3.3.3.1.cmml" xref="S3.E2.m1.3.3.1.1.4.3.3.3.3">subscript</csymbol><ci id="S3.E2.m1.3.3.1.1.4.3.3.3.3.2.cmml" xref="S3.E2.m1.3.3.1.1.4.3.3.3.3.2">𝚺</ci><ci id="S3.E2.m1.3.3.1.1.4.3.3.3.3.3.cmml" xref="S3.E2.m1.3.3.1.1.4.3.3.3.3.3">𝜃</ci></apply><interval closure="open" id="S3.E2.m1.3.3.1.1.4.3.3.3.1.2.cmml" xref="S3.E2.m1.3.3.1.1.4.3.3.3.1.1"><apply id="S3.E2.m1.3.3.1.1.4.3.3.3.1.1.1.cmml" xref="S3.E2.m1.3.3.1.1.4.3.3.3.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.1.1.4.3.3.3.1.1.1.1.cmml" xref="S3.E2.m1.3.3.1.1.4.3.3.3.1.1.1">subscript</csymbol><ci id="S3.E2.m1.3.3.1.1.4.3.3.3.1.1.1.2.cmml" xref="S3.E2.m1.3.3.1.1.4.3.3.3.1.1.1.2">𝐳</ci><ci id="S3.E2.m1.3.3.1.1.4.3.3.3.1.1.1.3.cmml" xref="S3.E2.m1.3.3.1.1.4.3.3.3.1.1.1.3">𝑡</ci></apply><ci id="S3.E2.m1.2.2.cmml" xref="S3.E2.m1.2.2">𝑡</ci></interval></apply></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.3c">p_{\theta}(\mathbf{z}_{t-1}|\mathbf{z}_{t})=\mathcal{N}(\mathbf{z}_{t-1};\bm{%
\mu}_{\theta}(\mathbf{z}_{t},t),\bm{\Sigma}_{\theta}(\mathbf{z}_{t},t)),</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.3d">italic_p start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( bold_z start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT | bold_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) = caligraphic_N ( bold_z start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT ; bold_italic_μ start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( bold_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_t ) , bold_Σ start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( bold_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_t ) ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.p1.14">in which <math alttext="\bm{\mu}_{\theta}(\mathbf{z}_{t},t)" class="ltx_Math" display="inline" id="S3.SS1.p1.10.m1.2"><semantics id="S3.SS1.p1.10.m1.2a"><mrow id="S3.SS1.p1.10.m1.2.2" xref="S3.SS1.p1.10.m1.2.2.cmml"><msub id="S3.SS1.p1.10.m1.2.2.3" xref="S3.SS1.p1.10.m1.2.2.3.cmml"><mi id="S3.SS1.p1.10.m1.2.2.3.2" xref="S3.SS1.p1.10.m1.2.2.3.2.cmml">𝝁</mi><mi id="S3.SS1.p1.10.m1.2.2.3.3" xref="S3.SS1.p1.10.m1.2.2.3.3.cmml">θ</mi></msub><mo id="S3.SS1.p1.10.m1.2.2.2" xref="S3.SS1.p1.10.m1.2.2.2.cmml">⁢</mo><mrow id="S3.SS1.p1.10.m1.2.2.1.1" xref="S3.SS1.p1.10.m1.2.2.1.2.cmml"><mo id="S3.SS1.p1.10.m1.2.2.1.1.2" stretchy="false" xref="S3.SS1.p1.10.m1.2.2.1.2.cmml">(</mo><msub id="S3.SS1.p1.10.m1.2.2.1.1.1" xref="S3.SS1.p1.10.m1.2.2.1.1.1.cmml"><mi id="S3.SS1.p1.10.m1.2.2.1.1.1.2" xref="S3.SS1.p1.10.m1.2.2.1.1.1.2.cmml">𝐳</mi><mi id="S3.SS1.p1.10.m1.2.2.1.1.1.3" xref="S3.SS1.p1.10.m1.2.2.1.1.1.3.cmml">t</mi></msub><mo id="S3.SS1.p1.10.m1.2.2.1.1.3" xref="S3.SS1.p1.10.m1.2.2.1.2.cmml">,</mo><mi id="S3.SS1.p1.10.m1.1.1" xref="S3.SS1.p1.10.m1.1.1.cmml">t</mi><mo id="S3.SS1.p1.10.m1.2.2.1.1.4" stretchy="false" xref="S3.SS1.p1.10.m1.2.2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.10.m1.2b"><apply id="S3.SS1.p1.10.m1.2.2.cmml" xref="S3.SS1.p1.10.m1.2.2"><times id="S3.SS1.p1.10.m1.2.2.2.cmml" xref="S3.SS1.p1.10.m1.2.2.2"></times><apply id="S3.SS1.p1.10.m1.2.2.3.cmml" xref="S3.SS1.p1.10.m1.2.2.3"><csymbol cd="ambiguous" id="S3.SS1.p1.10.m1.2.2.3.1.cmml" xref="S3.SS1.p1.10.m1.2.2.3">subscript</csymbol><ci id="S3.SS1.p1.10.m1.2.2.3.2.cmml" xref="S3.SS1.p1.10.m1.2.2.3.2">𝝁</ci><ci id="S3.SS1.p1.10.m1.2.2.3.3.cmml" xref="S3.SS1.p1.10.m1.2.2.3.3">𝜃</ci></apply><interval closure="open" id="S3.SS1.p1.10.m1.2.2.1.2.cmml" xref="S3.SS1.p1.10.m1.2.2.1.1"><apply id="S3.SS1.p1.10.m1.2.2.1.1.1.cmml" xref="S3.SS1.p1.10.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.10.m1.2.2.1.1.1.1.cmml" xref="S3.SS1.p1.10.m1.2.2.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.10.m1.2.2.1.1.1.2.cmml" xref="S3.SS1.p1.10.m1.2.2.1.1.1.2">𝐳</ci><ci id="S3.SS1.p1.10.m1.2.2.1.1.1.3.cmml" xref="S3.SS1.p1.10.m1.2.2.1.1.1.3">𝑡</ci></apply><ci id="S3.SS1.p1.10.m1.1.1.cmml" xref="S3.SS1.p1.10.m1.1.1">𝑡</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.10.m1.2c">\bm{\mu}_{\theta}(\mathbf{z}_{t},t)</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.10.m1.2d">bold_italic_μ start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( bold_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_t )</annotation></semantics></math> refers to the estimated target of the reverse diffusion process and the process typically is achieved by a diffusion model <math alttext="\bm{\epsilon}_{\theta}" class="ltx_Math" display="inline" id="S3.SS1.p1.11.m2.1"><semantics id="S3.SS1.p1.11.m2.1a"><msub id="S3.SS1.p1.11.m2.1.1" xref="S3.SS1.p1.11.m2.1.1.cmml"><mi class="ltx_mathvariant_bold-italic" id="S3.SS1.p1.11.m2.1.1.2" mathvariant="bold-italic" xref="S3.SS1.p1.11.m2.1.1.2.cmml">ϵ</mi><mi id="S3.SS1.p1.11.m2.1.1.3" xref="S3.SS1.p1.11.m2.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.11.m2.1b"><apply id="S3.SS1.p1.11.m2.1.1.cmml" xref="S3.SS1.p1.11.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.11.m2.1.1.1.cmml" xref="S3.SS1.p1.11.m2.1.1">subscript</csymbol><ci id="S3.SS1.p1.11.m2.1.1.2.cmml" xref="S3.SS1.p1.11.m2.1.1.2">bold-italic-ϵ</ci><ci id="S3.SS1.p1.11.m2.1.1.3.cmml" xref="S3.SS1.p1.11.m2.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.11.m2.1c">\bm{\epsilon}_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.11.m2.1d">bold_italic_ϵ start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math> with the parameters <math alttext="\theta" class="ltx_Math" display="inline" id="S3.SS1.p1.12.m3.1"><semantics id="S3.SS1.p1.12.m3.1a"><mi id="S3.SS1.p1.12.m3.1.1" xref="S3.SS1.p1.12.m3.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.12.m3.1b"><ci id="S3.SS1.p1.12.m3.1.1.cmml" xref="S3.SS1.p1.12.m3.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.12.m3.1c">\theta</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.12.m3.1d">italic_θ</annotation></semantics></math>.
To model the temporal dimension, the denoising model <math alttext="\bm{\epsilon}_{\theta}" class="ltx_Math" display="inline" id="S3.SS1.p1.13.m4.1"><semantics id="S3.SS1.p1.13.m4.1a"><msub id="S3.SS1.p1.13.m4.1.1" xref="S3.SS1.p1.13.m4.1.1.cmml"><mi class="ltx_mathvariant_bold-italic" id="S3.SS1.p1.13.m4.1.1.2" mathvariant="bold-italic" xref="S3.SS1.p1.13.m4.1.1.2.cmml">ϵ</mi><mi id="S3.SS1.p1.13.m4.1.1.3" xref="S3.SS1.p1.13.m4.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.13.m4.1b"><apply id="S3.SS1.p1.13.m4.1.1.cmml" xref="S3.SS1.p1.13.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.13.m4.1.1.1.cmml" xref="S3.SS1.p1.13.m4.1.1">subscript</csymbol><ci id="S3.SS1.p1.13.m4.1.1.2.cmml" xref="S3.SS1.p1.13.m4.1.1.2">bold-italic-ϵ</ci><ci id="S3.SS1.p1.13.m4.1.1.3.cmml" xref="S3.SS1.p1.13.m4.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.13.m4.1c">\bm{\epsilon}_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.13.m4.1d">bold_italic_ϵ start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math> is commonly built on a 3D-UNet architecture&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Blattmann et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib5" title="">2023</a>)</cite> in video generation methods&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Hu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib21" title="">2023</a>); Wang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib60" title="">2023c</a>)</cite>. Given the input conditional guidance <math alttext="c" class="ltx_Math" display="inline" id="S3.SS1.p1.14.m5.1"><semantics id="S3.SS1.p1.14.m5.1a"><mi id="S3.SS1.p1.14.m5.1.1" xref="S3.SS1.p1.14.m5.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.14.m5.1b"><ci id="S3.SS1.p1.14.m5.1.1.cmml" xref="S3.SS1.p1.14.m5.1.1">𝑐</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.14.m5.1c">c</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.14.m5.1d">italic_c</annotation></semantics></math>, they usually use an L2 loss to reduce the difference between the predicted noise and the ground-truth noise during the optimization process:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S3.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}=\mathbb{E}_{{\theta}}\Big{[}\|\bm{\epsilon}-\bm{\epsilon}_{\theta}%
(\mathbf{z}_{t},t,c)\|^{2}\Big{]}" class="ltx_Math" display="block" id="S3.E3.m1.3"><semantics id="S3.E3.m1.3a"><mrow id="S3.E3.m1.3.3" xref="S3.E3.m1.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.3.3.3" xref="S3.E3.m1.3.3.3.cmml">ℒ</mi><mo id="S3.E3.m1.3.3.2" xref="S3.E3.m1.3.3.2.cmml">=</mo><mrow id="S3.E3.m1.3.3.1" xref="S3.E3.m1.3.3.1.cmml"><msub id="S3.E3.m1.3.3.1.3" xref="S3.E3.m1.3.3.1.3.cmml"><mi id="S3.E3.m1.3.3.1.3.2" xref="S3.E3.m1.3.3.1.3.2.cmml">𝔼</mi><mi id="S3.E3.m1.3.3.1.3.3" xref="S3.E3.m1.3.3.1.3.3.cmml">θ</mi></msub><mo id="S3.E3.m1.3.3.1.2" xref="S3.E3.m1.3.3.1.2.cmml">⁢</mo><mrow id="S3.E3.m1.3.3.1.1.1" xref="S3.E3.m1.3.3.1.1.2.cmml"><mo id="S3.E3.m1.3.3.1.1.1.2" maxsize="160%" minsize="160%" xref="S3.E3.m1.3.3.1.1.2.1.cmml">[</mo><msup id="S3.E3.m1.3.3.1.1.1.1" xref="S3.E3.m1.3.3.1.1.1.1.cmml"><mrow id="S3.E3.m1.3.3.1.1.1.1.1.1" xref="S3.E3.m1.3.3.1.1.1.1.1.2.cmml"><mo id="S3.E3.m1.3.3.1.1.1.1.1.1.2" stretchy="false" xref="S3.E3.m1.3.3.1.1.1.1.1.2.1.cmml">‖</mo><mrow id="S3.E3.m1.3.3.1.1.1.1.1.1.1" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.cmml"><mi class="ltx_mathvariant_bold-italic" id="S3.E3.m1.3.3.1.1.1.1.1.1.1.3" mathvariant="bold-italic" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.3.cmml">ϵ</mi><mo id="S3.E3.m1.3.3.1.1.1.1.1.1.1.2" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.2.cmml">−</mo><mrow id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.cmml"><msub id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.cmml"><mi class="ltx_mathvariant_bold-italic" id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.2" mathvariant="bold-italic" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.2.cmml">ϵ</mi><mi id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3.cmml">θ</mi></msub><mo id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.2.cmml"><mo id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.2.cmml">(</mo><msub id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2.cmml">𝐳</mi><mi id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.2.cmml">,</mo><mi id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1.cmml">t</mi><mo id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.4" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.2.cmml">,</mo><mi id="S3.E3.m1.2.2" xref="S3.E3.m1.2.2.cmml">c</mi><mo id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.5" stretchy="false" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E3.m1.3.3.1.1.1.1.1.1.3" stretchy="false" xref="S3.E3.m1.3.3.1.1.1.1.1.2.1.cmml">‖</mo></mrow><mn id="S3.E3.m1.3.3.1.1.1.1.3" xref="S3.E3.m1.3.3.1.1.1.1.3.cmml">2</mn></msup><mo id="S3.E3.m1.3.3.1.1.1.3" maxsize="160%" minsize="160%" xref="S3.E3.m1.3.3.1.1.2.1.cmml">]</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.3b"><apply id="S3.E3.m1.3.3.cmml" xref="S3.E3.m1.3.3"><eq id="S3.E3.m1.3.3.2.cmml" xref="S3.E3.m1.3.3.2"></eq><ci id="S3.E3.m1.3.3.3.cmml" xref="S3.E3.m1.3.3.3">ℒ</ci><apply id="S3.E3.m1.3.3.1.cmml" xref="S3.E3.m1.3.3.1"><times id="S3.E3.m1.3.3.1.2.cmml" xref="S3.E3.m1.3.3.1.2"></times><apply id="S3.E3.m1.3.3.1.3.cmml" xref="S3.E3.m1.3.3.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.3.1.cmml" xref="S3.E3.m1.3.3.1.3">subscript</csymbol><ci id="S3.E3.m1.3.3.1.3.2.cmml" xref="S3.E3.m1.3.3.1.3.2">𝔼</ci><ci id="S3.E3.m1.3.3.1.3.3.cmml" xref="S3.E3.m1.3.3.1.3.3">𝜃</ci></apply><apply id="S3.E3.m1.3.3.1.1.2.cmml" xref="S3.E3.m1.3.3.1.1.1"><csymbol cd="latexml" id="S3.E3.m1.3.3.1.1.2.1.cmml" xref="S3.E3.m1.3.3.1.1.1.2">delimited-[]</csymbol><apply id="S3.E3.m1.3.3.1.1.1.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.1.1.1.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1">superscript</csymbol><apply id="S3.E3.m1.3.3.1.1.1.1.1.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E3.m1.3.3.1.1.1.1.1.2.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.2">norm</csymbol><apply id="S3.E3.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1"><minus id="S3.E3.m1.3.3.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.2"></minus><ci id="S3.E3.m1.3.3.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.3">bold-italic-ϵ</ci><apply id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1"><times id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.2"></times><apply id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.2">bold-italic-ϵ</ci><ci id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3">𝜃</ci></apply><vector id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1"><apply id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2">𝐳</ci><ci id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3">𝑡</ci></apply><ci id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1">𝑡</ci><ci id="S3.E3.m1.2.2.cmml" xref="S3.E3.m1.2.2">𝑐</ci></vector></apply></apply></apply><cn id="S3.E3.m1.3.3.1.1.1.1.3.cmml" type="integer" xref="S3.E3.m1.3.3.1.1.1.1.3">2</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.3c">\mathcal{L}=\mathbb{E}_{{\theta}}\Big{[}\|\bm{\epsilon}-\bm{\epsilon}_{\theta}%
(\mathbf{z}_{t},t,c)\|^{2}\Big{]}</annotation><annotation encoding="application/x-llamapun" id="S3.E3.m1.3d">caligraphic_L = blackboard_E start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT [ ∥ bold_italic_ϵ - bold_italic_ϵ start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( bold_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_t , italic_c ) ∥ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ]</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.p1.15">once the reversed denoising stage is complete, the predicted clean latent is passed through the VAE decoder to reconstruct the predicted video in pixel space.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Pose Indicator</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.2">To extract motion representations, previous works typically detect the pose keypoints via DWPose&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Yang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib71" title="">2023</a>)</cite> from the driven video <math alttext="I^{d}_{1:F}" class="ltx_Math" display="inline" id="S3.SS2.p1.1.m1.1"><semantics id="S3.SS2.p1.1.m1.1a"><msubsup id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml"><mi id="S3.SS2.p1.1.m1.1.1.2.2" xref="S3.SS2.p1.1.m1.1.1.2.2.cmml">I</mi><mrow id="S3.SS2.p1.1.m1.1.1.3" xref="S3.SS2.p1.1.m1.1.1.3.cmml"><mn id="S3.SS2.p1.1.m1.1.1.3.2" xref="S3.SS2.p1.1.m1.1.1.3.2.cmml">1</mn><mo id="S3.SS2.p1.1.m1.1.1.3.1" lspace="0.278em" rspace="0.278em" xref="S3.SS2.p1.1.m1.1.1.3.1.cmml">:</mo><mi id="S3.SS2.p1.1.m1.1.1.3.3" xref="S3.SS2.p1.1.m1.1.1.3.3.cmml">F</mi></mrow><mi id="S3.SS2.p1.1.m1.1.1.2.3" xref="S3.SS2.p1.1.m1.1.1.2.3.cmml">d</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><apply id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">subscript</csymbol><apply id="S3.SS2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.1.1.2.1.cmml" xref="S3.SS2.p1.1.m1.1.1">superscript</csymbol><ci id="S3.SS2.p1.1.m1.1.1.2.2.cmml" xref="S3.SS2.p1.1.m1.1.1.2.2">𝐼</ci><ci id="S3.SS2.p1.1.m1.1.1.2.3.cmml" xref="S3.SS2.p1.1.m1.1.1.2.3">𝑑</ci></apply><apply id="S3.SS2.p1.1.m1.1.1.3.cmml" xref="S3.SS2.p1.1.m1.1.1.3"><ci id="S3.SS2.p1.1.m1.1.1.3.1.cmml" xref="S3.SS2.p1.1.m1.1.1.3.1">:</ci><cn id="S3.SS2.p1.1.m1.1.1.3.2.cmml" type="integer" xref="S3.SS2.p1.1.m1.1.1.3.2">1</cn><ci id="S3.SS2.p1.1.m1.1.1.3.3.cmml" xref="S3.SS2.p1.1.m1.1.1.3.3">𝐹</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">I^{d}_{1:F}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.1.m1.1d">italic_I start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 : italic_F end_POSTSUBSCRIPT</annotation></semantics></math> and further visualize them as pose image <math alttext="I^{p}" class="ltx_Math" display="inline" id="S3.SS2.p1.2.m2.1"><semantics id="S3.SS2.p1.2.m2.1a"><msup id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml"><mi id="S3.SS2.p1.2.m2.1.1.2" xref="S3.SS2.p1.2.m2.1.1.2.cmml">I</mi><mi id="S3.SS2.p1.2.m2.1.1.3" xref="S3.SS2.p1.2.m2.1.1.3.cmml">p</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><apply id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.1.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">superscript</csymbol><ci id="S3.SS2.p1.2.m2.1.1.2.cmml" xref="S3.SS2.p1.2.m2.1.1.2">𝐼</ci><ci id="S3.SS2.p1.2.m2.1.1.3.cmml" xref="S3.SS2.p1.2.m2.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">I^{p}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.2.m2.1d">italic_I start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT</annotation></semantics></math>, which are trained using self-driven reconstruction strategy.
However, it brings several limitations as mentioned in Sec.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#S1" title="1 Introduction ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">1</span></a>: (1) The sole pose skeletons lack image-level details and are therefore unable to capture the essence of the reference video, such as motion-induced deformations and overall motion patterns. (2) The self-driven reconstruction training strategy naturally aligns the reference and pose images in terms of body shape, which simplifies the animation task by overlooking likely body shape differences between the reference image and the pose image during inference. Both limitations <span class="ltx_text" id="S3.SS2.p1.2.1" style="color:#000000;">weaken</span> the model to develop a deep, holistic motion understanding, leading to <span class="ltx_text ltx_font_bold" id="S3.SS2.p1.2.2">inadequate</span> motion representation. To address these issues, we propose Pose Indicator, which consists of Implicit Pose Indicator (IPI) and Explicit Pose Indicator (EPI).</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.15"><span class="ltx_text ltx_font_bold" id="S3.SS2.p2.15.1">Implicit Pose Indicator (IPI).</span>
To extract unified motion representations from the driving video in the first limitation, we resort to the CLIP image feature <math alttext="f^{d}_{\varphi}=\Phi(I^{d}_{1:F})" class="ltx_Math" display="inline" id="S3.SS2.p2.1.m1.1"><semantics id="S3.SS2.p2.1.m1.1a"><mrow id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml"><msubsup id="S3.SS2.p2.1.m1.1.1.3" xref="S3.SS2.p2.1.m1.1.1.3.cmml"><mi id="S3.SS2.p2.1.m1.1.1.3.2.2" xref="S3.SS2.p2.1.m1.1.1.3.2.2.cmml">f</mi><mi id="S3.SS2.p2.1.m1.1.1.3.3" xref="S3.SS2.p2.1.m1.1.1.3.3.cmml">φ</mi><mi id="S3.SS2.p2.1.m1.1.1.3.2.3" xref="S3.SS2.p2.1.m1.1.1.3.2.3.cmml">d</mi></msubsup><mo id="S3.SS2.p2.1.m1.1.1.2" xref="S3.SS2.p2.1.m1.1.1.2.cmml">=</mo><mrow id="S3.SS2.p2.1.m1.1.1.1" xref="S3.SS2.p2.1.m1.1.1.1.cmml"><mi id="S3.SS2.p2.1.m1.1.1.1.3" mathvariant="normal" xref="S3.SS2.p2.1.m1.1.1.1.3.cmml">Φ</mi><mo id="S3.SS2.p2.1.m1.1.1.1.2" xref="S3.SS2.p2.1.m1.1.1.1.2.cmml">⁢</mo><mrow id="S3.SS2.p2.1.m1.1.1.1.1.1" xref="S3.SS2.p2.1.m1.1.1.1.1.1.1.cmml"><mo id="S3.SS2.p2.1.m1.1.1.1.1.1.2" stretchy="false" xref="S3.SS2.p2.1.m1.1.1.1.1.1.1.cmml">(</mo><msubsup id="S3.SS2.p2.1.m1.1.1.1.1.1.1" xref="S3.SS2.p2.1.m1.1.1.1.1.1.1.cmml"><mi id="S3.SS2.p2.1.m1.1.1.1.1.1.1.2.2" xref="S3.SS2.p2.1.m1.1.1.1.1.1.1.2.2.cmml">I</mi><mrow id="S3.SS2.p2.1.m1.1.1.1.1.1.1.3" xref="S3.SS2.p2.1.m1.1.1.1.1.1.1.3.cmml"><mn id="S3.SS2.p2.1.m1.1.1.1.1.1.1.3.2" xref="S3.SS2.p2.1.m1.1.1.1.1.1.1.3.2.cmml">1</mn><mo id="S3.SS2.p2.1.m1.1.1.1.1.1.1.3.1" lspace="0.278em" rspace="0.278em" xref="S3.SS2.p2.1.m1.1.1.1.1.1.1.3.1.cmml">:</mo><mi id="S3.SS2.p2.1.m1.1.1.1.1.1.1.3.3" xref="S3.SS2.p2.1.m1.1.1.1.1.1.1.3.3.cmml">F</mi></mrow><mi id="S3.SS2.p2.1.m1.1.1.1.1.1.1.2.3" xref="S3.SS2.p2.1.m1.1.1.1.1.1.1.2.3.cmml">d</mi></msubsup><mo id="S3.SS2.p2.1.m1.1.1.1.1.1.3" stretchy="false" xref="S3.SS2.p2.1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><apply id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1"><eq id="S3.SS2.p2.1.m1.1.1.2.cmml" xref="S3.SS2.p2.1.m1.1.1.2"></eq><apply id="S3.SS2.p2.1.m1.1.1.3.cmml" xref="S3.SS2.p2.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.1.1.3.1.cmml" xref="S3.SS2.p2.1.m1.1.1.3">subscript</csymbol><apply id="S3.SS2.p2.1.m1.1.1.3.2.cmml" xref="S3.SS2.p2.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.1.1.3.2.1.cmml" xref="S3.SS2.p2.1.m1.1.1.3">superscript</csymbol><ci id="S3.SS2.p2.1.m1.1.1.3.2.2.cmml" xref="S3.SS2.p2.1.m1.1.1.3.2.2">𝑓</ci><ci id="S3.SS2.p2.1.m1.1.1.3.2.3.cmml" xref="S3.SS2.p2.1.m1.1.1.3.2.3">𝑑</ci></apply><ci id="S3.SS2.p2.1.m1.1.1.3.3.cmml" xref="S3.SS2.p2.1.m1.1.1.3.3">𝜑</ci></apply><apply id="S3.SS2.p2.1.m1.1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1.1"><times id="S3.SS2.p2.1.m1.1.1.1.2.cmml" xref="S3.SS2.p2.1.m1.1.1.1.2"></times><ci id="S3.SS2.p2.1.m1.1.1.1.3.cmml" xref="S3.SS2.p2.1.m1.1.1.1.3">Φ</ci><apply id="S3.SS2.p2.1.m1.1.1.1.1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.1.1.1.1.1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1.1.1.1">subscript</csymbol><apply id="S3.SS2.p2.1.m1.1.1.1.1.1.1.2.cmml" xref="S3.SS2.p2.1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.1.1.1.1.1.1.2.1.cmml" xref="S3.SS2.p2.1.m1.1.1.1.1.1">superscript</csymbol><ci id="S3.SS2.p2.1.m1.1.1.1.1.1.1.2.2.cmml" xref="S3.SS2.p2.1.m1.1.1.1.1.1.1.2.2">𝐼</ci><ci id="S3.SS2.p2.1.m1.1.1.1.1.1.1.2.3.cmml" xref="S3.SS2.p2.1.m1.1.1.1.1.1.1.2.3">𝑑</ci></apply><apply id="S3.SS2.p2.1.m1.1.1.1.1.1.1.3.cmml" xref="S3.SS2.p2.1.m1.1.1.1.1.1.1.3"><ci id="S3.SS2.p2.1.m1.1.1.1.1.1.1.3.1.cmml" xref="S3.SS2.p2.1.m1.1.1.1.1.1.1.3.1">:</ci><cn id="S3.SS2.p2.1.m1.1.1.1.1.1.1.3.2.cmml" type="integer" xref="S3.SS2.p2.1.m1.1.1.1.1.1.1.3.2">1</cn><ci id="S3.SS2.p2.1.m1.1.1.1.1.1.1.3.3.cmml" xref="S3.SS2.p2.1.m1.1.1.1.1.1.1.3.3">𝐹</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">f^{d}_{\varphi}=\Phi(I^{d}_{1:F})</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.1.m1.1d">italic_f start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_φ end_POSTSUBSCRIPT = roman_Φ ( italic_I start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 : italic_F end_POSTSUBSCRIPT )</annotation></semantics></math> extracted by a CLIP Image Encoder. CLIP utilizes contrastive learning to align the embeddings of related images and texts, which may include descriptions of appearance, movement, spatial relationships and etc. Therefore, the CLIP image feature is actually a highly entangled representation, containing motion patterns and relations helpful to animation generation.
As presented in Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#S2.F2" title="Figure 2 ‣ 2.2 Pose-guided character motion transfer ‣ 2 Related Work ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">2</span></a> (a), we introduce a lightweight extractor <math alttext="P" class="ltx_Math" display="inline" id="S3.SS2.p2.2.m2.1"><semantics id="S3.SS2.p2.2.m2.1a"><mi id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><ci id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">P</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.2.m2.1d">italic_P</annotation></semantics></math> which is composed of <math alttext="N" class="ltx_Math" display="inline" id="S3.SS2.p2.3.m3.1"><semantics id="S3.SS2.p2.3.m3.1a"><mi id="S3.SS2.p2.3.m3.1.1" xref="S3.SS2.p2.3.m3.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m3.1b"><ci id="S3.SS2.p2.3.m3.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m3.1c">N</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.3.m3.1d">italic_N</annotation></semantics></math> stacked layers of cross-attention and feed-forward networks (FFN). In cross attention layer, we employ <math alttext="f^{d}_{\varphi}" class="ltx_Math" display="inline" id="S3.SS2.p2.4.m4.1"><semantics id="S3.SS2.p2.4.m4.1a"><msubsup id="S3.SS2.p2.4.m4.1.1" xref="S3.SS2.p2.4.m4.1.1.cmml"><mi id="S3.SS2.p2.4.m4.1.1.2.2" xref="S3.SS2.p2.4.m4.1.1.2.2.cmml">f</mi><mi id="S3.SS2.p2.4.m4.1.1.3" xref="S3.SS2.p2.4.m4.1.1.3.cmml">φ</mi><mi id="S3.SS2.p2.4.m4.1.1.2.3" xref="S3.SS2.p2.4.m4.1.1.2.3.cmml">d</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.4.m4.1b"><apply id="S3.SS2.p2.4.m4.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.4.m4.1.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1">subscript</csymbol><apply id="S3.SS2.p2.4.m4.1.1.2.cmml" xref="S3.SS2.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.4.m4.1.1.2.1.cmml" xref="S3.SS2.p2.4.m4.1.1">superscript</csymbol><ci id="S3.SS2.p2.4.m4.1.1.2.2.cmml" xref="S3.SS2.p2.4.m4.1.1.2.2">𝑓</ci><ci id="S3.SS2.p2.4.m4.1.1.2.3.cmml" xref="S3.SS2.p2.4.m4.1.1.2.3">𝑑</ci></apply><ci id="S3.SS2.p2.4.m4.1.1.3.cmml" xref="S3.SS2.p2.4.m4.1.1.3">𝜑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.4.m4.1c">f^{d}_{\varphi}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.4.m4.1d">italic_f start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_φ end_POSTSUBSCRIPT</annotation></semantics></math> as the keys (<math alttext="{K}" class="ltx_Math" display="inline" id="S3.SS2.p2.5.m5.1"><semantics id="S3.SS2.p2.5.m5.1a"><mi id="S3.SS2.p2.5.m5.1.1" xref="S3.SS2.p2.5.m5.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.5.m5.1b"><ci id="S3.SS2.p2.5.m5.1.1.cmml" xref="S3.SS2.p2.5.m5.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.5.m5.1c">{K}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.5.m5.1d">italic_K</annotation></semantics></math>) and values (<math alttext="{V}" class="ltx_Math" display="inline" id="S3.SS2.p2.6.m6.1"><semantics id="S3.SS2.p2.6.m6.1a"><mi id="S3.SS2.p2.6.m6.1.1" xref="S3.SS2.p2.6.m6.1.1.cmml">V</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.6.m6.1b"><ci id="S3.SS2.p2.6.m6.1.1.cmml" xref="S3.SS2.p2.6.m6.1.1">𝑉</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.6.m6.1c">{V}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.6.m6.1d">italic_V</annotation></semantics></math>). Consequently, the challenge becomes designing an appropriate query (<math alttext="{Q}" class="ltx_Math" display="inline" id="S3.SS2.p2.7.m7.1"><semantics id="S3.SS2.p2.7.m7.1a"><mi id="S3.SS2.p2.7.m7.1.1" xref="S3.SS2.p2.7.m7.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.7.m7.1b"><ci id="S3.SS2.p2.7.m7.1.1.cmml" xref="S3.SS2.p2.7.m7.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.7.m7.1c">{Q}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.7.m7.1d">italic_Q</annotation></semantics></math>), which should act as a guidance for motion extraction. Considering that the keypoints <math alttext="p^{d}" class="ltx_Math" display="inline" id="S3.SS2.p2.8.m8.1"><semantics id="S3.SS2.p2.8.m8.1a"><msup id="S3.SS2.p2.8.m8.1.1" xref="S3.SS2.p2.8.m8.1.1.cmml"><mi id="S3.SS2.p2.8.m8.1.1.2" xref="S3.SS2.p2.8.m8.1.1.2.cmml">p</mi><mi id="S3.SS2.p2.8.m8.1.1.3" xref="S3.SS2.p2.8.m8.1.1.3.cmml">d</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.8.m8.1b"><apply id="S3.SS2.p2.8.m8.1.1.cmml" xref="S3.SS2.p2.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.8.m8.1.1.1.cmml" xref="S3.SS2.p2.8.m8.1.1">superscript</csymbol><ci id="S3.SS2.p2.8.m8.1.1.2.cmml" xref="S3.SS2.p2.8.m8.1.1.2">𝑝</ci><ci id="S3.SS2.p2.8.m8.1.1.3.cmml" xref="S3.SS2.p2.8.m8.1.1.3">𝑑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.8.m8.1c">p^{d}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.8.m8.1d">italic_p start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT</annotation></semantics></math> extracted by DWPose provide a direct description of the motion, we design a transformer-based encoder to obtain the embedding <math alttext="q_{p}" class="ltx_Math" display="inline" id="S3.SS2.p2.9.m9.1"><semantics id="S3.SS2.p2.9.m9.1a"><msub id="S3.SS2.p2.9.m9.1.1" xref="S3.SS2.p2.9.m9.1.1.cmml"><mi id="S3.SS2.p2.9.m9.1.1.2" xref="S3.SS2.p2.9.m9.1.1.2.cmml">q</mi><mi id="S3.SS2.p2.9.m9.1.1.3" xref="S3.SS2.p2.9.m9.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.9.m9.1b"><apply id="S3.SS2.p2.9.m9.1.1.cmml" xref="S3.SS2.p2.9.m9.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.9.m9.1.1.1.cmml" xref="S3.SS2.p2.9.m9.1.1">subscript</csymbol><ci id="S3.SS2.p2.9.m9.1.1.2.cmml" xref="S3.SS2.p2.9.m9.1.1.2">𝑞</ci><ci id="S3.SS2.p2.9.m9.1.1.3.cmml" xref="S3.SS2.p2.9.m9.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.9.m9.1c">q_{p}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.9.m9.1d">italic_q start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT</annotation></semantics></math>, which is regarded as an ideal candidate for <math alttext="{Q}" class="ltx_Math" display="inline" id="S3.SS2.p2.10.m10.1"><semantics id="S3.SS2.p2.10.m10.1a"><mi id="S3.SS2.p2.10.m10.1.1" xref="S3.SS2.p2.10.m10.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.10.m10.1b"><ci id="S3.SS2.p2.10.m10.1.1.cmml" xref="S3.SS2.p2.10.m10.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.10.m10.1c">{Q}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.10.m10.1d">italic_Q</annotation></semantics></math>.
Nevertheless, motion modeling using sole sparse keypoints is overly simplistic, resulting in the loss of underlying motion patterns.
To this end, we draw inspiration from query transformer architecture&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Awadalla et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib2" title="">2023</a>); Jaegle et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib23" title="">2021</a>)</cite> and initialize a learnable query vector <math alttext="q_{l}" class="ltx_Math" display="inline" id="S3.SS2.p2.11.m11.1"><semantics id="S3.SS2.p2.11.m11.1a"><msub id="S3.SS2.p2.11.m11.1.1" xref="S3.SS2.p2.11.m11.1.1.cmml"><mi id="S3.SS2.p2.11.m11.1.1.2" xref="S3.SS2.p2.11.m11.1.1.2.cmml">q</mi><mi id="S3.SS2.p2.11.m11.1.1.3" xref="S3.SS2.p2.11.m11.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.11.m11.1b"><apply id="S3.SS2.p2.11.m11.1.1.cmml" xref="S3.SS2.p2.11.m11.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.11.m11.1.1.1.cmml" xref="S3.SS2.p2.11.m11.1.1">subscript</csymbol><ci id="S3.SS2.p2.11.m11.1.1.2.cmml" xref="S3.SS2.p2.11.m11.1.1.2">𝑞</ci><ci id="S3.SS2.p2.11.m11.1.1.3.cmml" xref="S3.SS2.p2.11.m11.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.11.m11.1c">q_{l}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.11.m11.1d">italic_q start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT</annotation></semantics></math> to complement sparse keypoints.
Subsequently, we feed the merged query <math alttext="q_{m}=q_{p}+q_{l}" class="ltx_Math" display="inline" id="S3.SS2.p2.12.m12.1"><semantics id="S3.SS2.p2.12.m12.1a"><mrow id="S3.SS2.p2.12.m12.1.1" xref="S3.SS2.p2.12.m12.1.1.cmml"><msub id="S3.SS2.p2.12.m12.1.1.2" xref="S3.SS2.p2.12.m12.1.1.2.cmml"><mi id="S3.SS2.p2.12.m12.1.1.2.2" xref="S3.SS2.p2.12.m12.1.1.2.2.cmml">q</mi><mi id="S3.SS2.p2.12.m12.1.1.2.3" xref="S3.SS2.p2.12.m12.1.1.2.3.cmml">m</mi></msub><mo id="S3.SS2.p2.12.m12.1.1.1" xref="S3.SS2.p2.12.m12.1.1.1.cmml">=</mo><mrow id="S3.SS2.p2.12.m12.1.1.3" xref="S3.SS2.p2.12.m12.1.1.3.cmml"><msub id="S3.SS2.p2.12.m12.1.1.3.2" xref="S3.SS2.p2.12.m12.1.1.3.2.cmml"><mi id="S3.SS2.p2.12.m12.1.1.3.2.2" xref="S3.SS2.p2.12.m12.1.1.3.2.2.cmml">q</mi><mi id="S3.SS2.p2.12.m12.1.1.3.2.3" xref="S3.SS2.p2.12.m12.1.1.3.2.3.cmml">p</mi></msub><mo id="S3.SS2.p2.12.m12.1.1.3.1" xref="S3.SS2.p2.12.m12.1.1.3.1.cmml">+</mo><msub id="S3.SS2.p2.12.m12.1.1.3.3" xref="S3.SS2.p2.12.m12.1.1.3.3.cmml"><mi id="S3.SS2.p2.12.m12.1.1.3.3.2" xref="S3.SS2.p2.12.m12.1.1.3.3.2.cmml">q</mi><mi id="S3.SS2.p2.12.m12.1.1.3.3.3" xref="S3.SS2.p2.12.m12.1.1.3.3.3.cmml">l</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.12.m12.1b"><apply id="S3.SS2.p2.12.m12.1.1.cmml" xref="S3.SS2.p2.12.m12.1.1"><eq id="S3.SS2.p2.12.m12.1.1.1.cmml" xref="S3.SS2.p2.12.m12.1.1.1"></eq><apply id="S3.SS2.p2.12.m12.1.1.2.cmml" xref="S3.SS2.p2.12.m12.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p2.12.m12.1.1.2.1.cmml" xref="S3.SS2.p2.12.m12.1.1.2">subscript</csymbol><ci id="S3.SS2.p2.12.m12.1.1.2.2.cmml" xref="S3.SS2.p2.12.m12.1.1.2.2">𝑞</ci><ci id="S3.SS2.p2.12.m12.1.1.2.3.cmml" xref="S3.SS2.p2.12.m12.1.1.2.3">𝑚</ci></apply><apply id="S3.SS2.p2.12.m12.1.1.3.cmml" xref="S3.SS2.p2.12.m12.1.1.3"><plus id="S3.SS2.p2.12.m12.1.1.3.1.cmml" xref="S3.SS2.p2.12.m12.1.1.3.1"></plus><apply id="S3.SS2.p2.12.m12.1.1.3.2.cmml" xref="S3.SS2.p2.12.m12.1.1.3.2"><csymbol cd="ambiguous" id="S3.SS2.p2.12.m12.1.1.3.2.1.cmml" xref="S3.SS2.p2.12.m12.1.1.3.2">subscript</csymbol><ci id="S3.SS2.p2.12.m12.1.1.3.2.2.cmml" xref="S3.SS2.p2.12.m12.1.1.3.2.2">𝑞</ci><ci id="S3.SS2.p2.12.m12.1.1.3.2.3.cmml" xref="S3.SS2.p2.12.m12.1.1.3.2.3">𝑝</ci></apply><apply id="S3.SS2.p2.12.m12.1.1.3.3.cmml" xref="S3.SS2.p2.12.m12.1.1.3.3"><csymbol cd="ambiguous" id="S3.SS2.p2.12.m12.1.1.3.3.1.cmml" xref="S3.SS2.p2.12.m12.1.1.3.3">subscript</csymbol><ci id="S3.SS2.p2.12.m12.1.1.3.3.2.cmml" xref="S3.SS2.p2.12.m12.1.1.3.3.2">𝑞</ci><ci id="S3.SS2.p2.12.m12.1.1.3.3.3.cmml" xref="S3.SS2.p2.12.m12.1.1.3.3.3">𝑙</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.12.m12.1c">q_{m}=q_{p}+q_{l}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.12.m12.1d">italic_q start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT = italic_q start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT + italic_q start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="f^{d}_{\varphi}" class="ltx_Math" display="inline" id="S3.SS2.p2.13.m13.1"><semantics id="S3.SS2.p2.13.m13.1a"><msubsup id="S3.SS2.p2.13.m13.1.1" xref="S3.SS2.p2.13.m13.1.1.cmml"><mi id="S3.SS2.p2.13.m13.1.1.2.2" xref="S3.SS2.p2.13.m13.1.1.2.2.cmml">f</mi><mi id="S3.SS2.p2.13.m13.1.1.3" xref="S3.SS2.p2.13.m13.1.1.3.cmml">φ</mi><mi id="S3.SS2.p2.13.m13.1.1.2.3" xref="S3.SS2.p2.13.m13.1.1.2.3.cmml">d</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.13.m13.1b"><apply id="S3.SS2.p2.13.m13.1.1.cmml" xref="S3.SS2.p2.13.m13.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.13.m13.1.1.1.cmml" xref="S3.SS2.p2.13.m13.1.1">subscript</csymbol><apply id="S3.SS2.p2.13.m13.1.1.2.cmml" xref="S3.SS2.p2.13.m13.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.13.m13.1.1.2.1.cmml" xref="S3.SS2.p2.13.m13.1.1">superscript</csymbol><ci id="S3.SS2.p2.13.m13.1.1.2.2.cmml" xref="S3.SS2.p2.13.m13.1.1.2.2">𝑓</ci><ci id="S3.SS2.p2.13.m13.1.1.2.3.cmml" xref="S3.SS2.p2.13.m13.1.1.2.3">𝑑</ci></apply><ci id="S3.SS2.p2.13.m13.1.1.3.cmml" xref="S3.SS2.p2.13.m13.1.1.3">𝜑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.13.m13.1c">f^{d}_{\varphi}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.13.m13.1d">italic_f start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_φ end_POSTSUBSCRIPT</annotation></semantics></math> into <math alttext="P" class="ltx_Math" display="inline" id="S3.SS2.p2.14.m14.1"><semantics id="S3.SS2.p2.14.m14.1a"><mi id="S3.SS2.p2.14.m14.1.1" xref="S3.SS2.p2.14.m14.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.14.m14.1b"><ci id="S3.SS2.p2.14.m14.1.1.cmml" xref="S3.SS2.p2.14.m14.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.14.m14.1c">P</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.14.m14.1d">italic_P</annotation></semantics></math> and get the implicit pose indicator <math alttext="f_{i}" class="ltx_Math" display="inline" id="S3.SS2.p2.15.m15.1"><semantics id="S3.SS2.p2.15.m15.1a"><msub id="S3.SS2.p2.15.m15.1.1" xref="S3.SS2.p2.15.m15.1.1.cmml"><mi id="S3.SS2.p2.15.m15.1.1.2" xref="S3.SS2.p2.15.m15.1.1.2.cmml">f</mi><mi id="S3.SS2.p2.15.m15.1.1.3" xref="S3.SS2.p2.15.m15.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.15.m15.1b"><apply id="S3.SS2.p2.15.m15.1.1.cmml" xref="S3.SS2.p2.15.m15.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.15.m15.1.1.1.cmml" xref="S3.SS2.p2.15.m15.1.1">subscript</csymbol><ci id="S3.SS2.p2.15.m15.1.1.2.cmml" xref="S3.SS2.p2.15.m15.1.1.2">𝑓</ci><ci id="S3.SS2.p2.15.m15.1.1.3.cmml" xref="S3.SS2.p2.15.m15.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.15.m15.1c">f_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.15.m15.1d">italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>, which contains the essential representation of motion that cannot be represented by the simple 2D pose skeletons.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.11"><span class="ltx_text ltx_font_bold" id="S3.SS2.p3.11.1">Explicit Pose Indicator (EPI).</span>
To deal with the second limitation in the training strategy,
we propose EPI, designed to train the model to handle misaligned input pairs during inference.
The <span class="ltx_text ltx_font_italic" id="S3.SS2.p3.11.2">key insight</span> lies in simulating misalignments between reference image and pose images during training while ensuring the motion remains consistent with the given driving video <math alttext="I^{d}_{1:F}" class="ltx_Math" display="inline" id="S3.SS2.p3.1.m1.1"><semantics id="S3.SS2.p3.1.m1.1a"><msubsup id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml"><mi id="S3.SS2.p3.1.m1.1.1.2.2" xref="S3.SS2.p3.1.m1.1.1.2.2.cmml">I</mi><mrow id="S3.SS2.p3.1.m1.1.1.3" xref="S3.SS2.p3.1.m1.1.1.3.cmml"><mn id="S3.SS2.p3.1.m1.1.1.3.2" xref="S3.SS2.p3.1.m1.1.1.3.2.cmml">1</mn><mo id="S3.SS2.p3.1.m1.1.1.3.1" lspace="0.278em" rspace="0.278em" xref="S3.SS2.p3.1.m1.1.1.3.1.cmml">:</mo><mi id="S3.SS2.p3.1.m1.1.1.3.3" xref="S3.SS2.p3.1.m1.1.1.3.3.cmml">F</mi></mrow><mi id="S3.SS2.p3.1.m1.1.1.2.3" xref="S3.SS2.p3.1.m1.1.1.2.3.cmml">d</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><apply id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.1.m1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">subscript</csymbol><apply id="S3.SS2.p3.1.m1.1.1.2.cmml" xref="S3.SS2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.1.m1.1.1.2.1.cmml" xref="S3.SS2.p3.1.m1.1.1">superscript</csymbol><ci id="S3.SS2.p3.1.m1.1.1.2.2.cmml" xref="S3.SS2.p3.1.m1.1.1.2.2">𝐼</ci><ci id="S3.SS2.p3.1.m1.1.1.2.3.cmml" xref="S3.SS2.p3.1.m1.1.1.2.3">𝑑</ci></apply><apply id="S3.SS2.p3.1.m1.1.1.3.cmml" xref="S3.SS2.p3.1.m1.1.1.3"><ci id="S3.SS2.p3.1.m1.1.1.3.1.cmml" xref="S3.SS2.p3.1.m1.1.1.3.1">:</ci><cn id="S3.SS2.p3.1.m1.1.1.3.2.cmml" type="integer" xref="S3.SS2.p3.1.m1.1.1.3.2">1</cn><ci id="S3.SS2.p3.1.m1.1.1.3.3.cmml" xref="S3.SS2.p3.1.m1.1.1.3.3">𝐹</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">I^{d}_{1:F}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.1.m1.1d">italic_I start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 : italic_F end_POSTSUBSCRIPT</annotation></semantics></math>. Therefore, we explore two pose transformation schemes: Pose Realignment and Pose Rescale. As shown in Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#S2.F2" title="Figure 2 ‣ 2.2 Pose-guided character motion transfer ‣ 2 Related Work ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">2</span></a> (b), in the pose realignment scheme, we first establish a pose pool containing pose images from the training set. In each training step, we first sample the reference image <math alttext="I^{r}" class="ltx_Math" display="inline" id="S3.SS2.p3.2.m2.1"><semantics id="S3.SS2.p3.2.m2.1a"><msup id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml"><mi id="S3.SS2.p3.2.m2.1.1.2" xref="S3.SS2.p3.2.m2.1.1.2.cmml">I</mi><mi id="S3.SS2.p3.2.m2.1.1.3" xref="S3.SS2.p3.2.m2.1.1.3.cmml">r</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><apply id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m2.1.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1">superscript</csymbol><ci id="S3.SS2.p3.2.m2.1.1.2.cmml" xref="S3.SS2.p3.2.m2.1.1.2">𝐼</ci><ci id="S3.SS2.p3.2.m2.1.1.3.cmml" xref="S3.SS2.p3.2.m2.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">I^{r}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.2.m2.1d">italic_I start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT</annotation></semantics></math> and the driving pose <math alttext="I^{p}" class="ltx_Math" display="inline" id="S3.SS2.p3.3.m3.1"><semantics id="S3.SS2.p3.3.m3.1a"><msup id="S3.SS2.p3.3.m3.1.1" xref="S3.SS2.p3.3.m3.1.1.cmml"><mi id="S3.SS2.p3.3.m3.1.1.2" xref="S3.SS2.p3.3.m3.1.1.2.cmml">I</mi><mi id="S3.SS2.p3.3.m3.1.1.3" xref="S3.SS2.p3.3.m3.1.1.3.cmml">p</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m3.1b"><apply id="S3.SS2.p3.3.m3.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.3.m3.1.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1">superscript</csymbol><ci id="S3.SS2.p3.3.m3.1.1.2.cmml" xref="S3.SS2.p3.3.m3.1.1.2">𝐼</ci><ci id="S3.SS2.p3.3.m3.1.1.3.cmml" xref="S3.SS2.p3.3.m3.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m3.1c">I^{p}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.3.m3.1d">italic_I start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT</annotation></semantics></math> following previous works. Additionally, we randomly select an align anchor pose <math alttext="I^{p}_{anchor}" class="ltx_Math" display="inline" id="S3.SS2.p3.4.m4.1"><semantics id="S3.SS2.p3.4.m4.1a"><msubsup id="S3.SS2.p3.4.m4.1.1" xref="S3.SS2.p3.4.m4.1.1.cmml"><mi id="S3.SS2.p3.4.m4.1.1.2.2" xref="S3.SS2.p3.4.m4.1.1.2.2.cmml">I</mi><mrow id="S3.SS2.p3.4.m4.1.1.3" xref="S3.SS2.p3.4.m4.1.1.3.cmml"><mi id="S3.SS2.p3.4.m4.1.1.3.2" xref="S3.SS2.p3.4.m4.1.1.3.2.cmml">a</mi><mo id="S3.SS2.p3.4.m4.1.1.3.1" xref="S3.SS2.p3.4.m4.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p3.4.m4.1.1.3.3" xref="S3.SS2.p3.4.m4.1.1.3.3.cmml">n</mi><mo id="S3.SS2.p3.4.m4.1.1.3.1a" xref="S3.SS2.p3.4.m4.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p3.4.m4.1.1.3.4" xref="S3.SS2.p3.4.m4.1.1.3.4.cmml">c</mi><mo id="S3.SS2.p3.4.m4.1.1.3.1b" xref="S3.SS2.p3.4.m4.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p3.4.m4.1.1.3.5" xref="S3.SS2.p3.4.m4.1.1.3.5.cmml">h</mi><mo id="S3.SS2.p3.4.m4.1.1.3.1c" xref="S3.SS2.p3.4.m4.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p3.4.m4.1.1.3.6" xref="S3.SS2.p3.4.m4.1.1.3.6.cmml">o</mi><mo id="S3.SS2.p3.4.m4.1.1.3.1d" xref="S3.SS2.p3.4.m4.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p3.4.m4.1.1.3.7" xref="S3.SS2.p3.4.m4.1.1.3.7.cmml">r</mi></mrow><mi id="S3.SS2.p3.4.m4.1.1.2.3" xref="S3.SS2.p3.4.m4.1.1.2.3.cmml">p</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.4.m4.1b"><apply id="S3.SS2.p3.4.m4.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.4.m4.1.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1">subscript</csymbol><apply id="S3.SS2.p3.4.m4.1.1.2.cmml" xref="S3.SS2.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.4.m4.1.1.2.1.cmml" xref="S3.SS2.p3.4.m4.1.1">superscript</csymbol><ci id="S3.SS2.p3.4.m4.1.1.2.2.cmml" xref="S3.SS2.p3.4.m4.1.1.2.2">𝐼</ci><ci id="S3.SS2.p3.4.m4.1.1.2.3.cmml" xref="S3.SS2.p3.4.m4.1.1.2.3">𝑝</ci></apply><apply id="S3.SS2.p3.4.m4.1.1.3.cmml" xref="S3.SS2.p3.4.m4.1.1.3"><times id="S3.SS2.p3.4.m4.1.1.3.1.cmml" xref="S3.SS2.p3.4.m4.1.1.3.1"></times><ci id="S3.SS2.p3.4.m4.1.1.3.2.cmml" xref="S3.SS2.p3.4.m4.1.1.3.2">𝑎</ci><ci id="S3.SS2.p3.4.m4.1.1.3.3.cmml" xref="S3.SS2.p3.4.m4.1.1.3.3">𝑛</ci><ci id="S3.SS2.p3.4.m4.1.1.3.4.cmml" xref="S3.SS2.p3.4.m4.1.1.3.4">𝑐</ci><ci id="S3.SS2.p3.4.m4.1.1.3.5.cmml" xref="S3.SS2.p3.4.m4.1.1.3.5">ℎ</ci><ci id="S3.SS2.p3.4.m4.1.1.3.6.cmml" xref="S3.SS2.p3.4.m4.1.1.3.6">𝑜</ci><ci id="S3.SS2.p3.4.m4.1.1.3.7.cmml" xref="S3.SS2.p3.4.m4.1.1.3.7">𝑟</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.4.m4.1c">I^{p}_{anchor}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.4.m4.1d">italic_I start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_a italic_n italic_c italic_h italic_o italic_r end_POSTSUBSCRIPT</annotation></semantics></math> from the pose pool. This anchor serves as a reference for aligning the driving pose, producing the aligned pose <math alttext="I^{p}_{realign}" class="ltx_Math" display="inline" id="S3.SS2.p3.5.m5.1"><semantics id="S3.SS2.p3.5.m5.1a"><msubsup id="S3.SS2.p3.5.m5.1.1" xref="S3.SS2.p3.5.m5.1.1.cmml"><mi id="S3.SS2.p3.5.m5.1.1.2.2" xref="S3.SS2.p3.5.m5.1.1.2.2.cmml">I</mi><mrow id="S3.SS2.p3.5.m5.1.1.3" xref="S3.SS2.p3.5.m5.1.1.3.cmml"><mi id="S3.SS2.p3.5.m5.1.1.3.2" xref="S3.SS2.p3.5.m5.1.1.3.2.cmml">r</mi><mo id="S3.SS2.p3.5.m5.1.1.3.1" xref="S3.SS2.p3.5.m5.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p3.5.m5.1.1.3.3" xref="S3.SS2.p3.5.m5.1.1.3.3.cmml">e</mi><mo id="S3.SS2.p3.5.m5.1.1.3.1a" xref="S3.SS2.p3.5.m5.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p3.5.m5.1.1.3.4" xref="S3.SS2.p3.5.m5.1.1.3.4.cmml">a</mi><mo id="S3.SS2.p3.5.m5.1.1.3.1b" xref="S3.SS2.p3.5.m5.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p3.5.m5.1.1.3.5" xref="S3.SS2.p3.5.m5.1.1.3.5.cmml">l</mi><mo id="S3.SS2.p3.5.m5.1.1.3.1c" xref="S3.SS2.p3.5.m5.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p3.5.m5.1.1.3.6" xref="S3.SS2.p3.5.m5.1.1.3.6.cmml">i</mi><mo id="S3.SS2.p3.5.m5.1.1.3.1d" xref="S3.SS2.p3.5.m5.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p3.5.m5.1.1.3.7" xref="S3.SS2.p3.5.m5.1.1.3.7.cmml">g</mi><mo id="S3.SS2.p3.5.m5.1.1.3.1e" xref="S3.SS2.p3.5.m5.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p3.5.m5.1.1.3.8" xref="S3.SS2.p3.5.m5.1.1.3.8.cmml">n</mi></mrow><mi id="S3.SS2.p3.5.m5.1.1.2.3" xref="S3.SS2.p3.5.m5.1.1.2.3.cmml">p</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.5.m5.1b"><apply id="S3.SS2.p3.5.m5.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.5.m5.1.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1">subscript</csymbol><apply id="S3.SS2.p3.5.m5.1.1.2.cmml" xref="S3.SS2.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.5.m5.1.1.2.1.cmml" xref="S3.SS2.p3.5.m5.1.1">superscript</csymbol><ci id="S3.SS2.p3.5.m5.1.1.2.2.cmml" xref="S3.SS2.p3.5.m5.1.1.2.2">𝐼</ci><ci id="S3.SS2.p3.5.m5.1.1.2.3.cmml" xref="S3.SS2.p3.5.m5.1.1.2.3">𝑝</ci></apply><apply id="S3.SS2.p3.5.m5.1.1.3.cmml" xref="S3.SS2.p3.5.m5.1.1.3"><times id="S3.SS2.p3.5.m5.1.1.3.1.cmml" xref="S3.SS2.p3.5.m5.1.1.3.1"></times><ci id="S3.SS2.p3.5.m5.1.1.3.2.cmml" xref="S3.SS2.p3.5.m5.1.1.3.2">𝑟</ci><ci id="S3.SS2.p3.5.m5.1.1.3.3.cmml" xref="S3.SS2.p3.5.m5.1.1.3.3">𝑒</ci><ci id="S3.SS2.p3.5.m5.1.1.3.4.cmml" xref="S3.SS2.p3.5.m5.1.1.3.4">𝑎</ci><ci id="S3.SS2.p3.5.m5.1.1.3.5.cmml" xref="S3.SS2.p3.5.m5.1.1.3.5">𝑙</ci><ci id="S3.SS2.p3.5.m5.1.1.3.6.cmml" xref="S3.SS2.p3.5.m5.1.1.3.6">𝑖</ci><ci id="S3.SS2.p3.5.m5.1.1.3.7.cmml" xref="S3.SS2.p3.5.m5.1.1.3.7">𝑔</ci><ci id="S3.SS2.p3.5.m5.1.1.3.8.cmml" xref="S3.SS2.p3.5.m5.1.1.3.8">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.5.m5.1c">I^{p}_{realign}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.5.m5.1d">italic_I start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_r italic_e italic_a italic_l italic_i italic_g italic_n end_POSTSUBSCRIPT</annotation></semantics></math>. However, since the characters we aim to animate are often anthropomorphic characters, whose shapes can significantly differ from human, such as varying head-to-shoulder ratios, extremely short legs, or even the absence of arms (as shown in Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#S0.F1" title="Figure 1 ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">1</span></a> and Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#S4.F5" title="Figure 5 ‣ 4.1 Experimental Settings ‣ 4 Experiments ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">5</span></a>), relying solely on pose realignment is insufficient to capture these variations for simulation.
Therefore, we further introduce Pose Rescale. Specifically, we define a set of keypoint rescaling operations, including modifying the length of the body, legs, arms, neck, and shoulders, altering face size, even adding or removing specific body parts and etc. These transformations are stored in a rescale pool. After obtaining the realigned poses <math alttext="I^{p}_{realign}" class="ltx_Math" display="inline" id="S3.SS2.p3.6.m6.1"><semantics id="S3.SS2.p3.6.m6.1a"><msubsup id="S3.SS2.p3.6.m6.1.1" xref="S3.SS2.p3.6.m6.1.1.cmml"><mi id="S3.SS2.p3.6.m6.1.1.2.2" xref="S3.SS2.p3.6.m6.1.1.2.2.cmml">I</mi><mrow id="S3.SS2.p3.6.m6.1.1.3" xref="S3.SS2.p3.6.m6.1.1.3.cmml"><mi id="S3.SS2.p3.6.m6.1.1.3.2" xref="S3.SS2.p3.6.m6.1.1.3.2.cmml">r</mi><mo id="S3.SS2.p3.6.m6.1.1.3.1" xref="S3.SS2.p3.6.m6.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p3.6.m6.1.1.3.3" xref="S3.SS2.p3.6.m6.1.1.3.3.cmml">e</mi><mo id="S3.SS2.p3.6.m6.1.1.3.1a" xref="S3.SS2.p3.6.m6.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p3.6.m6.1.1.3.4" xref="S3.SS2.p3.6.m6.1.1.3.4.cmml">a</mi><mo id="S3.SS2.p3.6.m6.1.1.3.1b" xref="S3.SS2.p3.6.m6.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p3.6.m6.1.1.3.5" xref="S3.SS2.p3.6.m6.1.1.3.5.cmml">l</mi><mo id="S3.SS2.p3.6.m6.1.1.3.1c" xref="S3.SS2.p3.6.m6.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p3.6.m6.1.1.3.6" xref="S3.SS2.p3.6.m6.1.1.3.6.cmml">i</mi><mo id="S3.SS2.p3.6.m6.1.1.3.1d" xref="S3.SS2.p3.6.m6.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p3.6.m6.1.1.3.7" xref="S3.SS2.p3.6.m6.1.1.3.7.cmml">g</mi><mo id="S3.SS2.p3.6.m6.1.1.3.1e" xref="S3.SS2.p3.6.m6.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p3.6.m6.1.1.3.8" xref="S3.SS2.p3.6.m6.1.1.3.8.cmml">n</mi></mrow><mi id="S3.SS2.p3.6.m6.1.1.2.3" xref="S3.SS2.p3.6.m6.1.1.2.3.cmml">p</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.6.m6.1b"><apply id="S3.SS2.p3.6.m6.1.1.cmml" xref="S3.SS2.p3.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.6.m6.1.1.1.cmml" xref="S3.SS2.p3.6.m6.1.1">subscript</csymbol><apply id="S3.SS2.p3.6.m6.1.1.2.cmml" xref="S3.SS2.p3.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.6.m6.1.1.2.1.cmml" xref="S3.SS2.p3.6.m6.1.1">superscript</csymbol><ci id="S3.SS2.p3.6.m6.1.1.2.2.cmml" xref="S3.SS2.p3.6.m6.1.1.2.2">𝐼</ci><ci id="S3.SS2.p3.6.m6.1.1.2.3.cmml" xref="S3.SS2.p3.6.m6.1.1.2.3">𝑝</ci></apply><apply id="S3.SS2.p3.6.m6.1.1.3.cmml" xref="S3.SS2.p3.6.m6.1.1.3"><times id="S3.SS2.p3.6.m6.1.1.3.1.cmml" xref="S3.SS2.p3.6.m6.1.1.3.1"></times><ci id="S3.SS2.p3.6.m6.1.1.3.2.cmml" xref="S3.SS2.p3.6.m6.1.1.3.2">𝑟</ci><ci id="S3.SS2.p3.6.m6.1.1.3.3.cmml" xref="S3.SS2.p3.6.m6.1.1.3.3">𝑒</ci><ci id="S3.SS2.p3.6.m6.1.1.3.4.cmml" xref="S3.SS2.p3.6.m6.1.1.3.4">𝑎</ci><ci id="S3.SS2.p3.6.m6.1.1.3.5.cmml" xref="S3.SS2.p3.6.m6.1.1.3.5">𝑙</ci><ci id="S3.SS2.p3.6.m6.1.1.3.6.cmml" xref="S3.SS2.p3.6.m6.1.1.3.6">𝑖</ci><ci id="S3.SS2.p3.6.m6.1.1.3.7.cmml" xref="S3.SS2.p3.6.m6.1.1.3.7">𝑔</ci><ci id="S3.SS2.p3.6.m6.1.1.3.8.cmml" xref="S3.SS2.p3.6.m6.1.1.3.8">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.6.m6.1c">I^{p}_{realign}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.6.m6.1d">italic_I start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_r italic_e italic_a italic_l italic_i italic_g italic_n end_POSTSUBSCRIPT</annotation></semantics></math>, we apply a random selection of transformations from this pool with a certain probability on them, generating the final transformed poses <math alttext="I^{p}_{n}" class="ltx_Math" display="inline" id="S3.SS2.p3.7.m7.1"><semantics id="S3.SS2.p3.7.m7.1a"><msubsup id="S3.SS2.p3.7.m7.1.1" xref="S3.SS2.p3.7.m7.1.1.cmml"><mi id="S3.SS2.p3.7.m7.1.1.2.2" xref="S3.SS2.p3.7.m7.1.1.2.2.cmml">I</mi><mi id="S3.SS2.p3.7.m7.1.1.3" xref="S3.SS2.p3.7.m7.1.1.3.cmml">n</mi><mi id="S3.SS2.p3.7.m7.1.1.2.3" xref="S3.SS2.p3.7.m7.1.1.2.3.cmml">p</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.7.m7.1b"><apply id="S3.SS2.p3.7.m7.1.1.cmml" xref="S3.SS2.p3.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.7.m7.1.1.1.cmml" xref="S3.SS2.p3.7.m7.1.1">subscript</csymbol><apply id="S3.SS2.p3.7.m7.1.1.2.cmml" xref="S3.SS2.p3.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.7.m7.1.1.2.1.cmml" xref="S3.SS2.p3.7.m7.1.1">superscript</csymbol><ci id="S3.SS2.p3.7.m7.1.1.2.2.cmml" xref="S3.SS2.p3.7.m7.1.1.2.2">𝐼</ci><ci id="S3.SS2.p3.7.m7.1.1.2.3.cmml" xref="S3.SS2.p3.7.m7.1.1.2.3">𝑝</ci></apply><ci id="S3.SS2.p3.7.m7.1.1.3.cmml" xref="S3.SS2.p3.7.m7.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.7.m7.1c">I^{p}_{n}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.7.m7.1d">italic_I start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT</annotation></semantics></math> (additional examples of transformations are provided in the Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#A1" title="Appendix A Network Details ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">A</span></a>). Note that we set the probability of <math alttext="\lambda\in[0,1]" class="ltx_Math" display="inline" id="S3.SS2.p3.8.m8.2"><semantics id="S3.SS2.p3.8.m8.2a"><mrow id="S3.SS2.p3.8.m8.2.3" xref="S3.SS2.p3.8.m8.2.3.cmml"><mi id="S3.SS2.p3.8.m8.2.3.2" xref="S3.SS2.p3.8.m8.2.3.2.cmml">λ</mi><mo id="S3.SS2.p3.8.m8.2.3.1" xref="S3.SS2.p3.8.m8.2.3.1.cmml">∈</mo><mrow id="S3.SS2.p3.8.m8.2.3.3.2" xref="S3.SS2.p3.8.m8.2.3.3.1.cmml"><mo id="S3.SS2.p3.8.m8.2.3.3.2.1" stretchy="false" xref="S3.SS2.p3.8.m8.2.3.3.1.cmml">[</mo><mn id="S3.SS2.p3.8.m8.1.1" xref="S3.SS2.p3.8.m8.1.1.cmml">0</mn><mo id="S3.SS2.p3.8.m8.2.3.3.2.2" xref="S3.SS2.p3.8.m8.2.3.3.1.cmml">,</mo><mn id="S3.SS2.p3.8.m8.2.2" xref="S3.SS2.p3.8.m8.2.2.cmml">1</mn><mo id="S3.SS2.p3.8.m8.2.3.3.2.3" stretchy="false" xref="S3.SS2.p3.8.m8.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.8.m8.2b"><apply id="S3.SS2.p3.8.m8.2.3.cmml" xref="S3.SS2.p3.8.m8.2.3"><in id="S3.SS2.p3.8.m8.2.3.1.cmml" xref="S3.SS2.p3.8.m8.2.3.1"></in><ci id="S3.SS2.p3.8.m8.2.3.2.cmml" xref="S3.SS2.p3.8.m8.2.3.2">𝜆</ci><interval closure="closed" id="S3.SS2.p3.8.m8.2.3.3.1.cmml" xref="S3.SS2.p3.8.m8.2.3.3.2"><cn id="S3.SS2.p3.8.m8.1.1.cmml" type="integer" xref="S3.SS2.p3.8.m8.1.1">0</cn><cn id="S3.SS2.p3.8.m8.2.2.cmml" type="integer" xref="S3.SS2.p3.8.m8.2.2">1</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.8.m8.2c">\lambda\in[0,1]</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.8.m8.2d">italic_λ ∈ [ 0 , 1 ]</annotation></semantics></math> to apply the pose transformation, and with a probability of <math alttext="1-\lambda" class="ltx_Math" display="inline" id="S3.SS2.p3.9.m9.1"><semantics id="S3.SS2.p3.9.m9.1a"><mrow id="S3.SS2.p3.9.m9.1.1" xref="S3.SS2.p3.9.m9.1.1.cmml"><mn id="S3.SS2.p3.9.m9.1.1.2" xref="S3.SS2.p3.9.m9.1.1.2.cmml">1</mn><mo id="S3.SS2.p3.9.m9.1.1.1" xref="S3.SS2.p3.9.m9.1.1.1.cmml">−</mo><mi id="S3.SS2.p3.9.m9.1.1.3" xref="S3.SS2.p3.9.m9.1.1.3.cmml">λ</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.9.m9.1b"><apply id="S3.SS2.p3.9.m9.1.1.cmml" xref="S3.SS2.p3.9.m9.1.1"><minus id="S3.SS2.p3.9.m9.1.1.1.cmml" xref="S3.SS2.p3.9.m9.1.1.1"></minus><cn id="S3.SS2.p3.9.m9.1.1.2.cmml" type="integer" xref="S3.SS2.p3.9.m9.1.1.2">1</cn><ci id="S3.SS2.p3.9.m9.1.1.3.cmml" xref="S3.SS2.p3.9.m9.1.1.3">𝜆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.9.m9.1c">1-\lambda</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.9.m9.1d">1 - italic_λ</annotation></semantics></math>, the pose image remains unchanged. Subsequently, <math alttext="I^{p}_{n}" class="ltx_Math" display="inline" id="S3.SS2.p3.10.m10.1"><semantics id="S3.SS2.p3.10.m10.1a"><msubsup id="S3.SS2.p3.10.m10.1.1" xref="S3.SS2.p3.10.m10.1.1.cmml"><mi id="S3.SS2.p3.10.m10.1.1.2.2" xref="S3.SS2.p3.10.m10.1.1.2.2.cmml">I</mi><mi id="S3.SS2.p3.10.m10.1.1.3" xref="S3.SS2.p3.10.m10.1.1.3.cmml">n</mi><mi id="S3.SS2.p3.10.m10.1.1.2.3" xref="S3.SS2.p3.10.m10.1.1.2.3.cmml">p</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.10.m10.1b"><apply id="S3.SS2.p3.10.m10.1.1.cmml" xref="S3.SS2.p3.10.m10.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.10.m10.1.1.1.cmml" xref="S3.SS2.p3.10.m10.1.1">subscript</csymbol><apply id="S3.SS2.p3.10.m10.1.1.2.cmml" xref="S3.SS2.p3.10.m10.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.10.m10.1.1.2.1.cmml" xref="S3.SS2.p3.10.m10.1.1">superscript</csymbol><ci id="S3.SS2.p3.10.m10.1.1.2.2.cmml" xref="S3.SS2.p3.10.m10.1.1.2.2">𝐼</ci><ci id="S3.SS2.p3.10.m10.1.1.2.3.cmml" xref="S3.SS2.p3.10.m10.1.1.2.3">𝑝</ci></apply><ci id="S3.SS2.p3.10.m10.1.1.3.cmml" xref="S3.SS2.p3.10.m10.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.10.m10.1c">I^{p}_{n}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.10.m10.1d">italic_I start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT</annotation></semantics></math> is encoded to the explicit feature <math alttext="f_{e}" class="ltx_Math" display="inline" id="S3.SS2.p3.11.m11.1"><semantics id="S3.SS2.p3.11.m11.1a"><msub id="S3.SS2.p3.11.m11.1.1" xref="S3.SS2.p3.11.m11.1.1.cmml"><mi id="S3.SS2.p3.11.m11.1.1.2" xref="S3.SS2.p3.11.m11.1.1.2.cmml">f</mi><mi id="S3.SS2.p3.11.m11.1.1.3" xref="S3.SS2.p3.11.m11.1.1.3.cmml">e</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.11.m11.1b"><apply id="S3.SS2.p3.11.m11.1.1.cmml" xref="S3.SS2.p3.11.m11.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.11.m11.1.1.1.cmml" xref="S3.SS2.p3.11.m11.1.1">subscript</csymbol><ci id="S3.SS2.p3.11.m11.1.1.2.cmml" xref="S3.SS2.p3.11.m11.1.1.2">𝑓</ci><ci id="S3.SS2.p3.11.m11.1.1.3.cmml" xref="S3.SS2.p3.11.m11.1.1.3">𝑒</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.11.m11.1c">f_{e}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.11.m11.1d">italic_f start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT</annotation></semantics></math> via a Pose Encoder.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Framework and Implement Details</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.29">In light of the success of previous works&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Hu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib21" title="">2023</a>); Zhang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib82" title="">2024</a>)</cite>, <span class="ltx_text ltx_font_typewriter" id="S3.SS3.p1.29.1">Animate-X</span> follows the main framework, which consists of several encoders for feature extraction and a 3D-UNet&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Wang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib57" title="">2023a</a>; <a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib60" title="">c</a>); Blattmann et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib5" title="">2023</a>)</cite> for video generation. As shown in Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#S2.F2" title="Figure 2 ‣ 2.2 Pose-guided character motion transfer ‣ 2 Related Work ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">2</span></a>, given a reference image <math alttext="I^{r}" class="ltx_Math" display="inline" id="S3.SS3.p1.1.m1.1"><semantics id="S3.SS3.p1.1.m1.1a"><msup id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml"><mi id="S3.SS3.p1.1.m1.1.1.2" xref="S3.SS3.p1.1.m1.1.1.2.cmml">I</mi><mi id="S3.SS3.p1.1.m1.1.1.3" xref="S3.SS3.p1.1.m1.1.1.3.cmml">r</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><apply id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">superscript</csymbol><ci id="S3.SS3.p1.1.m1.1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.1.2">𝐼</ci><ci id="S3.SS3.p1.1.m1.1.1.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">I^{r}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.1.m1.1d">italic_I start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT</annotation></semantics></math>, we employ the pretrained CLIP Image Encoder <math alttext="\Phi" class="ltx_Math" display="inline" id="S3.SS3.p1.2.m2.1"><semantics id="S3.SS3.p1.2.m2.1a"><mi id="S3.SS3.p1.2.m2.1.1" mathvariant="normal" xref="S3.SS3.p1.2.m2.1.1.cmml">Φ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b"><ci id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1">Φ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">\Phi</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.2.m2.1d">roman_Φ</annotation></semantics></math>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Radford et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib36" title="">2021</a>)</cite> to extract appearance feature <math alttext="f^{r}_{\varphi}" class="ltx_Math" display="inline" id="S3.SS3.p1.3.m3.1"><semantics id="S3.SS3.p1.3.m3.1a"><msubsup id="S3.SS3.p1.3.m3.1.1" xref="S3.SS3.p1.3.m3.1.1.cmml"><mi id="S3.SS3.p1.3.m3.1.1.2.2" xref="S3.SS3.p1.3.m3.1.1.2.2.cmml">f</mi><mi id="S3.SS3.p1.3.m3.1.1.3" xref="S3.SS3.p1.3.m3.1.1.3.cmml">φ</mi><mi id="S3.SS3.p1.3.m3.1.1.2.3" xref="S3.SS3.p1.3.m3.1.1.2.3.cmml">r</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.3.m3.1b"><apply id="S3.SS3.p1.3.m3.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.3.m3.1.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1">subscript</csymbol><apply id="S3.SS3.p1.3.m3.1.1.2.cmml" xref="S3.SS3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.3.m3.1.1.2.1.cmml" xref="S3.SS3.p1.3.m3.1.1">superscript</csymbol><ci id="S3.SS3.p1.3.m3.1.1.2.2.cmml" xref="S3.SS3.p1.3.m3.1.1.2.2">𝑓</ci><ci id="S3.SS3.p1.3.m3.1.1.2.3.cmml" xref="S3.SS3.p1.3.m3.1.1.2.3">𝑟</ci></apply><ci id="S3.SS3.p1.3.m3.1.1.3.cmml" xref="S3.SS3.p1.3.m3.1.1.3">𝜑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.3.m3.1c">f^{r}_{\varphi}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.3.m3.1d">italic_f start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_φ end_POSTSUBSCRIPT</annotation></semantics></math> from <math alttext="I^{r}" class="ltx_Math" display="inline" id="S3.SS3.p1.4.m4.1"><semantics id="S3.SS3.p1.4.m4.1a"><msup id="S3.SS3.p1.4.m4.1.1" xref="S3.SS3.p1.4.m4.1.1.cmml"><mi id="S3.SS3.p1.4.m4.1.1.2" xref="S3.SS3.p1.4.m4.1.1.2.cmml">I</mi><mi id="S3.SS3.p1.4.m4.1.1.3" xref="S3.SS3.p1.4.m4.1.1.3.cmml">r</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.4.m4.1b"><apply id="S3.SS3.p1.4.m4.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.4.m4.1.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1">superscript</csymbol><ci id="S3.SS3.p1.4.m4.1.1.2.cmml" xref="S3.SS3.p1.4.m4.1.1.2">𝐼</ci><ci id="S3.SS3.p1.4.m4.1.1.3.cmml" xref="S3.SS3.p1.4.m4.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.4.m4.1c">I^{r}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.4.m4.1d">italic_I start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT</annotation></semantics></math>. To reduce the parameters of the framework and facilitate appearance alignment, we exclude the Reference Net presented in most of the previous works&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Hu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib21" title="">2023</a>); Zhang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib82" title="">2024</a>); Zhu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib86" title="">2024</a>)</cite>. Instead, a VAE encoder <math alttext="\mathcal{E}" class="ltx_Math" display="inline" id="S3.SS3.p1.5.m5.1"><semantics id="S3.SS3.p1.5.m5.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p1.5.m5.1.1" xref="S3.SS3.p1.5.m5.1.1.cmml">ℰ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.5.m5.1b"><ci id="S3.SS3.p1.5.m5.1.1.cmml" xref="S3.SS3.p1.5.m5.1.1">ℰ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.5.m5.1c">\mathcal{E}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.5.m5.1d">caligraphic_E</annotation></semantics></math> is utilized to extract the latent representation <math alttext="f^{r}_{e}" class="ltx_Math" display="inline" id="S3.SS3.p1.6.m6.1"><semantics id="S3.SS3.p1.6.m6.1a"><msubsup id="S3.SS3.p1.6.m6.1.1" xref="S3.SS3.p1.6.m6.1.1.cmml"><mi id="S3.SS3.p1.6.m6.1.1.2.2" xref="S3.SS3.p1.6.m6.1.1.2.2.cmml">f</mi><mi id="S3.SS3.p1.6.m6.1.1.3" xref="S3.SS3.p1.6.m6.1.1.3.cmml">e</mi><mi id="S3.SS3.p1.6.m6.1.1.2.3" xref="S3.SS3.p1.6.m6.1.1.2.3.cmml">r</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.6.m6.1b"><apply id="S3.SS3.p1.6.m6.1.1.cmml" xref="S3.SS3.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.6.m6.1.1.1.cmml" xref="S3.SS3.p1.6.m6.1.1">subscript</csymbol><apply id="S3.SS3.p1.6.m6.1.1.2.cmml" xref="S3.SS3.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.6.m6.1.1.2.1.cmml" xref="S3.SS3.p1.6.m6.1.1">superscript</csymbol><ci id="S3.SS3.p1.6.m6.1.1.2.2.cmml" xref="S3.SS3.p1.6.m6.1.1.2.2">𝑓</ci><ci id="S3.SS3.p1.6.m6.1.1.2.3.cmml" xref="S3.SS3.p1.6.m6.1.1.2.3">𝑟</ci></apply><ci id="S3.SS3.p1.6.m6.1.1.3.cmml" xref="S3.SS3.p1.6.m6.1.1.3">𝑒</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.6.m6.1c">f^{r}_{e}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.6.m6.1d">italic_f start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT</annotation></semantics></math> from <math alttext="I^{r}" class="ltx_Math" display="inline" id="S3.SS3.p1.7.m7.1"><semantics id="S3.SS3.p1.7.m7.1a"><msup id="S3.SS3.p1.7.m7.1.1" xref="S3.SS3.p1.7.m7.1.1.cmml"><mi id="S3.SS3.p1.7.m7.1.1.2" xref="S3.SS3.p1.7.m7.1.1.2.cmml">I</mi><mi id="S3.SS3.p1.7.m7.1.1.3" xref="S3.SS3.p1.7.m7.1.1.3.cmml">r</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.7.m7.1b"><apply id="S3.SS3.p1.7.m7.1.1.cmml" xref="S3.SS3.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.7.m7.1.1.1.cmml" xref="S3.SS3.p1.7.m7.1.1">superscript</csymbol><ci id="S3.SS3.p1.7.m7.1.1.2.cmml" xref="S3.SS3.p1.7.m7.1.1.2">𝐼</ci><ci id="S3.SS3.p1.7.m7.1.1.3.cmml" xref="S3.SS3.p1.7.m7.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.7.m7.1c">I^{r}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.7.m7.1d">italic_I start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT</annotation></semantics></math>, which is then directly used as part of the input for the denoising network <math alttext="\epsilon_{\theta}" class="ltx_Math" display="inline" id="S3.SS3.p1.8.m8.1"><semantics id="S3.SS3.p1.8.m8.1a"><msub id="S3.SS3.p1.8.m8.1.1" xref="S3.SS3.p1.8.m8.1.1.cmml"><mi id="S3.SS3.p1.8.m8.1.1.2" xref="S3.SS3.p1.8.m8.1.1.2.cmml">ϵ</mi><mi id="S3.SS3.p1.8.m8.1.1.3" xref="S3.SS3.p1.8.m8.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.8.m8.1b"><apply id="S3.SS3.p1.8.m8.1.1.cmml" xref="S3.SS3.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.8.m8.1.1.1.cmml" xref="S3.SS3.p1.8.m8.1.1">subscript</csymbol><ci id="S3.SS3.p1.8.m8.1.1.2.cmml" xref="S3.SS3.p1.8.m8.1.1.2">italic-ϵ</ci><ci id="S3.SS3.p1.8.m8.1.1.3.cmml" xref="S3.SS3.p1.8.m8.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.8.m8.1c">\epsilon_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.8.m8.1d">italic_ϵ start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math> following&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Wang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib61" title="">2024b</a>)</cite>. For the driven video <math alttext="I^{d}_{1:F}" class="ltx_Math" display="inline" id="S3.SS3.p1.9.m9.1"><semantics id="S3.SS3.p1.9.m9.1a"><msubsup id="S3.SS3.p1.9.m9.1.1" xref="S3.SS3.p1.9.m9.1.1.cmml"><mi id="S3.SS3.p1.9.m9.1.1.2.2" xref="S3.SS3.p1.9.m9.1.1.2.2.cmml">I</mi><mrow id="S3.SS3.p1.9.m9.1.1.3" xref="S3.SS3.p1.9.m9.1.1.3.cmml"><mn id="S3.SS3.p1.9.m9.1.1.3.2" xref="S3.SS3.p1.9.m9.1.1.3.2.cmml">1</mn><mo id="S3.SS3.p1.9.m9.1.1.3.1" lspace="0.278em" rspace="0.278em" xref="S3.SS3.p1.9.m9.1.1.3.1.cmml">:</mo><mi id="S3.SS3.p1.9.m9.1.1.3.3" xref="S3.SS3.p1.9.m9.1.1.3.3.cmml">F</mi></mrow><mi id="S3.SS3.p1.9.m9.1.1.2.3" xref="S3.SS3.p1.9.m9.1.1.2.3.cmml">d</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.9.m9.1b"><apply id="S3.SS3.p1.9.m9.1.1.cmml" xref="S3.SS3.p1.9.m9.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.9.m9.1.1.1.cmml" xref="S3.SS3.p1.9.m9.1.1">subscript</csymbol><apply id="S3.SS3.p1.9.m9.1.1.2.cmml" xref="S3.SS3.p1.9.m9.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.9.m9.1.1.2.1.cmml" xref="S3.SS3.p1.9.m9.1.1">superscript</csymbol><ci id="S3.SS3.p1.9.m9.1.1.2.2.cmml" xref="S3.SS3.p1.9.m9.1.1.2.2">𝐼</ci><ci id="S3.SS3.p1.9.m9.1.1.2.3.cmml" xref="S3.SS3.p1.9.m9.1.1.2.3">𝑑</ci></apply><apply id="S3.SS3.p1.9.m9.1.1.3.cmml" xref="S3.SS3.p1.9.m9.1.1.3"><ci id="S3.SS3.p1.9.m9.1.1.3.1.cmml" xref="S3.SS3.p1.9.m9.1.1.3.1">:</ci><cn id="S3.SS3.p1.9.m9.1.1.3.2.cmml" type="integer" xref="S3.SS3.p1.9.m9.1.1.3.2">1</cn><ci id="S3.SS3.p1.9.m9.1.1.3.3.cmml" xref="S3.SS3.p1.9.m9.1.1.3.3">𝐹</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.9.m9.1c">I^{d}_{1:F}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.9.m9.1d">italic_I start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 : italic_F end_POSTSUBSCRIPT</annotation></semantics></math>, we detect the pose keypoints <math alttext="p^{d}" class="ltx_Math" display="inline" id="S3.SS3.p1.10.m10.1"><semantics id="S3.SS3.p1.10.m10.1a"><msup id="S3.SS3.p1.10.m10.1.1" xref="S3.SS3.p1.10.m10.1.1.cmml"><mi id="S3.SS3.p1.10.m10.1.1.2" xref="S3.SS3.p1.10.m10.1.1.2.cmml">p</mi><mi id="S3.SS3.p1.10.m10.1.1.3" xref="S3.SS3.p1.10.m10.1.1.3.cmml">d</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.10.m10.1b"><apply id="S3.SS3.p1.10.m10.1.1.cmml" xref="S3.SS3.p1.10.m10.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.10.m10.1.1.1.cmml" xref="S3.SS3.p1.10.m10.1.1">superscript</csymbol><ci id="S3.SS3.p1.10.m10.1.1.2.cmml" xref="S3.SS3.p1.10.m10.1.1.2">𝑝</ci><ci id="S3.SS3.p1.10.m10.1.1.3.cmml" xref="S3.SS3.p1.10.m10.1.1.3">𝑑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.10.m10.1c">p^{d}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.10.m10.1d">italic_p start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT</annotation></semantics></math> and CLIP feature <math alttext="I^{d}" class="ltx_Math" display="inline" id="S3.SS3.p1.11.m11.1"><semantics id="S3.SS3.p1.11.m11.1a"><msup id="S3.SS3.p1.11.m11.1.1" xref="S3.SS3.p1.11.m11.1.1.cmml"><mi id="S3.SS3.p1.11.m11.1.1.2" xref="S3.SS3.p1.11.m11.1.1.2.cmml">I</mi><mi id="S3.SS3.p1.11.m11.1.1.3" xref="S3.SS3.p1.11.m11.1.1.3.cmml">d</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.11.m11.1b"><apply id="S3.SS3.p1.11.m11.1.1.cmml" xref="S3.SS3.p1.11.m11.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.11.m11.1.1.1.cmml" xref="S3.SS3.p1.11.m11.1.1">superscript</csymbol><ci id="S3.SS3.p1.11.m11.1.1.2.cmml" xref="S3.SS3.p1.11.m11.1.1.2">𝐼</ci><ci id="S3.SS3.p1.11.m11.1.1.3.cmml" xref="S3.SS3.p1.11.m11.1.1.3">𝑑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.11.m11.1c">I^{d}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.11.m11.1d">italic_I start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT</annotation></semantics></math> via a DWPose&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Yang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib71" title="">2023</a>)</cite> and CLIP Image Encoder <math alttext="\Phi" class="ltx_Math" display="inline" id="S3.SS3.p1.12.m12.1"><semantics id="S3.SS3.p1.12.m12.1a"><mi id="S3.SS3.p1.12.m12.1.1" mathvariant="normal" xref="S3.SS3.p1.12.m12.1.1.cmml">Φ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.12.m12.1b"><ci id="S3.SS3.p1.12.m12.1.1.cmml" xref="S3.SS3.p1.12.m12.1.1">Φ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.12.m12.1c">\Phi</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.12.m12.1d">roman_Φ</annotation></semantics></math>. Subsequently, IPI and EPI introduced in Sec.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#S3.SS2" title="3.2 Pose Indicator ‣ 3 Method ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">3.2</span></a> extract the implicit latent <math alttext="f_{i}" class="ltx_Math" display="inline" id="S3.SS3.p1.13.m13.1"><semantics id="S3.SS3.p1.13.m13.1a"><msub id="S3.SS3.p1.13.m13.1.1" xref="S3.SS3.p1.13.m13.1.1.cmml"><mi id="S3.SS3.p1.13.m13.1.1.2" xref="S3.SS3.p1.13.m13.1.1.2.cmml">f</mi><mi id="S3.SS3.p1.13.m13.1.1.3" xref="S3.SS3.p1.13.m13.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.13.m13.1b"><apply id="S3.SS3.p1.13.m13.1.1.cmml" xref="S3.SS3.p1.13.m13.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.13.m13.1.1.1.cmml" xref="S3.SS3.p1.13.m13.1.1">subscript</csymbol><ci id="S3.SS3.p1.13.m13.1.1.2.cmml" xref="S3.SS3.p1.13.m13.1.1.2">𝑓</ci><ci id="S3.SS3.p1.13.m13.1.1.3.cmml" xref="S3.SS3.p1.13.m13.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.13.m13.1c">f_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.13.m13.1d">italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> and explicit latent <math alttext="f_{e}" class="ltx_Math" display="inline" id="S3.SS3.p1.14.m14.1"><semantics id="S3.SS3.p1.14.m14.1a"><msub id="S3.SS3.p1.14.m14.1.1" xref="S3.SS3.p1.14.m14.1.1.cmml"><mi id="S3.SS3.p1.14.m14.1.1.2" xref="S3.SS3.p1.14.m14.1.1.2.cmml">f</mi><mi id="S3.SS3.p1.14.m14.1.1.3" xref="S3.SS3.p1.14.m14.1.1.3.cmml">e</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.14.m14.1b"><apply id="S3.SS3.p1.14.m14.1.1.cmml" xref="S3.SS3.p1.14.m14.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.14.m14.1.1.1.cmml" xref="S3.SS3.p1.14.m14.1.1">subscript</csymbol><ci id="S3.SS3.p1.14.m14.1.1.2.cmml" xref="S3.SS3.p1.14.m14.1.1.2">𝑓</ci><ci id="S3.SS3.p1.14.m14.1.1.3.cmml" xref="S3.SS3.p1.14.m14.1.1.3">𝑒</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.14.m14.1c">f_{e}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.14.m14.1d">italic_f start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT</annotation></semantics></math>, respectively. The explicit <math alttext="f_{e}" class="ltx_Math" display="inline" id="S3.SS3.p1.15.m15.1"><semantics id="S3.SS3.p1.15.m15.1a"><msub id="S3.SS3.p1.15.m15.1.1" xref="S3.SS3.p1.15.m15.1.1.cmml"><mi id="S3.SS3.p1.15.m15.1.1.2" xref="S3.SS3.p1.15.m15.1.1.2.cmml">f</mi><mi id="S3.SS3.p1.15.m15.1.1.3" xref="S3.SS3.p1.15.m15.1.1.3.cmml">e</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.15.m15.1b"><apply id="S3.SS3.p1.15.m15.1.1.cmml" xref="S3.SS3.p1.15.m15.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.15.m15.1.1.1.cmml" xref="S3.SS3.p1.15.m15.1.1">subscript</csymbol><ci id="S3.SS3.p1.15.m15.1.1.2.cmml" xref="S3.SS3.p1.15.m15.1.1.2">𝑓</ci><ci id="S3.SS3.p1.15.m15.1.1.3.cmml" xref="S3.SS3.p1.15.m15.1.1.3">𝑒</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.15.m15.1c">f_{e}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.15.m15.1d">italic_f start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT</annotation></semantics></math> is first concatenated with the noised latent <math alttext="\epsilon" class="ltx_Math" display="inline" id="S3.SS3.p1.16.m16.1"><semantics id="S3.SS3.p1.16.m16.1a"><mi id="S3.SS3.p1.16.m16.1.1" xref="S3.SS3.p1.16.m16.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.16.m16.1b"><ci id="S3.SS3.p1.16.m16.1.1.cmml" xref="S3.SS3.p1.16.m16.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.16.m16.1c">\epsilon</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.16.m16.1d">italic_ϵ</annotation></semantics></math> to obtain the fused features along the channel dimension, which is further stacked with <math alttext="f^{r}_{e}" class="ltx_Math" display="inline" id="S3.SS3.p1.17.m17.1"><semantics id="S3.SS3.p1.17.m17.1a"><msubsup id="S3.SS3.p1.17.m17.1.1" xref="S3.SS3.p1.17.m17.1.1.cmml"><mi id="S3.SS3.p1.17.m17.1.1.2.2" xref="S3.SS3.p1.17.m17.1.1.2.2.cmml">f</mi><mi id="S3.SS3.p1.17.m17.1.1.3" xref="S3.SS3.p1.17.m17.1.1.3.cmml">e</mi><mi id="S3.SS3.p1.17.m17.1.1.2.3" xref="S3.SS3.p1.17.m17.1.1.2.3.cmml">r</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.17.m17.1b"><apply id="S3.SS3.p1.17.m17.1.1.cmml" xref="S3.SS3.p1.17.m17.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.17.m17.1.1.1.cmml" xref="S3.SS3.p1.17.m17.1.1">subscript</csymbol><apply id="S3.SS3.p1.17.m17.1.1.2.cmml" xref="S3.SS3.p1.17.m17.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.17.m17.1.1.2.1.cmml" xref="S3.SS3.p1.17.m17.1.1">superscript</csymbol><ci id="S3.SS3.p1.17.m17.1.1.2.2.cmml" xref="S3.SS3.p1.17.m17.1.1.2.2">𝑓</ci><ci id="S3.SS3.p1.17.m17.1.1.2.3.cmml" xref="S3.SS3.p1.17.m17.1.1.2.3">𝑟</ci></apply><ci id="S3.SS3.p1.17.m17.1.1.3.cmml" xref="S3.SS3.p1.17.m17.1.1.3">𝑒</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.17.m17.1c">f^{r}_{e}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.17.m17.1d">italic_f start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT</annotation></semantics></math> along the temporal dimension, resulting in combined features <math alttext="f_{merge}" class="ltx_Math" display="inline" id="S3.SS3.p1.18.m18.1"><semantics id="S3.SS3.p1.18.m18.1a"><msub id="S3.SS3.p1.18.m18.1.1" xref="S3.SS3.p1.18.m18.1.1.cmml"><mi id="S3.SS3.p1.18.m18.1.1.2" xref="S3.SS3.p1.18.m18.1.1.2.cmml">f</mi><mrow id="S3.SS3.p1.18.m18.1.1.3" xref="S3.SS3.p1.18.m18.1.1.3.cmml"><mi id="S3.SS3.p1.18.m18.1.1.3.2" xref="S3.SS3.p1.18.m18.1.1.3.2.cmml">m</mi><mo id="S3.SS3.p1.18.m18.1.1.3.1" xref="S3.SS3.p1.18.m18.1.1.3.1.cmml">⁢</mo><mi id="S3.SS3.p1.18.m18.1.1.3.3" xref="S3.SS3.p1.18.m18.1.1.3.3.cmml">e</mi><mo id="S3.SS3.p1.18.m18.1.1.3.1a" xref="S3.SS3.p1.18.m18.1.1.3.1.cmml">⁢</mo><mi id="S3.SS3.p1.18.m18.1.1.3.4" xref="S3.SS3.p1.18.m18.1.1.3.4.cmml">r</mi><mo id="S3.SS3.p1.18.m18.1.1.3.1b" xref="S3.SS3.p1.18.m18.1.1.3.1.cmml">⁢</mo><mi id="S3.SS3.p1.18.m18.1.1.3.5" xref="S3.SS3.p1.18.m18.1.1.3.5.cmml">g</mi><mo id="S3.SS3.p1.18.m18.1.1.3.1c" xref="S3.SS3.p1.18.m18.1.1.3.1.cmml">⁢</mo><mi id="S3.SS3.p1.18.m18.1.1.3.6" xref="S3.SS3.p1.18.m18.1.1.3.6.cmml">e</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.18.m18.1b"><apply id="S3.SS3.p1.18.m18.1.1.cmml" xref="S3.SS3.p1.18.m18.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.18.m18.1.1.1.cmml" xref="S3.SS3.p1.18.m18.1.1">subscript</csymbol><ci id="S3.SS3.p1.18.m18.1.1.2.cmml" xref="S3.SS3.p1.18.m18.1.1.2">𝑓</ci><apply id="S3.SS3.p1.18.m18.1.1.3.cmml" xref="S3.SS3.p1.18.m18.1.1.3"><times id="S3.SS3.p1.18.m18.1.1.3.1.cmml" xref="S3.SS3.p1.18.m18.1.1.3.1"></times><ci id="S3.SS3.p1.18.m18.1.1.3.2.cmml" xref="S3.SS3.p1.18.m18.1.1.3.2">𝑚</ci><ci id="S3.SS3.p1.18.m18.1.1.3.3.cmml" xref="S3.SS3.p1.18.m18.1.1.3.3">𝑒</ci><ci id="S3.SS3.p1.18.m18.1.1.3.4.cmml" xref="S3.SS3.p1.18.m18.1.1.3.4">𝑟</ci><ci id="S3.SS3.p1.18.m18.1.1.3.5.cmml" xref="S3.SS3.p1.18.m18.1.1.3.5">𝑔</ci><ci id="S3.SS3.p1.18.m18.1.1.3.6.cmml" xref="S3.SS3.p1.18.m18.1.1.3.6">𝑒</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.18.m18.1c">f_{merge}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.18.m18.1d">italic_f start_POSTSUBSCRIPT italic_m italic_e italic_r italic_g italic_e end_POSTSUBSCRIPT</annotation></semantics></math>. Then, the combined features are fed into the video diffusion model <math alttext="\epsilon_{\theta}" class="ltx_Math" display="inline" id="S3.SS3.p1.19.m19.1"><semantics id="S3.SS3.p1.19.m19.1a"><msub id="S3.SS3.p1.19.m19.1.1" xref="S3.SS3.p1.19.m19.1.1.cmml"><mi id="S3.SS3.p1.19.m19.1.1.2" xref="S3.SS3.p1.19.m19.1.1.2.cmml">ϵ</mi><mi id="S3.SS3.p1.19.m19.1.1.3" xref="S3.SS3.p1.19.m19.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.19.m19.1b"><apply id="S3.SS3.p1.19.m19.1.1.cmml" xref="S3.SS3.p1.19.m19.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.19.m19.1.1.1.cmml" xref="S3.SS3.p1.19.m19.1.1">subscript</csymbol><ci id="S3.SS3.p1.19.m19.1.1.2.cmml" xref="S3.SS3.p1.19.m19.1.1.2">italic-ϵ</ci><ci id="S3.SS3.p1.19.m19.1.1.3.cmml" xref="S3.SS3.p1.19.m19.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.19.m19.1c">\epsilon_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.19.m19.1d">italic_ϵ start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math> for jointly appearance alignment and motion modeling. The diffusion model <math alttext="\epsilon_{\theta}" class="ltx_Math" display="inline" id="S3.SS3.p1.20.m20.1"><semantics id="S3.SS3.p1.20.m20.1a"><msub id="S3.SS3.p1.20.m20.1.1" xref="S3.SS3.p1.20.m20.1.1.cmml"><mi id="S3.SS3.p1.20.m20.1.1.2" xref="S3.SS3.p1.20.m20.1.1.2.cmml">ϵ</mi><mi id="S3.SS3.p1.20.m20.1.1.3" xref="S3.SS3.p1.20.m20.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.20.m20.1b"><apply id="S3.SS3.p1.20.m20.1.1.cmml" xref="S3.SS3.p1.20.m20.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.20.m20.1.1.1.cmml" xref="S3.SS3.p1.20.m20.1.1">subscript</csymbol><ci id="S3.SS3.p1.20.m20.1.1.2.cmml" xref="S3.SS3.p1.20.m20.1.1.2">italic-ϵ</ci><ci id="S3.SS3.p1.20.m20.1.1.3.cmml" xref="S3.SS3.p1.20.m20.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.20.m20.1c">\epsilon_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.20.m20.1d">italic_ϵ start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math> comprises multiple stacked layers of Spatial Attention, Motion Attention and Temporal Attention. The Spatial Attention receives inputs from <math alttext="f_{merge}" class="ltx_Math" display="inline" id="S3.SS3.p1.21.m21.1"><semantics id="S3.SS3.p1.21.m21.1a"><msub id="S3.SS3.p1.21.m21.1.1" xref="S3.SS3.p1.21.m21.1.1.cmml"><mi id="S3.SS3.p1.21.m21.1.1.2" xref="S3.SS3.p1.21.m21.1.1.2.cmml">f</mi><mrow id="S3.SS3.p1.21.m21.1.1.3" xref="S3.SS3.p1.21.m21.1.1.3.cmml"><mi id="S3.SS3.p1.21.m21.1.1.3.2" xref="S3.SS3.p1.21.m21.1.1.3.2.cmml">m</mi><mo id="S3.SS3.p1.21.m21.1.1.3.1" xref="S3.SS3.p1.21.m21.1.1.3.1.cmml">⁢</mo><mi id="S3.SS3.p1.21.m21.1.1.3.3" xref="S3.SS3.p1.21.m21.1.1.3.3.cmml">e</mi><mo id="S3.SS3.p1.21.m21.1.1.3.1a" xref="S3.SS3.p1.21.m21.1.1.3.1.cmml">⁢</mo><mi id="S3.SS3.p1.21.m21.1.1.3.4" xref="S3.SS3.p1.21.m21.1.1.3.4.cmml">r</mi><mo id="S3.SS3.p1.21.m21.1.1.3.1b" xref="S3.SS3.p1.21.m21.1.1.3.1.cmml">⁢</mo><mi id="S3.SS3.p1.21.m21.1.1.3.5" xref="S3.SS3.p1.21.m21.1.1.3.5.cmml">g</mi><mo id="S3.SS3.p1.21.m21.1.1.3.1c" xref="S3.SS3.p1.21.m21.1.1.3.1.cmml">⁢</mo><mi id="S3.SS3.p1.21.m21.1.1.3.6" xref="S3.SS3.p1.21.m21.1.1.3.6.cmml">e</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.21.m21.1b"><apply id="S3.SS3.p1.21.m21.1.1.cmml" xref="S3.SS3.p1.21.m21.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.21.m21.1.1.1.cmml" xref="S3.SS3.p1.21.m21.1.1">subscript</csymbol><ci id="S3.SS3.p1.21.m21.1.1.2.cmml" xref="S3.SS3.p1.21.m21.1.1.2">𝑓</ci><apply id="S3.SS3.p1.21.m21.1.1.3.cmml" xref="S3.SS3.p1.21.m21.1.1.3"><times id="S3.SS3.p1.21.m21.1.1.3.1.cmml" xref="S3.SS3.p1.21.m21.1.1.3.1"></times><ci id="S3.SS3.p1.21.m21.1.1.3.2.cmml" xref="S3.SS3.p1.21.m21.1.1.3.2">𝑚</ci><ci id="S3.SS3.p1.21.m21.1.1.3.3.cmml" xref="S3.SS3.p1.21.m21.1.1.3.3">𝑒</ci><ci id="S3.SS3.p1.21.m21.1.1.3.4.cmml" xref="S3.SS3.p1.21.m21.1.1.3.4">𝑟</ci><ci id="S3.SS3.p1.21.m21.1.1.3.5.cmml" xref="S3.SS3.p1.21.m21.1.1.3.5">𝑔</ci><ci id="S3.SS3.p1.21.m21.1.1.3.6.cmml" xref="S3.SS3.p1.21.m21.1.1.3.6">𝑒</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.21.m21.1c">f_{merge}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.21.m21.1d">italic_f start_POSTSUBSCRIPT italic_m italic_e italic_r italic_g italic_e end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="f^{r}_{i}" class="ltx_Math" display="inline" id="S3.SS3.p1.22.m22.1"><semantics id="S3.SS3.p1.22.m22.1a"><msubsup id="S3.SS3.p1.22.m22.1.1" xref="S3.SS3.p1.22.m22.1.1.cmml"><mi id="S3.SS3.p1.22.m22.1.1.2.2" xref="S3.SS3.p1.22.m22.1.1.2.2.cmml">f</mi><mi id="S3.SS3.p1.22.m22.1.1.3" xref="S3.SS3.p1.22.m22.1.1.3.cmml">i</mi><mi id="S3.SS3.p1.22.m22.1.1.2.3" xref="S3.SS3.p1.22.m22.1.1.2.3.cmml">r</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.22.m22.1b"><apply id="S3.SS3.p1.22.m22.1.1.cmml" xref="S3.SS3.p1.22.m22.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.22.m22.1.1.1.cmml" xref="S3.SS3.p1.22.m22.1.1">subscript</csymbol><apply id="S3.SS3.p1.22.m22.1.1.2.cmml" xref="S3.SS3.p1.22.m22.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.22.m22.1.1.2.1.cmml" xref="S3.SS3.p1.22.m22.1.1">superscript</csymbol><ci id="S3.SS3.p1.22.m22.1.1.2.2.cmml" xref="S3.SS3.p1.22.m22.1.1.2.2">𝑓</ci><ci id="S3.SS3.p1.22.m22.1.1.2.3.cmml" xref="S3.SS3.p1.22.m22.1.1.2.3">𝑟</ci></apply><ci id="S3.SS3.p1.22.m22.1.1.3.cmml" xref="S3.SS3.p1.22.m22.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.22.m22.1c">f^{r}_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.22.m22.1d">italic_f start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> and fuses the identity condition from <math alttext="I^{r}" class="ltx_Math" display="inline" id="S3.SS3.p1.23.m23.1"><semantics id="S3.SS3.p1.23.m23.1a"><msup id="S3.SS3.p1.23.m23.1.1" xref="S3.SS3.p1.23.m23.1.1.cmml"><mi id="S3.SS3.p1.23.m23.1.1.2" xref="S3.SS3.p1.23.m23.1.1.2.cmml">I</mi><mi id="S3.SS3.p1.23.m23.1.1.3" xref="S3.SS3.p1.23.m23.1.1.3.cmml">r</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.23.m23.1b"><apply id="S3.SS3.p1.23.m23.1.1.cmml" xref="S3.SS3.p1.23.m23.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.23.m23.1.1.1.cmml" xref="S3.SS3.p1.23.m23.1.1">superscript</csymbol><ci id="S3.SS3.p1.23.m23.1.1.2.cmml" xref="S3.SS3.p1.23.m23.1.1.2">𝐼</ci><ci id="S3.SS3.p1.23.m23.1.1.3.cmml" xref="S3.SS3.p1.23.m23.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.23.m23.1c">I^{r}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.23.m23.1d">italic_I start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT</annotation></semantics></math> with the motion condition from <math alttext="I^{d}" class="ltx_Math" display="inline" id="S3.SS3.p1.24.m24.1"><semantics id="S3.SS3.p1.24.m24.1a"><msup id="S3.SS3.p1.24.m24.1.1" xref="S3.SS3.p1.24.m24.1.1.cmml"><mi id="S3.SS3.p1.24.m24.1.1.2" xref="S3.SS3.p1.24.m24.1.1.2.cmml">I</mi><mi id="S3.SS3.p1.24.m24.1.1.3" xref="S3.SS3.p1.24.m24.1.1.3.cmml">d</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.24.m24.1b"><apply id="S3.SS3.p1.24.m24.1.1.cmml" xref="S3.SS3.p1.24.m24.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.24.m24.1.1.1.cmml" xref="S3.SS3.p1.24.m24.1.1">superscript</csymbol><ci id="S3.SS3.p1.24.m24.1.1.2.cmml" xref="S3.SS3.p1.24.m24.1.1.2">𝐼</ci><ci id="S3.SS3.p1.24.m24.1.1.3.cmml" xref="S3.SS3.p1.24.m24.1.1.3">𝑑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.24.m24.1c">I^{d}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.24.m24.1d">italic_I start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT</annotation></semantics></math> through cross-attention (<span class="ltx_text ltx_markedasmath" id="S3.SS3.p1.29.2">CA</span>), producing an intermediate representation <math alttext="x" class="ltx_Math" display="inline" id="S3.SS3.p1.26.m26.1"><semantics id="S3.SS3.p1.26.m26.1a"><mi id="S3.SS3.p1.26.m26.1.1" xref="S3.SS3.p1.26.m26.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.26.m26.1b"><ci id="S3.SS3.p1.26.m26.1.1.cmml" xref="S3.SS3.p1.26.m26.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.26.m26.1c">x</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.26.m26.1d">italic_x</annotation></semantics></math>. To further enhance motion consistency, the implicit representation <math alttext="f_{i}" class="ltx_Math" display="inline" id="S3.SS3.p1.27.m27.1"><semantics id="S3.SS3.p1.27.m27.1a"><msub id="S3.SS3.p1.27.m27.1.1" xref="S3.SS3.p1.27.m27.1.1.cmml"><mi id="S3.SS3.p1.27.m27.1.1.2" xref="S3.SS3.p1.27.m27.1.1.2.cmml">f</mi><mi id="S3.SS3.p1.27.m27.1.1.3" xref="S3.SS3.p1.27.m27.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.27.m27.1b"><apply id="S3.SS3.p1.27.m27.1.1.cmml" xref="S3.SS3.p1.27.m27.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.27.m27.1.1.1.cmml" xref="S3.SS3.p1.27.m27.1.1">subscript</csymbol><ci id="S3.SS3.p1.27.m27.1.1.2.cmml" xref="S3.SS3.p1.27.m27.1.1.2">𝑓</ci><ci id="S3.SS3.p1.27.m27.1.1.3.cmml" xref="S3.SS3.p1.27.m27.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.27.m27.1c">f_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.27.m27.1d">italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> is fed into the Motion Attention module, along with <math alttext="x" class="ltx_Math" display="inline" id="S3.SS3.p1.28.m28.1"><semantics id="S3.SS3.p1.28.m28.1a"><mi id="S3.SS3.p1.28.m28.1.1" xref="S3.SS3.p1.28.m28.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.28.m28.1b"><ci id="S3.SS3.p1.28.m28.1.1.cmml" xref="S3.SS3.p1.28.m28.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.28.m28.1c">x</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.28.m28.1d">italic_x</annotation></semantics></math> in the form of a residual connection, resulting in the representation <math alttext="x^{\prime}=x+\text{CA}(x,f_{i})" class="ltx_Math" display="inline" id="S3.SS3.p1.29.m29.2"><semantics id="S3.SS3.p1.29.m29.2a"><mrow id="S3.SS3.p1.29.m29.2.2" xref="S3.SS3.p1.29.m29.2.2.cmml"><msup id="S3.SS3.p1.29.m29.2.2.3" xref="S3.SS3.p1.29.m29.2.2.3.cmml"><mi id="S3.SS3.p1.29.m29.2.2.3.2" xref="S3.SS3.p1.29.m29.2.2.3.2.cmml">x</mi><mo id="S3.SS3.p1.29.m29.2.2.3.3" xref="S3.SS3.p1.29.m29.2.2.3.3.cmml">′</mo></msup><mo id="S3.SS3.p1.29.m29.2.2.2" xref="S3.SS3.p1.29.m29.2.2.2.cmml">=</mo><mrow id="S3.SS3.p1.29.m29.2.2.1" xref="S3.SS3.p1.29.m29.2.2.1.cmml"><mi id="S3.SS3.p1.29.m29.2.2.1.3" xref="S3.SS3.p1.29.m29.2.2.1.3.cmml">x</mi><mo id="S3.SS3.p1.29.m29.2.2.1.2" xref="S3.SS3.p1.29.m29.2.2.1.2.cmml">+</mo><mrow id="S3.SS3.p1.29.m29.2.2.1.1" xref="S3.SS3.p1.29.m29.2.2.1.1.cmml"><mtext id="S3.SS3.p1.29.m29.2.2.1.1.3" xref="S3.SS3.p1.29.m29.2.2.1.1.3a.cmml">CA</mtext><mo id="S3.SS3.p1.29.m29.2.2.1.1.2" xref="S3.SS3.p1.29.m29.2.2.1.1.2.cmml">⁢</mo><mrow id="S3.SS3.p1.29.m29.2.2.1.1.1.1" xref="S3.SS3.p1.29.m29.2.2.1.1.1.2.cmml"><mo id="S3.SS3.p1.29.m29.2.2.1.1.1.1.2" stretchy="false" xref="S3.SS3.p1.29.m29.2.2.1.1.1.2.cmml">(</mo><mi id="S3.SS3.p1.29.m29.1.1" xref="S3.SS3.p1.29.m29.1.1.cmml">x</mi><mo id="S3.SS3.p1.29.m29.2.2.1.1.1.1.3" xref="S3.SS3.p1.29.m29.2.2.1.1.1.2.cmml">,</mo><msub id="S3.SS3.p1.29.m29.2.2.1.1.1.1.1" xref="S3.SS3.p1.29.m29.2.2.1.1.1.1.1.cmml"><mi id="S3.SS3.p1.29.m29.2.2.1.1.1.1.1.2" xref="S3.SS3.p1.29.m29.2.2.1.1.1.1.1.2.cmml">f</mi><mi id="S3.SS3.p1.29.m29.2.2.1.1.1.1.1.3" xref="S3.SS3.p1.29.m29.2.2.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS3.p1.29.m29.2.2.1.1.1.1.4" stretchy="false" xref="S3.SS3.p1.29.m29.2.2.1.1.1.2.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.29.m29.2b"><apply id="S3.SS3.p1.29.m29.2.2.cmml" xref="S3.SS3.p1.29.m29.2.2"><eq id="S3.SS3.p1.29.m29.2.2.2.cmml" xref="S3.SS3.p1.29.m29.2.2.2"></eq><apply id="S3.SS3.p1.29.m29.2.2.3.cmml" xref="S3.SS3.p1.29.m29.2.2.3"><csymbol cd="ambiguous" id="S3.SS3.p1.29.m29.2.2.3.1.cmml" xref="S3.SS3.p1.29.m29.2.2.3">superscript</csymbol><ci id="S3.SS3.p1.29.m29.2.2.3.2.cmml" xref="S3.SS3.p1.29.m29.2.2.3.2">𝑥</ci><ci id="S3.SS3.p1.29.m29.2.2.3.3.cmml" xref="S3.SS3.p1.29.m29.2.2.3.3">′</ci></apply><apply id="S3.SS3.p1.29.m29.2.2.1.cmml" xref="S3.SS3.p1.29.m29.2.2.1"><plus id="S3.SS3.p1.29.m29.2.2.1.2.cmml" xref="S3.SS3.p1.29.m29.2.2.1.2"></plus><ci id="S3.SS3.p1.29.m29.2.2.1.3.cmml" xref="S3.SS3.p1.29.m29.2.2.1.3">𝑥</ci><apply id="S3.SS3.p1.29.m29.2.2.1.1.cmml" xref="S3.SS3.p1.29.m29.2.2.1.1"><times id="S3.SS3.p1.29.m29.2.2.1.1.2.cmml" xref="S3.SS3.p1.29.m29.2.2.1.1.2"></times><ci id="S3.SS3.p1.29.m29.2.2.1.1.3a.cmml" xref="S3.SS3.p1.29.m29.2.2.1.1.3"><mtext id="S3.SS3.p1.29.m29.2.2.1.1.3.cmml" xref="S3.SS3.p1.29.m29.2.2.1.1.3">CA</mtext></ci><interval closure="open" id="S3.SS3.p1.29.m29.2.2.1.1.1.2.cmml" xref="S3.SS3.p1.29.m29.2.2.1.1.1.1"><ci id="S3.SS3.p1.29.m29.1.1.cmml" xref="S3.SS3.p1.29.m29.1.1">𝑥</ci><apply id="S3.SS3.p1.29.m29.2.2.1.1.1.1.1.cmml" xref="S3.SS3.p1.29.m29.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.29.m29.2.2.1.1.1.1.1.1.cmml" xref="S3.SS3.p1.29.m29.2.2.1.1.1.1.1">subscript</csymbol><ci id="S3.SS3.p1.29.m29.2.2.1.1.1.1.1.2.cmml" xref="S3.SS3.p1.29.m29.2.2.1.1.1.1.1.2">𝑓</ci><ci id="S3.SS3.p1.29.m29.2.2.1.1.1.1.1.3.cmml" xref="S3.SS3.p1.29.m29.2.2.1.1.1.1.1.3">𝑖</ci></apply></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.29.m29.2c">x^{\prime}=x+\text{CA}(x,f_{i})</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.29.m29.2d">italic_x start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT = italic_x + CA ( italic_x , italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math>.
Inpsired by the linear time efficiency of Mamba&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Gu &amp; Dao (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib14" title="">2023</a>)</cite> in long sequence processing, we employ it as Temporal Attention module to maintain the temporal consistency.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.p2.1.2">Training and Inference.</span>
<span class="ltx_text" id="S3.SS3.p2.1.1" style="color:#000000;">To improve the model’s robustness against pose and reference image misalignments, we adopt two key training schemes. First, we set a high transformation probability <math alttext="\lambda" class="ltx_Math" display="inline" id="S3.SS3.p2.1.1.m1.1"><semantics id="S3.SS3.p2.1.1.m1.1a"><mi id="S3.SS3.p2.1.1.m1.1.1" mathcolor="#000000" xref="S3.SS3.p2.1.1.m1.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.1.m1.1b"><ci id="S3.SS3.p2.1.1.m1.1.1.cmml" xref="S3.SS3.p2.1.1.m1.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.1.m1.1c">\lambda</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.1.1.m1.1d">italic_λ</annotation></semantics></math> (over 98%) in the EPI, enabling the model to handle a wide range of misalignment scenarios. Second, we apply random dropout to the input conditions at a predefined rate&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Wang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib61" title="">2024b</a>)</cite>. After that, while the reference image and driven video are from the same human dancing video during training, in the inference phase (Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#A1.F9" title="Figure 9 ‣ Appendix A Network Details ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">9</span></a> (b)), <span class="ltx_text ltx_font_typewriter" id="S3.SS3.p2.1.1.1">Animate-X</span> can handle an arbitrary reference image and driven video, which may differ in appearance.</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure ltx_align_floatright" id="S3.F3"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="616" id="S3.F3.g1" src="./animate-x_files/x3.png" width="830">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Examples from our <math alttext="A^{2}" class="ltx_Math" display="inline" id="S3.F3.2.m1.1"><semantics id="S3.F3.2.m1.1b"><msup id="S3.F3.2.m1.1.1" xref="S3.F3.2.m1.1.1.cmml"><mi id="S3.F3.2.m1.1.1.2" xref="S3.F3.2.m1.1.1.2.cmml">A</mi><mn id="S3.F3.2.m1.1.1.3" xref="S3.F3.2.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S3.F3.2.m1.1c"><apply id="S3.F3.2.m1.1.1.cmml" xref="S3.F3.2.m1.1.1"><csymbol cd="ambiguous" id="S3.F3.2.m1.1.1.1.cmml" xref="S3.F3.2.m1.1.1">superscript</csymbol><ci id="S3.F3.2.m1.1.1.2.cmml" xref="S3.F3.2.m1.1.1.2">𝐴</ci><cn id="S3.F3.2.m1.1.1.3.cmml" type="integer" xref="S3.F3.2.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.2.m1.1d">A^{2}</annotation><annotation encoding="application/x-llamapun" id="S3.F3.2.m1.1e">italic_A start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_typewriter" id="S3.F3.4.1">Bench</span>.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span><math alttext="A^{2}" class="ltx_Math" display="inline" id="S3.SS4.1.m1.1"><semantics id="S3.SS4.1.m1.1b"><msup id="S3.SS4.1.m1.1.1" xref="S3.SS4.1.m1.1.1.cmml"><mi id="S3.SS4.1.m1.1.1.2" xref="S3.SS4.1.m1.1.1.2.cmml">A</mi><mn id="S3.SS4.1.m1.1.1.3" xref="S3.SS4.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S3.SS4.1.m1.1c"><apply id="S3.SS4.1.m1.1.1.cmml" xref="S3.SS4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS4.1.m1.1.1.1.cmml" xref="S3.SS4.1.m1.1.1">superscript</csymbol><ci id="S3.SS4.1.m1.1.1.2.cmml" xref="S3.SS4.1.m1.1.1.2">𝐴</ci><cn id="S3.SS4.1.m1.1.1.3.cmml" type="integer" xref="S3.SS4.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.1.m1.1d">A^{2}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.1.m1.1e">italic_A start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_typewriter" id="S3.SS4.2.1">Bench</span>
</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.1">The main task of our <span class="ltx_text ltx_font_typewriter" id="S3.SS4.p1.1.1">Animate-X</span> is to animate an anthropomorphic character with vivid and smooth motions. However, current publicly available datasets&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Jafarian &amp; Park (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib24" title="">2021</a>); Zablotskaia et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib75" title="">2019a</a>)</cite> primarily focus on human animation and fall short in capturing a broad range of anthropomorphic characters and corresponding dancing videos. This gap makes these datasets and benchmarks unsuitable for quantitatively evaluating different methods in anthropomorphic character animation.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.SS4.p2">
<p class="ltx_p" id="S3.SS4.p2.1">To bridge this gap, we propose the <span class="ltx_text ltx_font_bold" id="S3.SS4.p2.1.1">A</span>nimated <span class="ltx_text ltx_font_bold" id="S3.SS4.p2.1.2">A</span>nthropomorphic character <span class="ltx_text ltx_font_bold" id="S3.SS4.p2.1.3">Bench</span>mark (<math alttext="A^{2}" class="ltx_Math" display="inline" id="S3.SS4.p2.1.m1.1"><semantics id="S3.SS4.p2.1.m1.1a"><msup id="S3.SS4.p2.1.m1.1.1" xref="S3.SS4.p2.1.m1.1.1.cmml"><mi id="S3.SS4.p2.1.m1.1.1.2" xref="S3.SS4.p2.1.m1.1.1.2.cmml">A</mi><mn id="S3.SS4.p2.1.m1.1.1.3" xref="S3.SS4.p2.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.1.m1.1b"><apply id="S3.SS4.p2.1.m1.1.1.cmml" xref="S3.SS4.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p2.1.m1.1.1.1.cmml" xref="S3.SS4.p2.1.m1.1.1">superscript</csymbol><ci id="S3.SS4.p2.1.m1.1.1.2.cmml" xref="S3.SS4.p2.1.m1.1.1.2">𝐴</ci><cn id="S3.SS4.p2.1.m1.1.1.3.cmml" type="integer" xref="S3.SS4.p2.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.1.m1.1c">A^{2}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p2.1.m1.1d">italic_A start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_typewriter" id="S3.SS4.p2.1.4">Bench</span>) to comprehensively evaluate the performance of different methods. Specifically, we first provide a prompt template to GPT-4&nbsp;<cite class="ltx_cite ltx_citemacro_cite">OpenAI (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib33" title="">2024</a>)</cite> and leverage it to generate 500 prompts, each of which contains a textual description of an anthropomorphic character. Please refer to Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#A2.SS2" title="B.2 Data Details ‣ Appendix B Benchmark Details ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">B.2</span></a> for details. Inspired by the powerful image generation capability of KLing AI&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Technology (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib53" title="">2024</a>)</cite>, we feed the produced prompts into its Text-To-Image module, which synthesizes the corresponding anthropomorphic character images according to the given text prompts. Subsequently, the Image-To-Video module is employed to further make the characters in the images dance vividly. For each prompt, we repeat the process for 4 times and filter the most satisfactory image-video pairs as the output corresponding to this prompt. In this manner, we collect 500 anthropomorphic characters and the corresponding dance videos, as shown in Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#S3.F3" title="Figure 3 ‣ 3.3 Framework and Implement Details ‣ 3 Method ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">3</span></a>. Please refer to Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#A2" title="Appendix B Benchmark Details ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">B</span></a> for details.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure ltx_align_floatright" id="S3.F4"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="212" id="S3.F4.g1" src="./animate-x_files/setting_demo.png" width="598">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>The illustration of comparison settings.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="S3.T1">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T1.11" style="width:433.6pt;height:86.9pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-100.0pt,19.9pt) scale(0.684390561154974,0.684390561154974) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S3.T1.11.11">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T1.7.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S3.T1.7.7.7.8" style="padding-left:2.5pt;padding-right:2.5pt;">Method</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S3.T1.1.1.1.1" style="padding-left:2.5pt;padding-right:2.5pt;">PSNR* <math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T1.1.1.1.1.m1.1"><semantics id="S3.T1.1.1.1.1.m1.1a"><mo id="S3.T1.1.1.1.1.m1.1.1" stretchy="false" xref="S3.T1.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T1.1.1.1.1.m1.1b"><ci id="S3.T1.1.1.1.1.m1.1.1.cmml" xref="S3.T1.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.1.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S3.T1.1.1.1.1.m1.1d">↑</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S3.T1.2.2.2.2" style="padding-left:2.5pt;padding-right:2.5pt;">SSIM <math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T1.2.2.2.2.m1.1"><semantics id="S3.T1.2.2.2.2.m1.1a"><mo id="S3.T1.2.2.2.2.m1.1.1" stretchy="false" xref="S3.T1.2.2.2.2.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T1.2.2.2.2.m1.1b"><ci id="S3.T1.2.2.2.2.m1.1.1.cmml" xref="S3.T1.2.2.2.2.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.2.2.2.2.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S3.T1.2.2.2.2.m1.1d">↑</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S3.T1.3.3.3.3" style="padding-left:2.5pt;padding-right:2.5pt;">L1 <math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T1.3.3.3.3.m1.1"><semantics id="S3.T1.3.3.3.3.m1.1a"><mo id="S3.T1.3.3.3.3.m1.1.1" stretchy="false" xref="S3.T1.3.3.3.3.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T1.3.3.3.3.m1.1b"><ci id="S3.T1.3.3.3.3.m1.1.1.cmml" xref="S3.T1.3.3.3.3.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.3.3.3.3.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S3.T1.3.3.3.3.m1.1d">↑</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S3.T1.4.4.4.4" style="padding-left:2.5pt;padding-right:2.5pt;">LPIPS <math alttext="\downarrow" class="ltx_Math" display="inline" id="S3.T1.4.4.4.4.m1.1"><semantics id="S3.T1.4.4.4.4.m1.1a"><mo id="S3.T1.4.4.4.4.m1.1.1" stretchy="false" xref="S3.T1.4.4.4.4.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S3.T1.4.4.4.4.m1.1b"><ci id="S3.T1.4.4.4.4.m1.1.1.cmml" xref="S3.T1.4.4.4.4.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.4.4.4.4.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S3.T1.4.4.4.4.m1.1d">↓</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S3.T1.5.5.5.5" style="padding-left:2.5pt;padding-right:2.5pt;">FID <math alttext="\downarrow" class="ltx_Math" display="inline" id="S3.T1.5.5.5.5.m1.1"><semantics id="S3.T1.5.5.5.5.m1.1a"><mo id="S3.T1.5.5.5.5.m1.1.1" stretchy="false" xref="S3.T1.5.5.5.5.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S3.T1.5.5.5.5.m1.1b"><ci id="S3.T1.5.5.5.5.m1.1.1.cmml" xref="S3.T1.5.5.5.5.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.5.5.5.5.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S3.T1.5.5.5.5.m1.1d">↓</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S3.T1.6.6.6.6" style="padding-left:2.5pt;padding-right:2.5pt;">FID-VID <math alttext="\downarrow" class="ltx_Math" display="inline" id="S3.T1.6.6.6.6.m1.1"><semantics id="S3.T1.6.6.6.6.m1.1a"><mo id="S3.T1.6.6.6.6.m1.1.1" stretchy="false" xref="S3.T1.6.6.6.6.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S3.T1.6.6.6.6.m1.1b"><ci id="S3.T1.6.6.6.6.m1.1.1.cmml" xref="S3.T1.6.6.6.6.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.6.6.6.6.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S3.T1.6.6.6.6.m1.1d">↓</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S3.T1.7.7.7.7" style="padding-left:2.5pt;padding-right:2.5pt;">FVD <math alttext="\downarrow" class="ltx_Math" display="inline" id="S3.T1.7.7.7.7.m1.1"><semantics id="S3.T1.7.7.7.7.m1.1a"><mo id="S3.T1.7.7.7.7.m1.1.1" stretchy="false" xref="S3.T1.7.7.7.7.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S3.T1.7.7.7.7.m1.1b"><ci id="S3.T1.7.7.7.7.m1.1.1.cmml" xref="S3.T1.7.7.7.7.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.7.7.7.7.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S3.T1.7.7.7.7.m1.1d">↓</annotation></semantics></math>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.11.11.12.1">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.11.11.12.1.1" style="padding-left:2.5pt;padding-right:2.5pt;">Moore-AnimateAnyone&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Corporation (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib11" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.11.11.12.1.2" style="padding-left:2.5pt;padding-right:2.5pt;">9.86</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.11.11.12.1.3" style="padding-left:2.5pt;padding-right:2.5pt;">0.299</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.11.11.12.1.4" style="padding-left:2.5pt;padding-right:2.5pt;">1.58E-04</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.11.11.12.1.5" style="padding-left:2.5pt;padding-right:2.5pt;">0.626</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.11.11.12.1.6" style="padding-left:2.5pt;padding-right:2.5pt;">50.97</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.11.11.12.1.7" style="padding-left:2.5pt;padding-right:2.5pt;">75.11</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.11.11.12.1.8" style="padding-left:2.5pt;padding-right:2.5pt;">1367.84</td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.8.8">
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T1.8.8.8.1" style="padding-left:2.5pt;padding-right:2.5pt;">MimicMotion&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Zhang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib82" title="">2024</a>)</cite> <math alttext="{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(ArXiv24)}}}" class="ltx_Math" display="inline" id="S3.T1.8.8.8.1.m1.1"><semantics id="S3.T1.8.8.8.1.m1.1a"><msub id="S3.T1.8.8.8.1.m1.1.1" xref="S3.T1.8.8.8.1.m1.1.1.cmml"><mi id="S3.T1.8.8.8.1.m1.1.1a" xref="S3.T1.8.8.8.1.m1.1.1.cmml"></mi><mtext id="S3.T1.8.8.8.1.m1.1.1.1" mathcolor="#808080" xref="S3.T1.8.8.8.1.m1.1.1.1a.cmml">(ArXiv24)</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.T1.8.8.8.1.m1.1b"><apply id="S3.T1.8.8.8.1.m1.1.1.cmml" xref="S3.T1.8.8.8.1.m1.1.1"><ci id="S3.T1.8.8.8.1.m1.1.1.1a.cmml" xref="S3.T1.8.8.8.1.m1.1.1.1"><mtext id="S3.T1.8.8.8.1.m1.1.1.1.cmml" mathsize="70%" xref="S3.T1.8.8.8.1.m1.1.1.1">(ArXiv24)</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.8.8.8.1.m1.1c">{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(ArXiv24)}}}</annotation><annotation encoding="application/x-llamapun" id="S3.T1.8.8.8.1.m1.1d">start_FLOATSUBSCRIPT (ArXiv24) end_FLOATSUBSCRIPT</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.8.8.2" style="padding-left:2.5pt;padding-right:2.5pt;">10.18</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.8.8.3" style="padding-left:2.5pt;padding-right:2.5pt;">0.318</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.8.8.4" style="padding-left:2.5pt;padding-right:2.5pt;">1.51E-04</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.8.8.5" style="padding-left:2.5pt;padding-right:2.5pt;">0.622</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.8.8.8.6" style="padding-left:2.5pt;padding-right:2.5pt;">122.92</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.8.8.7" style="padding-left:2.5pt;padding-right:2.5pt;">129.40</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.8.8.8" style="padding-left:2.5pt;padding-right:2.5pt;">2250.13</td>
</tr>
<tr class="ltx_tr" id="S3.T1.9.9.9">
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T1.9.9.9.1" style="padding-left:2.5pt;padding-right:2.5pt;">ControlNeXt&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Peng et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib34" title="">2024</a>)</cite> <math alttext="{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(ArXiv24)}}}" class="ltx_Math" display="inline" id="S3.T1.9.9.9.1.m1.1"><semantics id="S3.T1.9.9.9.1.m1.1a"><msub id="S3.T1.9.9.9.1.m1.1.1" xref="S3.T1.9.9.9.1.m1.1.1.cmml"><mi id="S3.T1.9.9.9.1.m1.1.1a" xref="S3.T1.9.9.9.1.m1.1.1.cmml"></mi><mtext id="S3.T1.9.9.9.1.m1.1.1.1" mathcolor="#808080" xref="S3.T1.9.9.9.1.m1.1.1.1a.cmml">(ArXiv24)</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.T1.9.9.9.1.m1.1b"><apply id="S3.T1.9.9.9.1.m1.1.1.cmml" xref="S3.T1.9.9.9.1.m1.1.1"><ci id="S3.T1.9.9.9.1.m1.1.1.1a.cmml" xref="S3.T1.9.9.9.1.m1.1.1.1"><mtext id="S3.T1.9.9.9.1.m1.1.1.1.cmml" mathsize="70%" xref="S3.T1.9.9.9.1.m1.1.1.1">(ArXiv24)</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.9.9.9.1.m1.1c">{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(ArXiv24)}}}</annotation><annotation encoding="application/x-llamapun" id="S3.T1.9.9.9.1.m1.1d">start_FLOATSUBSCRIPT (ArXiv24) end_FLOATSUBSCRIPT</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.9.9.9.2" style="padding-left:2.5pt;padding-right:2.5pt;">10.88</td>
<td class="ltx_td ltx_align_center" id="S3.T1.9.9.9.3" style="padding-left:2.5pt;padding-right:2.5pt;">0.379</td>
<td class="ltx_td ltx_align_center" id="S3.T1.9.9.9.4" style="padding-left:2.5pt;padding-right:2.5pt;">1.38E-04</td>
<td class="ltx_td ltx_align_center" id="S3.T1.9.9.9.5" style="padding-left:2.5pt;padding-right:2.5pt;">0.572</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.9.9.9.6" style="padding-left:2.5pt;padding-right:2.5pt;">68.15</td>
<td class="ltx_td ltx_align_center" id="S3.T1.9.9.9.7" style="padding-left:2.5pt;padding-right:2.5pt;">81.05</td>
<td class="ltx_td ltx_align_center" id="S3.T1.9.9.9.8" style="padding-left:2.5pt;padding-right:2.5pt;">1652.09</td>
</tr>
<tr class="ltx_tr" id="S3.T1.10.10.10">
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T1.10.10.10.1" style="padding-left:2.5pt;padding-right:2.5pt;">MusePose&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Tong et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib54" title="">2024</a>)</cite> <math alttext="{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(ArXiv24)}}}" class="ltx_Math" display="inline" id="S3.T1.10.10.10.1.m1.1"><semantics id="S3.T1.10.10.10.1.m1.1a"><msub id="S3.T1.10.10.10.1.m1.1.1" xref="S3.T1.10.10.10.1.m1.1.1.cmml"><mi id="S3.T1.10.10.10.1.m1.1.1a" xref="S3.T1.10.10.10.1.m1.1.1.cmml"></mi><mtext id="S3.T1.10.10.10.1.m1.1.1.1" mathcolor="#808080" xref="S3.T1.10.10.10.1.m1.1.1.1a.cmml">(ArXiv24)</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.T1.10.10.10.1.m1.1b"><apply id="S3.T1.10.10.10.1.m1.1.1.cmml" xref="S3.T1.10.10.10.1.m1.1.1"><ci id="S3.T1.10.10.10.1.m1.1.1.1a.cmml" xref="S3.T1.10.10.10.1.m1.1.1.1"><mtext id="S3.T1.10.10.10.1.m1.1.1.1.cmml" mathsize="70%" xref="S3.T1.10.10.10.1.m1.1.1.1">(ArXiv24)</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.10.10.10.1.m1.1c">{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(ArXiv24)}}}</annotation><annotation encoding="application/x-llamapun" id="S3.T1.10.10.10.1.m1.1d">start_FLOATSUBSCRIPT (ArXiv24) end_FLOATSUBSCRIPT</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.10.10.10.2" style="padding-left:2.5pt;padding-right:2.5pt;">11.05</td>
<td class="ltx_td ltx_align_center" id="S3.T1.10.10.10.3" style="padding-left:2.5pt;padding-right:2.5pt;">0.397</td>
<td class="ltx_td ltx_align_center" id="S3.T1.10.10.10.4" style="padding-left:2.5pt;padding-right:2.5pt;">1.27E-04</td>
<td class="ltx_td ltx_align_center" id="S3.T1.10.10.10.5" style="padding-left:2.5pt;padding-right:2.5pt;">0.549</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.10.10.10.6" style="padding-left:2.5pt;padding-right:2.5pt;">100.91</td>
<td class="ltx_td ltx_align_center" id="S3.T1.10.10.10.7" style="padding-left:2.5pt;padding-right:2.5pt;">114.15</td>
<td class="ltx_td ltx_align_center" id="S3.T1.10.10.10.8" style="padding-left:2.5pt;padding-right:2.5pt;">1760.46</td>
</tr>
<tr class="ltx_tr" id="S3.T1.11.11.11">
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T1.11.11.11.1" style="padding-left:2.5pt;padding-right:2.5pt;">Unianimate&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Wang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib61" title="">2024b</a>)</cite> <math alttext="{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(ArXiv24)}}}" class="ltx_Math" display="inline" id="S3.T1.11.11.11.1.m1.1"><semantics id="S3.T1.11.11.11.1.m1.1a"><msub id="S3.T1.11.11.11.1.m1.1.1" xref="S3.T1.11.11.11.1.m1.1.1.cmml"><mi id="S3.T1.11.11.11.1.m1.1.1a" xref="S3.T1.11.11.11.1.m1.1.1.cmml"></mi><mtext id="S3.T1.11.11.11.1.m1.1.1.1" mathcolor="#808080" xref="S3.T1.11.11.11.1.m1.1.1.1a.cmml">(ArXiv24)</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.T1.11.11.11.1.m1.1b"><apply id="S3.T1.11.11.11.1.m1.1.1.cmml" xref="S3.T1.11.11.11.1.m1.1.1"><ci id="S3.T1.11.11.11.1.m1.1.1.1a.cmml" xref="S3.T1.11.11.11.1.m1.1.1.1"><mtext id="S3.T1.11.11.11.1.m1.1.1.1.cmml" mathsize="70%" xref="S3.T1.11.11.11.1.m1.1.1.1">(ArXiv24)</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.11.11.11.1.m1.1c">{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(ArXiv24)}}}</annotation><annotation encoding="application/x-llamapun" id="S3.T1.11.11.11.1.m1.1d">start_FLOATSUBSCRIPT (ArXiv24) end_FLOATSUBSCRIPT</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.11.11.11.2" style="padding-left:2.5pt;padding-right:2.5pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T1.11.11.11.2.1">11.82</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.11.11.11.3" style="padding-left:2.5pt;padding-right:2.5pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T1.11.11.11.3.1">0.398</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.11.11.11.4" style="padding-left:2.5pt;padding-right:2.5pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T1.11.11.11.4.1">1.24E-04</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.11.11.11.5" style="padding-left:2.5pt;padding-right:2.5pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T1.11.11.11.5.1">0.532</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.11.11.11.6" style="padding-left:2.5pt;padding-right:2.5pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T1.11.11.11.6.1">48.47</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.11.11.11.7" style="padding-left:2.5pt;padding-right:2.5pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T1.11.11.11.7.1">61.03</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.11.11.11.8" style="padding-left:2.5pt;padding-right:2.5pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T1.11.11.11.8.1">1156.36</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.11.11.13.2" style="background-color:#F0F0F0;">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S3.T1.11.11.13.2.1" style="padding-left:2.5pt;padding-right:2.5pt;"><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="S3.T1.11.11.13.2.1.1" style="background-color:#F0F0F0;">Animate-X</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S3.T1.11.11.13.2.2" style="padding-left:2.5pt;padding-right:2.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.11.11.13.2.2.1" style="background-color:#F0F0F0;">13.60</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S3.T1.11.11.13.2.3" style="padding-left:2.5pt;padding-right:2.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.11.11.13.2.3.1" style="background-color:#F0F0F0;">0.452</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S3.T1.11.11.13.2.4" style="padding-left:2.5pt;padding-right:2.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.11.11.13.2.4.1" style="background-color:#F0F0F0;">1.02E-04</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S3.T1.11.11.13.2.5" style="padding-left:2.5pt;padding-right:2.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.11.11.13.2.5.1" style="background-color:#F0F0F0;">0.430</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S3.T1.11.11.13.2.6" style="padding-left:2.5pt;padding-right:2.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.11.11.13.2.6.1" style="background-color:#F0F0F0;">26.11</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S3.T1.11.11.13.2.7" style="padding-left:2.5pt;padding-right:2.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.11.11.13.2.7.1" style="background-color:#F0F0F0;">32.23</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S3.T1.11.11.13.2.8" style="padding-left:2.5pt;padding-right:2.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.11.11.13.2.8.1" style="background-color:#F0F0F0;">703.87</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>
Quantitative comparisons with SOTAs on <math alttext="A^{2}" class="ltx_Math" display="inline" id="S3.T1.13.m1.1"><semantics id="S3.T1.13.m1.1b"><msup id="S3.T1.13.m1.1.1" xref="S3.T1.13.m1.1.1.cmml"><mi id="S3.T1.13.m1.1.1.2" xref="S3.T1.13.m1.1.1.2.cmml">A</mi><mn id="S3.T1.13.m1.1.1.3" xref="S3.T1.13.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S3.T1.13.m1.1c"><apply id="S3.T1.13.m1.1.1.cmml" xref="S3.T1.13.m1.1.1"><csymbol cd="ambiguous" id="S3.T1.13.m1.1.1.1.cmml" xref="S3.T1.13.m1.1.1">superscript</csymbol><ci id="S3.T1.13.m1.1.1.2.cmml" xref="S3.T1.13.m1.1.1.2">𝐴</ci><cn id="S3.T1.13.m1.1.1.3.cmml" type="integer" xref="S3.T1.13.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.13.m1.1d">A^{2}</annotation><annotation encoding="application/x-llamapun" id="S3.T1.13.m1.1e">italic_A start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_typewriter" id="S3.T1.15.1">Bench</span> with the rescaled pose setting.
“PSNR*” means using the modified metric&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Wang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib59" title="">2024a</a>)</cite> to avoid numerical overflow.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="S3.T2">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T2.16" style="width:433.6pt;height:136.9pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-98.3pt,30.9pt) scale(0.68801022036203,0.68801022036203) ;">
<table class="ltx_tabular ltx_align_middle" id="S3.T2.16.16">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T2.7.7.7">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.7.7.7.8" style="padding-left:2.5pt;padding-right:2.5pt;">Method</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.1.1.1" style="padding-left:2.5pt;padding-right:2.5pt;">PSNR* <math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T2.1.1.1.1.m1.1"><semantics id="S3.T2.1.1.1.1.m1.1a"><mo id="S3.T2.1.1.1.1.m1.1.1" stretchy="false" xref="S3.T2.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T2.1.1.1.1.m1.1b"><ci id="S3.T2.1.1.1.1.m1.1.1.cmml" xref="S3.T2.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.1.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S3.T2.1.1.1.1.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.2.2.2.2" style="padding-left:2.5pt;padding-right:2.5pt;">SSIM <math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T2.2.2.2.2.m1.1"><semantics id="S3.T2.2.2.2.2.m1.1a"><mo id="S3.T2.2.2.2.2.m1.1.1" stretchy="false" xref="S3.T2.2.2.2.2.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T2.2.2.2.2.m1.1b"><ci id="S3.T2.2.2.2.2.m1.1.1.cmml" xref="S3.T2.2.2.2.2.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.2.2.2.2.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S3.T2.2.2.2.2.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.3.3.3" style="padding-left:2.5pt;padding-right:2.5pt;">L1 <math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T2.3.3.3.3.m1.1"><semantics id="S3.T2.3.3.3.3.m1.1a"><mo id="S3.T2.3.3.3.3.m1.1.1" stretchy="false" xref="S3.T2.3.3.3.3.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T2.3.3.3.3.m1.1b"><ci id="S3.T2.3.3.3.3.m1.1.1.cmml" xref="S3.T2.3.3.3.3.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.3.3.3.3.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S3.T2.3.3.3.3.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.4.4.4.4" style="padding-left:2.5pt;padding-right:2.5pt;">LPIPS <math alttext="\downarrow" class="ltx_Math" display="inline" id="S3.T2.4.4.4.4.m1.1"><semantics id="S3.T2.4.4.4.4.m1.1a"><mo id="S3.T2.4.4.4.4.m1.1.1" stretchy="false" xref="S3.T2.4.4.4.4.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S3.T2.4.4.4.4.m1.1b"><ci id="S3.T2.4.4.4.4.m1.1.1.cmml" xref="S3.T2.4.4.4.4.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.4.4.4.4.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S3.T2.4.4.4.4.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.5.5.5.5" style="padding-left:2.5pt;padding-right:2.5pt;">FID <math alttext="\downarrow" class="ltx_Math" display="inline" id="S3.T2.5.5.5.5.m1.1"><semantics id="S3.T2.5.5.5.5.m1.1a"><mo id="S3.T2.5.5.5.5.m1.1.1" stretchy="false" xref="S3.T2.5.5.5.5.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S3.T2.5.5.5.5.m1.1b"><ci id="S3.T2.5.5.5.5.m1.1.1.cmml" xref="S3.T2.5.5.5.5.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.5.5.5.5.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S3.T2.5.5.5.5.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.6.6.6.6" style="padding-left:2.5pt;padding-right:2.5pt;">FID-VID <math alttext="\downarrow" class="ltx_Math" display="inline" id="S3.T2.6.6.6.6.m1.1"><semantics id="S3.T2.6.6.6.6.m1.1a"><mo id="S3.T2.6.6.6.6.m1.1.1" stretchy="false" xref="S3.T2.6.6.6.6.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S3.T2.6.6.6.6.m1.1b"><ci id="S3.T2.6.6.6.6.m1.1.1.cmml" xref="S3.T2.6.6.6.6.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.6.6.6.6.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S3.T2.6.6.6.6.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.7.7.7.7" style="padding-left:2.5pt;padding-right:2.5pt;">FVD <math alttext="\downarrow" class="ltx_Math" display="inline" id="S3.T2.7.7.7.7.m1.1"><semantics id="S3.T2.7.7.7.7.m1.1a"><mo id="S3.T2.7.7.7.7.m1.1.1" stretchy="false" xref="S3.T2.7.7.7.7.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S3.T2.7.7.7.7.m1.1b"><ci id="S3.T2.7.7.7.7.m1.1.1.cmml" xref="S3.T2.7.7.7.7.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.7.7.7.7.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S3.T2.7.7.7.7.m1.1d">↓</annotation></semantics></math>
</td>
</tr>
<tr class="ltx_tr" id="S3.T2.8.8.8">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.8.8.8.1" style="padding-left:2.5pt;padding-right:2.5pt;">FOMM&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Siarohin et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib42" title="">2019a</a>)</cite> <math alttext="{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(NeurIPS19)}}}" class="ltx_Math" display="inline" id="S3.T2.8.8.8.1.m1.1"><semantics id="S3.T2.8.8.8.1.m1.1a"><msub id="S3.T2.8.8.8.1.m1.1.1" xref="S3.T2.8.8.8.1.m1.1.1.cmml"><mi id="S3.T2.8.8.8.1.m1.1.1a" xref="S3.T2.8.8.8.1.m1.1.1.cmml"></mi><mtext id="S3.T2.8.8.8.1.m1.1.1.1" mathcolor="#808080" xref="S3.T2.8.8.8.1.m1.1.1.1a.cmml">(NeurIPS19)</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.T2.8.8.8.1.m1.1b"><apply id="S3.T2.8.8.8.1.m1.1.1.cmml" xref="S3.T2.8.8.8.1.m1.1.1"><ci id="S3.T2.8.8.8.1.m1.1.1.1a.cmml" xref="S3.T2.8.8.8.1.m1.1.1.1"><mtext id="S3.T2.8.8.8.1.m1.1.1.1.cmml" mathsize="70%" xref="S3.T2.8.8.8.1.m1.1.1.1">(NeurIPS19)</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.8.8.8.1.m1.1c">{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(NeurIPS19)}}}</annotation><annotation encoding="application/x-llamapun" id="S3.T2.8.8.8.1.m1.1d">start_FLOATSUBSCRIPT (NeurIPS19) end_FLOATSUBSCRIPT</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.8.8.8.2" style="padding-left:2.5pt;padding-right:2.5pt;">10.49</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.8.8.8.3" style="padding-left:2.5pt;padding-right:2.5pt;">0.363</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.8.8.8.4" style="padding-left:2.5pt;padding-right:2.5pt;">1.47E-04</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.8.8.8.5" style="padding-left:2.5pt;padding-right:2.5pt;">0.613</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.8.8.8.6" style="padding-left:2.5pt;padding-right:2.5pt;">183.18</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.8.8.8.7" style="padding-left:2.5pt;padding-right:2.5pt;">147.82</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.8.8.8.8" style="padding-left:2.5pt;padding-right:2.5pt;">2535.12</td>
</tr>
<tr class="ltx_tr" id="S3.T2.9.9.9">
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.9.9.9.1" style="padding-left:2.5pt;padding-right:2.5pt;">MRAA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Siarohin et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib44" title="">2021a</a>)</cite> <math alttext="{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(CVPR21)}}}" class="ltx_Math" display="inline" id="S3.T2.9.9.9.1.m1.1"><semantics id="S3.T2.9.9.9.1.m1.1a"><msub id="S3.T2.9.9.9.1.m1.1.1" xref="S3.T2.9.9.9.1.m1.1.1.cmml"><mi id="S3.T2.9.9.9.1.m1.1.1a" xref="S3.T2.9.9.9.1.m1.1.1.cmml"></mi><mtext id="S3.T2.9.9.9.1.m1.1.1.1" mathcolor="#808080" xref="S3.T2.9.9.9.1.m1.1.1.1a.cmml">(CVPR21)</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.T2.9.9.9.1.m1.1b"><apply id="S3.T2.9.9.9.1.m1.1.1.cmml" xref="S3.T2.9.9.9.1.m1.1.1"><ci id="S3.T2.9.9.9.1.m1.1.1.1a.cmml" xref="S3.T2.9.9.9.1.m1.1.1.1"><mtext id="S3.T2.9.9.9.1.m1.1.1.1.cmml" mathsize="70%" xref="S3.T2.9.9.9.1.m1.1.1.1">(CVPR21)</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.9.9.9.1.m1.1c">{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(CVPR21)}}}</annotation><annotation encoding="application/x-llamapun" id="S3.T2.9.9.9.1.m1.1d">start_FLOATSUBSCRIPT (CVPR21) end_FLOATSUBSCRIPT</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.9.9.2" style="padding-left:2.5pt;padding-right:2.5pt;">12.62</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.9.9.3" style="padding-left:2.5pt;padding-right:2.5pt;">0.420</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.9.9.4" style="padding-left:2.5pt;padding-right:2.5pt;">1.09E-04</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.9.9.5" style="padding-left:2.5pt;padding-right:2.5pt;">0.556</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.9.9.9.6" style="padding-left:2.5pt;padding-right:2.5pt;">161.57</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.9.9.7" style="padding-left:2.5pt;padding-right:2.5pt;">196.87</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.9.9.8" style="padding-left:2.5pt;padding-right:2.5pt;">3094.68</td>
</tr>
<tr class="ltx_tr" id="S3.T2.10.10.10">
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.10.10.10.1" style="padding-left:2.5pt;padding-right:2.5pt;">LIA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Wang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib63" title="">2022</a>)</cite> <math alttext="{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(ICLR22)}}}" class="ltx_Math" display="inline" id="S3.T2.10.10.10.1.m1.1"><semantics id="S3.T2.10.10.10.1.m1.1a"><msub id="S3.T2.10.10.10.1.m1.1.1" xref="S3.T2.10.10.10.1.m1.1.1.cmml"><mi id="S3.T2.10.10.10.1.m1.1.1a" xref="S3.T2.10.10.10.1.m1.1.1.cmml"></mi><mtext id="S3.T2.10.10.10.1.m1.1.1.1" mathcolor="#808080" xref="S3.T2.10.10.10.1.m1.1.1.1a.cmml">(ICLR22)</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.T2.10.10.10.1.m1.1b"><apply id="S3.T2.10.10.10.1.m1.1.1.cmml" xref="S3.T2.10.10.10.1.m1.1.1"><ci id="S3.T2.10.10.10.1.m1.1.1.1a.cmml" xref="S3.T2.10.10.10.1.m1.1.1.1"><mtext id="S3.T2.10.10.10.1.m1.1.1.1.cmml" mathsize="70%" xref="S3.T2.10.10.10.1.m1.1.1.1">(ICLR22)</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.10.10.10.1.m1.1c">{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(ICLR22)}}}</annotation><annotation encoding="application/x-llamapun" id="S3.T2.10.10.10.1.m1.1d">start_FLOATSUBSCRIPT (ICLR22) end_FLOATSUBSCRIPT</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S3.T2.10.10.10.2" style="padding-left:2.5pt;padding-right:2.5pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T2.10.10.10.2.1">13.78</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.10.10.10.3" style="padding-left:2.5pt;padding-right:2.5pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T2.10.10.10.3.1">0.445</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.10.10.10.4" style="padding-left:2.5pt;padding-right:2.5pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T2.10.10.10.4.1">9.70E-05</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.10.10.10.5" style="padding-left:2.5pt;padding-right:2.5pt;">0.497</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.10.10.10.6" style="padding-left:2.5pt;padding-right:2.5pt;">105.13</td>
<td class="ltx_td ltx_align_center" id="S3.T2.10.10.10.7" style="padding-left:2.5pt;padding-right:2.5pt;">78.51</td>
<td class="ltx_td ltx_align_center" id="S3.T2.10.10.10.8" style="padding-left:2.5pt;padding-right:2.5pt;">1813.28</td>
</tr>
<tr class="ltx_tr" id="S3.T2.11.11.11">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.11.11.11.1" style="padding-left:2.5pt;padding-right:2.5pt;">DreamPose&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Karras et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib26" title="">2023</a>)</cite> <math alttext="{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(ICCV23)}}}" class="ltx_Math" display="inline" id="S3.T2.11.11.11.1.m1.1"><semantics id="S3.T2.11.11.11.1.m1.1a"><msub id="S3.T2.11.11.11.1.m1.1.1" xref="S3.T2.11.11.11.1.m1.1.1.cmml"><mi id="S3.T2.11.11.11.1.m1.1.1a" xref="S3.T2.11.11.11.1.m1.1.1.cmml"></mi><mtext id="S3.T2.11.11.11.1.m1.1.1.1" mathcolor="#808080" xref="S3.T2.11.11.11.1.m1.1.1.1a.cmml">(ICCV23)</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.T2.11.11.11.1.m1.1b"><apply id="S3.T2.11.11.11.1.m1.1.1.cmml" xref="S3.T2.11.11.11.1.m1.1.1"><ci id="S3.T2.11.11.11.1.m1.1.1.1a.cmml" xref="S3.T2.11.11.11.1.m1.1.1.1"><mtext id="S3.T2.11.11.11.1.m1.1.1.1.cmml" mathsize="70%" xref="S3.T2.11.11.11.1.m1.1.1.1">(ICCV23)</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.11.11.11.1.m1.1c">{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(ICCV23)}}}</annotation><annotation encoding="application/x-llamapun" id="S3.T2.11.11.11.1.m1.1d">start_FLOATSUBSCRIPT (ICCV23) end_FLOATSUBSCRIPT</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.11.11.11.2" style="padding-left:2.5pt;padding-right:2.5pt;">7.76</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.11.11.11.3" style="padding-left:2.5pt;padding-right:2.5pt;">0.305</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.11.11.11.4" style="padding-left:2.5pt;padding-right:2.5pt;">2.28E-04</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.11.11.11.5" style="padding-left:2.5pt;padding-right:2.5pt;">0.534</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.11.11.11.6" style="padding-left:2.5pt;padding-right:2.5pt;">277.64</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.11.11.11.7" style="padding-left:2.5pt;padding-right:2.5pt;">315.58</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.11.11.11.8" style="padding-left:2.5pt;padding-right:2.5pt;">4324.42</td>
</tr>
<tr class="ltx_tr" id="S3.T2.12.12.12">
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.12.12.12.1" style="padding-left:2.5pt;padding-right:2.5pt;">MagicAnimate&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Xu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib68" title="">2023a</a>)</cite> <math alttext="{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(CVPR24)}}}" class="ltx_Math" display="inline" id="S3.T2.12.12.12.1.m1.1"><semantics id="S3.T2.12.12.12.1.m1.1a"><msub id="S3.T2.12.12.12.1.m1.1.1" xref="S3.T2.12.12.12.1.m1.1.1.cmml"><mi id="S3.T2.12.12.12.1.m1.1.1a" xref="S3.T2.12.12.12.1.m1.1.1.cmml"></mi><mtext id="S3.T2.12.12.12.1.m1.1.1.1" mathcolor="#808080" xref="S3.T2.12.12.12.1.m1.1.1.1a.cmml">(CVPR24)</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.T2.12.12.12.1.m1.1b"><apply id="S3.T2.12.12.12.1.m1.1.1.cmml" xref="S3.T2.12.12.12.1.m1.1.1"><ci id="S3.T2.12.12.12.1.m1.1.1.1a.cmml" xref="S3.T2.12.12.12.1.m1.1.1.1"><mtext id="S3.T2.12.12.12.1.m1.1.1.1.cmml" mathsize="70%" xref="S3.T2.12.12.12.1.m1.1.1.1">(CVPR24)</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.12.12.12.1.m1.1c">{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(CVPR24)}}}</annotation><annotation encoding="application/x-llamapun" id="S3.T2.12.12.12.1.m1.1d">start_FLOATSUBSCRIPT (CVPR24) end_FLOATSUBSCRIPT</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S3.T2.12.12.12.2" style="padding-left:2.5pt;padding-right:2.5pt;">11.90</td>
<td class="ltx_td ltx_align_center" id="S3.T2.12.12.12.3" style="padding-left:2.5pt;padding-right:2.5pt;">0.396</td>
<td class="ltx_td ltx_align_center" id="S3.T2.12.12.12.4" style="padding-left:2.5pt;padding-right:2.5pt;">1.17E-04</td>
<td class="ltx_td ltx_align_center" id="S3.T2.12.12.12.5" style="padding-left:2.5pt;padding-right:2.5pt;">0.523</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.12.12.12.6" style="padding-left:2.5pt;padding-right:2.5pt;">117.09</td>
<td class="ltx_td ltx_align_center" id="S3.T2.12.12.12.7" style="padding-left:2.5pt;padding-right:2.5pt;">117.54</td>
<td class="ltx_td ltx_align_center" id="S3.T2.12.12.12.8" style="padding-left:2.5pt;padding-right:2.5pt;">2021.93</td>
</tr>
<tr class="ltx_tr" id="S3.T2.13.13.13">
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.13.13.13.1" style="padding-left:2.5pt;padding-right:2.5pt;">Moore-AnimateAnyone&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Corporation (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib11" title="">2024</a>)</cite> <math alttext="{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(CVPR24)}}}" class="ltx_Math" display="inline" id="S3.T2.13.13.13.1.m1.1"><semantics id="S3.T2.13.13.13.1.m1.1a"><msub id="S3.T2.13.13.13.1.m1.1.1" xref="S3.T2.13.13.13.1.m1.1.1.cmml"><mi id="S3.T2.13.13.13.1.m1.1.1a" xref="S3.T2.13.13.13.1.m1.1.1.cmml"></mi><mtext id="S3.T2.13.13.13.1.m1.1.1.1" mathcolor="#808080" xref="S3.T2.13.13.13.1.m1.1.1.1a.cmml">(CVPR24)</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.T2.13.13.13.1.m1.1b"><apply id="S3.T2.13.13.13.1.m1.1.1.cmml" xref="S3.T2.13.13.13.1.m1.1.1"><ci id="S3.T2.13.13.13.1.m1.1.1.1a.cmml" xref="S3.T2.13.13.13.1.m1.1.1.1"><mtext id="S3.T2.13.13.13.1.m1.1.1.1.cmml" mathsize="70%" xref="S3.T2.13.13.13.1.m1.1.1.1">(CVPR24)</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.13.13.13.1.m1.1c">{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(CVPR24)}}}</annotation><annotation encoding="application/x-llamapun" id="S3.T2.13.13.13.1.m1.1d">start_FLOATSUBSCRIPT (CVPR24) end_FLOATSUBSCRIPT</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S3.T2.13.13.13.2" style="padding-left:2.5pt;padding-right:2.5pt;">11.56</td>
<td class="ltx_td ltx_align_center" id="S3.T2.13.13.13.3" style="padding-left:2.5pt;padding-right:2.5pt;">0.360</td>
<td class="ltx_td ltx_align_center" id="S3.T2.13.13.13.4" style="padding-left:2.5pt;padding-right:2.5pt;">1.27E-04</td>
<td class="ltx_td ltx_align_center" id="S3.T2.13.13.13.5" style="padding-left:2.5pt;padding-right:2.5pt;">0.532</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.13.13.13.6" style="padding-left:2.5pt;padding-right:2.5pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T2.13.13.13.6.1">37.82</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.13.13.13.7" style="padding-left:2.5pt;padding-right:2.5pt;">59.80</td>
<td class="ltx_td ltx_align_center" id="S3.T2.13.13.13.8" style="padding-left:2.5pt;padding-right:2.5pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T2.13.13.13.8.1">1117.29</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.14.14.14">
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.14.14.14.1" style="padding-left:2.5pt;padding-right:2.5pt;">MimicMotion&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Zhang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib82" title="">2024</a>)</cite> <math alttext="{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(ArXiv24)}}}" class="ltx_Math" display="inline" id="S3.T2.14.14.14.1.m1.1"><semantics id="S3.T2.14.14.14.1.m1.1a"><msub id="S3.T2.14.14.14.1.m1.1.1" xref="S3.T2.14.14.14.1.m1.1.1.cmml"><mi id="S3.T2.14.14.14.1.m1.1.1a" xref="S3.T2.14.14.14.1.m1.1.1.cmml"></mi><mtext id="S3.T2.14.14.14.1.m1.1.1.1" mathcolor="#808080" xref="S3.T2.14.14.14.1.m1.1.1.1a.cmml">(ArXiv24)</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.T2.14.14.14.1.m1.1b"><apply id="S3.T2.14.14.14.1.m1.1.1.cmml" xref="S3.T2.14.14.14.1.m1.1.1"><ci id="S3.T2.14.14.14.1.m1.1.1.1a.cmml" xref="S3.T2.14.14.14.1.m1.1.1.1"><mtext id="S3.T2.14.14.14.1.m1.1.1.1.cmml" mathsize="70%" xref="S3.T2.14.14.14.1.m1.1.1.1">(ArXiv24)</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.14.14.14.1.m1.1c">{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(ArXiv24)}}}</annotation><annotation encoding="application/x-llamapun" id="S3.T2.14.14.14.1.m1.1d">start_FLOATSUBSCRIPT (ArXiv24) end_FLOATSUBSCRIPT</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S3.T2.14.14.14.2" style="padding-left:2.5pt;padding-right:2.5pt;">12.66</td>
<td class="ltx_td ltx_align_center" id="S3.T2.14.14.14.3" style="padding-left:2.5pt;padding-right:2.5pt;">0.407</td>
<td class="ltx_td ltx_align_center" id="S3.T2.14.14.14.4" style="padding-left:2.5pt;padding-right:2.5pt;">1.07E-04</td>
<td class="ltx_td ltx_align_center" id="S3.T2.14.14.14.5" style="padding-left:2.5pt;padding-right:2.5pt;">0.497</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.14.14.14.6" style="padding-left:2.5pt;padding-right:2.5pt;">96.46</td>
<td class="ltx_td ltx_align_center" id="S3.T2.14.14.14.7" style="padding-left:2.5pt;padding-right:2.5pt;">61.77</td>
<td class="ltx_td ltx_align_center" id="S3.T2.14.14.14.8" style="padding-left:2.5pt;padding-right:2.5pt;">1368.83</td>
</tr>
<tr class="ltx_tr" id="S3.T2.15.15.15">
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.15.15.15.1" style="padding-left:2.5pt;padding-right:2.5pt;">ControlNeXt&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Peng et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib34" title="">2024</a>)</cite> <math alttext="{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(ArXiv24)}}}" class="ltx_Math" display="inline" id="S3.T2.15.15.15.1.m1.1"><semantics id="S3.T2.15.15.15.1.m1.1a"><msub id="S3.T2.15.15.15.1.m1.1.1" xref="S3.T2.15.15.15.1.m1.1.1.cmml"><mi id="S3.T2.15.15.15.1.m1.1.1a" xref="S3.T2.15.15.15.1.m1.1.1.cmml"></mi><mtext id="S3.T2.15.15.15.1.m1.1.1.1" mathcolor="#808080" xref="S3.T2.15.15.15.1.m1.1.1.1a.cmml">(ArXiv24)</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.T2.15.15.15.1.m1.1b"><apply id="S3.T2.15.15.15.1.m1.1.1.cmml" xref="S3.T2.15.15.15.1.m1.1.1"><ci id="S3.T2.15.15.15.1.m1.1.1.1a.cmml" xref="S3.T2.15.15.15.1.m1.1.1.1"><mtext id="S3.T2.15.15.15.1.m1.1.1.1.cmml" mathsize="70%" xref="S3.T2.15.15.15.1.m1.1.1.1">(ArXiv24)</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.15.15.15.1.m1.1c">{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(ArXiv24)}}}</annotation><annotation encoding="application/x-llamapun" id="S3.T2.15.15.15.1.m1.1d">start_FLOATSUBSCRIPT (ArXiv24) end_FLOATSUBSCRIPT</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S3.T2.15.15.15.2" style="padding-left:2.5pt;padding-right:2.5pt;">12.82</td>
<td class="ltx_td ltx_align_center" id="S3.T2.15.15.15.3" style="padding-left:2.5pt;padding-right:2.5pt;">0.421</td>
<td class="ltx_td ltx_align_center" id="S3.T2.15.15.15.4" style="padding-left:2.5pt;padding-right:2.5pt;">1.02E-04</td>
<td class="ltx_td ltx_align_center" id="S3.T2.15.15.15.5" style="padding-left:2.5pt;padding-right:2.5pt;">0.472</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.15.15.15.6" style="padding-left:2.5pt;padding-right:2.5pt;">46.66</td>
<td class="ltx_td ltx_align_center" id="S3.T2.15.15.15.7" style="padding-left:2.5pt;padding-right:2.5pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T2.15.15.15.7.1">59.41</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.15.15.15.8" style="padding-left:2.5pt;padding-right:2.5pt;">1152.96</td>
</tr>
<tr class="ltx_tr" id="S3.T2.16.16.16">
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.16.16.16.1" style="padding-left:2.5pt;padding-right:2.5pt;">MusePose&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Tong et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib54" title="">2024</a>)</cite> <math alttext="{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(ArXiv24)}}}" class="ltx_Math" display="inline" id="S3.T2.16.16.16.1.m1.1"><semantics id="S3.T2.16.16.16.1.m1.1a"><msub id="S3.T2.16.16.16.1.m1.1.1" xref="S3.T2.16.16.16.1.m1.1.1.cmml"><mi id="S3.T2.16.16.16.1.m1.1.1a" xref="S3.T2.16.16.16.1.m1.1.1.cmml"></mi><mtext id="S3.T2.16.16.16.1.m1.1.1.1" mathcolor="#808080" xref="S3.T2.16.16.16.1.m1.1.1.1a.cmml">(ArXiv24)</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.T2.16.16.16.1.m1.1b"><apply id="S3.T2.16.16.16.1.m1.1.1.cmml" xref="S3.T2.16.16.16.1.m1.1.1"><ci id="S3.T2.16.16.16.1.m1.1.1.1a.cmml" xref="S3.T2.16.16.16.1.m1.1.1.1"><mtext id="S3.T2.16.16.16.1.m1.1.1.1.cmml" mathsize="70%" xref="S3.T2.16.16.16.1.m1.1.1.1">(ArXiv24)</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.16.16.16.1.m1.1c">{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(ArXiv24)}}}</annotation><annotation encoding="application/x-llamapun" id="S3.T2.16.16.16.1.m1.1d">start_FLOATSUBSCRIPT (ArXiv24) end_FLOATSUBSCRIPT</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.16.16.2" style="padding-left:2.5pt;padding-right:2.5pt;">12.92</td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.16.16.3" style="padding-left:2.5pt;padding-right:2.5pt;">0.438</td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.16.16.4" style="padding-left:2.5pt;padding-right:2.5pt;">9.90E-05</td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.16.16.5" style="padding-left:2.5pt;padding-right:2.5pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T2.16.16.16.5.1">0.470</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.16.16.6" style="padding-left:2.5pt;padding-right:2.5pt;">80.22</td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.16.16.7" style="padding-left:2.5pt;padding-right:2.5pt;">87.97</td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.16.16.8" style="padding-left:2.5pt;padding-right:2.5pt;">1401.96</td>
</tr>
<tr class="ltx_tr" id="S3.T2.16.16.17.1" style="background-color:#F0F0F0;">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S3.T2.16.16.17.1.1" style="padding-left:2.5pt;padding-right:2.5pt;"><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="S3.T2.16.16.17.1.1.1" style="background-color:#F0F0F0;">Animate-X</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S3.T2.16.16.17.1.2" style="padding-left:2.5pt;padding-right:2.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.16.16.17.1.2.1" style="background-color:#F0F0F0;">14.10</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S3.T2.16.16.17.1.3" style="padding-left:2.5pt;padding-right:2.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.16.16.17.1.3.1" style="background-color:#F0F0F0;">0.463</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S3.T2.16.16.17.1.4" style="padding-left:2.5pt;padding-right:2.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.16.16.17.1.4.1" style="background-color:#F0F0F0;">8.92E-05</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S3.T2.16.16.17.1.5" style="padding-left:2.5pt;padding-right:2.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.16.16.17.1.5.1" style="background-color:#F0F0F0;">0.425</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S3.T2.16.16.17.1.6" style="padding-left:2.5pt;padding-right:2.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.16.16.17.1.6.1" style="background-color:#F0F0F0;">31.58</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S3.T2.16.16.17.1.7" style="padding-left:2.5pt;padding-right:2.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.16.16.17.1.7.1" style="background-color:#F0F0F0;">33.15</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S3.T2.16.16.17.1.8" style="padding-left:2.5pt;padding-right:2.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.16.16.17.1.8.1" style="background-color:#F0F0F0;">849.19</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>
Quantitative comparisons with existing methods on <math alttext="A^{2}" class="ltx_Math" display="inline" id="S3.T2.18.m1.1"><semantics id="S3.T2.18.m1.1b"><msup id="S3.T2.18.m1.1.1" xref="S3.T2.18.m1.1.1.cmml"><mi id="S3.T2.18.m1.1.1.2" xref="S3.T2.18.m1.1.1.2.cmml">A</mi><mn id="S3.T2.18.m1.1.1.3" xref="S3.T2.18.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S3.T2.18.m1.1c"><apply id="S3.T2.18.m1.1.1.cmml" xref="S3.T2.18.m1.1.1"><csymbol cd="ambiguous" id="S3.T2.18.m1.1.1.1.cmml" xref="S3.T2.18.m1.1.1">superscript</csymbol><ci id="S3.T2.18.m1.1.1.2.cmml" xref="S3.T2.18.m1.1.1.2">𝐴</ci><cn id="S3.T2.18.m1.1.1.3.cmml" type="integer" xref="S3.T2.18.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.18.m1.1d">A^{2}</annotation><annotation encoding="application/x-llamapun" id="S3.T2.18.m1.1e">italic_A start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_typewriter" id="S3.T2.20.1">Bench</span> in the self-driven setting. Underline means the second best result.
</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Experimental Settings</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.2"><span class="ltx_text ltx_font_bold" id="S4.SS1.p1.2.1">Dataset.</span> We collect approximately 9,000 human videos from the internet and supplement this with TikTok dataset&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Jafarian &amp; Park (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib24" title="">2021</a>)</cite> and Fashion dataset&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Zablotskaia et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib75" title="">2019a</a>)</cite> for training.
Following previous works&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Hu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib21" title="">2023</a>); Zablotskaia et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib75" title="">2019a</a>); Jafarian &amp; Park (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib24" title="">2021</a>)</cite>, we use 10 and 100 videos for both qualitative and quantitative comparisons from TikTok and Fashion dataset, respectively.
We additionally experimented on 100 image-video pairs selected from the newly proposed <math alttext="A^{2}" class="ltx_Math" display="inline" id="S4.SS1.p1.1.m1.1"><semantics id="S4.SS1.p1.1.m1.1a"><msup id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml"><mi id="S4.SS1.p1.1.m1.1.1.2" xref="S4.SS1.p1.1.m1.1.1.2.cmml">A</mi><mn id="S4.SS1.p1.1.m1.1.1.3" xref="S4.SS1.p1.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><apply id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.1.m1.1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">superscript</csymbol><ci id="S4.SS1.p1.1.m1.1.1.2.cmml" xref="S4.SS1.p1.1.m1.1.1.2">𝐴</ci><cn id="S4.SS1.p1.1.m1.1.1.3.cmml" type="integer" xref="S4.SS1.p1.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">A^{2}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.1.m1.1d">italic_A start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_typewriter" id="S4.SS1.p1.2.2">Bench</span> introduced in Sec&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#S3.SS4" title="3.4 𝐴²Bench ‣ 3 Method ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">3.4</span></a>. Please note that, to ensure a fair comparison, the data in the <math alttext="A^{2}" class="ltx_Math" display="inline" id="S4.SS1.p1.2.m2.1"><semantics id="S4.SS1.p1.2.m2.1a"><msup id="S4.SS1.p1.2.m2.1.1" xref="S4.SS1.p1.2.m2.1.1.cmml"><mi id="S4.SS1.p1.2.m2.1.1.2" xref="S4.SS1.p1.2.m2.1.1.2.cmml">A</mi><mn id="S4.SS1.p1.2.m2.1.1.3" xref="S4.SS1.p1.2.m2.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.1b"><apply id="S4.SS1.p1.2.m2.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.2.m2.1.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1">superscript</csymbol><ci id="S4.SS1.p1.2.m2.1.1.2.cmml" xref="S4.SS1.p1.2.m2.1.1.2">𝐴</ci><cn id="S4.SS1.p1.2.m2.1.1.3.cmml" type="integer" xref="S4.SS1.p1.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.1c">A^{2}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.2.m2.1d">italic_A start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_typewriter" id="S4.SS1.p1.2.3">Bench</span> are <span class="ltx_text ltx_font_bold" id="S4.SS1.p1.2.4">not</span> included in the training set to train our model. The data are only used to evaluate the quantitative results and provide interesting reference image cases.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p2.1.1">Evaluation Metrics.</span>
We assess the results using evaluation metrics in Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#A2.SS1" title="B.1 Evaluation Metric ‣ Appendix B Benchmark Details ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">B.1</span></a>, including PSNR&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Hore &amp; Ziou (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib20" title="">2010</a>)</cite>, SSIM&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Wang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib65" title="">2004</a>)</cite>, L1, LPIPS&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Zhang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib81" title="">2018</a>)</cite>, which are widely-used image metrics for measuring the visual quality of the generated results. In addition, we introduce FID&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Heusel et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib17" title="">2017</a>)</cite>, FID-VID&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Balaji et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib3" title="">2019</a>)</cite> and FVD&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Unterthiner et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib55" title="">2018</a>)</cite> to quantify the discrepancy between the generated video distribution and the real video distribution.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S4.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="569" id="S4.F5.g1" src="./animate-x_files/x4.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Qualitative comparisons with state-of-the-art methods.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Experimental Results</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.13"><span class="ltx_text ltx_font_bold" id="S4.SS2.p1.13.1">Quantitative Results.</span> Since our <span class="ltx_text ltx_font_typewriter" id="S4.SS2.p1.13.2">Animate-X</span> primarily focuses on animating the anthropomorphic characters, very few of which, if not none, can be extracted the pose skeleton accurately by DWPose&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Yang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib71" title="">2023</a>)</cite>. It naturally leads to a misalignment of the input reference image with the driving pose images. To compute quantitative results in this case, we set up a new comparison setting.
For each case in <math alttext="A^{2}" class="ltx_Math" display="inline" id="S4.SS2.p1.1.m1.1"><semantics id="S4.SS2.p1.1.m1.1a"><msup id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml"><mi id="S4.SS2.p1.1.m1.1.1.2" xref="S4.SS2.p1.1.m1.1.1.2.cmml">A</mi><mn id="S4.SS2.p1.1.m1.1.1.3" xref="S4.SS2.p1.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><apply id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1">superscript</csymbol><ci id="S4.SS2.p1.1.m1.1.1.2.cmml" xref="S4.SS2.p1.1.m1.1.1.2">𝐴</ci><cn id="S4.SS2.p1.1.m1.1.1.3.cmml" type="integer" xref="S4.SS2.p1.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">A^{2}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.1.m1.1d">italic_A start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_typewriter" id="S4.SS2.p1.13.3">Bench</span> (<span class="ltx_text ltx_font_italic" id="S4.SS2.p1.13.4">i.e.</span>, a reference image <math alttext="I^{a}" class="ltx_Math" display="inline" id="S4.SS2.p1.2.m2.1"><semantics id="S4.SS2.p1.2.m2.1a"><msup id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml"><mi id="S4.SS2.p1.2.m2.1.1.2" xref="S4.SS2.p1.2.m2.1.1.2.cmml">I</mi><mi id="S4.SS2.p1.2.m2.1.1.3" xref="S4.SS2.p1.2.m2.1.1.3.cmml">a</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><apply id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.2.m2.1.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1">superscript</csymbol><ci id="S4.SS2.p1.2.m2.1.1.2.cmml" xref="S4.SS2.p1.2.m2.1.1.2">𝐼</ci><ci id="S4.SS2.p1.2.m2.1.1.3.cmml" xref="S4.SS2.p1.2.m2.1.1.3">𝑎</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">I^{a}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.2.m2.1d">italic_I start_POSTSUPERSCRIPT italic_a end_POSTSUPERSCRIPT</annotation></semantics></math> and a pose <math alttext="P^{a}" class="ltx_Math" display="inline" id="S4.SS2.p1.3.m3.1"><semantics id="S4.SS2.p1.3.m3.1a"><msup id="S4.SS2.p1.3.m3.1.1" xref="S4.SS2.p1.3.m3.1.1.cmml"><mi id="S4.SS2.p1.3.m3.1.1.2" xref="S4.SS2.p1.3.m3.1.1.2.cmml">P</mi><mi id="S4.SS2.p1.3.m3.1.1.3" xref="S4.SS2.p1.3.m3.1.1.3.cmml">a</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.3.m3.1b"><apply id="S4.SS2.p1.3.m3.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.3.m3.1.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1">superscript</csymbol><ci id="S4.SS2.p1.3.m3.1.1.2.cmml" xref="S4.SS2.p1.3.m3.1.1.2">𝑃</ci><ci id="S4.SS2.p1.3.m3.1.1.3.cmml" xref="S4.SS2.p1.3.m3.1.1.3">𝑎</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.3.m3.1c">P^{a}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.3.m3.1d">italic_P start_POSTSUPERSCRIPT italic_a end_POSTSUPERSCRIPT</annotation></semantics></math>, as shown in Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#S3.F4" title="Figure 4 ‣ 3.4 𝐴²Bench ‣ 3 Method ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">4</span></a>), we randomly select one human’s pose image <math alttext="P^{b}" class="ltx_Math" display="inline" id="S4.SS2.p1.4.m4.1"><semantics id="S4.SS2.p1.4.m4.1a"><msup id="S4.SS2.p1.4.m4.1.1" xref="S4.SS2.p1.4.m4.1.1.cmml"><mi id="S4.SS2.p1.4.m4.1.1.2" xref="S4.SS2.p1.4.m4.1.1.2.cmml">P</mi><mi id="S4.SS2.p1.4.m4.1.1.3" xref="S4.SS2.p1.4.m4.1.1.3.cmml">b</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.4.m4.1b"><apply id="S4.SS2.p1.4.m4.1.1.cmml" xref="S4.SS2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.4.m4.1.1.1.cmml" xref="S4.SS2.p1.4.m4.1.1">superscript</csymbol><ci id="S4.SS2.p1.4.m4.1.1.2.cmml" xref="S4.SS2.p1.4.m4.1.1.2">𝑃</ci><ci id="S4.SS2.p1.4.m4.1.1.3.cmml" xref="S4.SS2.p1.4.m4.1.1.3">𝑏</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.4.m4.1c">P^{b}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.4.m4.1d">italic_P start_POSTSUPERSCRIPT italic_b end_POSTSUPERSCRIPT</annotation></semantics></math> and align the anthropomorphic character’s pose <math alttext="P^{a}" class="ltx_Math" display="inline" id="S4.SS2.p1.5.m5.1"><semantics id="S4.SS2.p1.5.m5.1a"><msup id="S4.SS2.p1.5.m5.1.1" xref="S4.SS2.p1.5.m5.1.1.cmml"><mi id="S4.SS2.p1.5.m5.1.1.2" xref="S4.SS2.p1.5.m5.1.1.2.cmml">P</mi><mi id="S4.SS2.p1.5.m5.1.1.3" xref="S4.SS2.p1.5.m5.1.1.3.cmml">a</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.5.m5.1b"><apply id="S4.SS2.p1.5.m5.1.1.cmml" xref="S4.SS2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.5.m5.1.1.1.cmml" xref="S4.SS2.p1.5.m5.1.1">superscript</csymbol><ci id="S4.SS2.p1.5.m5.1.1.2.cmml" xref="S4.SS2.p1.5.m5.1.1.2">𝑃</ci><ci id="S4.SS2.p1.5.m5.1.1.3.cmml" xref="S4.SS2.p1.5.m5.1.1.3">𝑎</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.5.m5.1c">P^{a}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.5.m5.1d">italic_P start_POSTSUPERSCRIPT italic_a end_POSTSUPERSCRIPT</annotation></semantics></math> to it, such that the aligned pose <math alttext="p^{a}_{b}" class="ltx_Math" display="inline" id="S4.SS2.p1.6.m6.1"><semantics id="S4.SS2.p1.6.m6.1a"><msubsup id="S4.SS2.p1.6.m6.1.1" xref="S4.SS2.p1.6.m6.1.1.cmml"><mi id="S4.SS2.p1.6.m6.1.1.2.2" xref="S4.SS2.p1.6.m6.1.1.2.2.cmml">p</mi><mi id="S4.SS2.p1.6.m6.1.1.3" xref="S4.SS2.p1.6.m6.1.1.3.cmml">b</mi><mi id="S4.SS2.p1.6.m6.1.1.2.3" xref="S4.SS2.p1.6.m6.1.1.2.3.cmml">a</mi></msubsup><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.6.m6.1b"><apply id="S4.SS2.p1.6.m6.1.1.cmml" xref="S4.SS2.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.6.m6.1.1.1.cmml" xref="S4.SS2.p1.6.m6.1.1">subscript</csymbol><apply id="S4.SS2.p1.6.m6.1.1.2.cmml" xref="S4.SS2.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.6.m6.1.1.2.1.cmml" xref="S4.SS2.p1.6.m6.1.1">superscript</csymbol><ci id="S4.SS2.p1.6.m6.1.1.2.2.cmml" xref="S4.SS2.p1.6.m6.1.1.2.2">𝑝</ci><ci id="S4.SS2.p1.6.m6.1.1.2.3.cmml" xref="S4.SS2.p1.6.m6.1.1.2.3">𝑎</ci></apply><ci id="S4.SS2.p1.6.m6.1.1.3.cmml" xref="S4.SS2.p1.6.m6.1.1.3">𝑏</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.6.m6.1c">p^{a}_{b}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.6.m6.1d">italic_p start_POSTSUPERSCRIPT italic_a end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT</annotation></semantics></math> retains the movements of <math alttext="P^{a}" class="ltx_Math" display="inline" id="S4.SS2.p1.7.m7.1"><semantics id="S4.SS2.p1.7.m7.1a"><msup id="S4.SS2.p1.7.m7.1.1" xref="S4.SS2.p1.7.m7.1.1.cmml"><mi id="S4.SS2.p1.7.m7.1.1.2" xref="S4.SS2.p1.7.m7.1.1.2.cmml">P</mi><mi id="S4.SS2.p1.7.m7.1.1.3" xref="S4.SS2.p1.7.m7.1.1.3.cmml">a</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.7.m7.1b"><apply id="S4.SS2.p1.7.m7.1.1.cmml" xref="S4.SS2.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.7.m7.1.1.1.cmml" xref="S4.SS2.p1.7.m7.1.1">superscript</csymbol><ci id="S4.SS2.p1.7.m7.1.1.2.cmml" xref="S4.SS2.p1.7.m7.1.1.2">𝑃</ci><ci id="S4.SS2.p1.7.m7.1.1.3.cmml" xref="S4.SS2.p1.7.m7.1.1.3">𝑎</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.7.m7.1c">P^{a}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.7.m7.1d">italic_P start_POSTSUPERSCRIPT italic_a end_POSTSUPERSCRIPT</annotation></semantics></math> but has the same body shape (fat/thin, tall/short, <span class="ltx_text ltx_font_italic" id="S4.SS2.p1.13.5">etc.</span>) as <math alttext="p^{b}" class="ltx_Math" display="inline" id="S4.SS2.p1.8.m8.1"><semantics id="S4.SS2.p1.8.m8.1a"><msup id="S4.SS2.p1.8.m8.1.1" xref="S4.SS2.p1.8.m8.1.1.cmml"><mi id="S4.SS2.p1.8.m8.1.1.2" xref="S4.SS2.p1.8.m8.1.1.2.cmml">p</mi><mi id="S4.SS2.p1.8.m8.1.1.3" xref="S4.SS2.p1.8.m8.1.1.3.cmml">b</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.8.m8.1b"><apply id="S4.SS2.p1.8.m8.1.1.cmml" xref="S4.SS2.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.8.m8.1.1.1.cmml" xref="S4.SS2.p1.8.m8.1.1">superscript</csymbol><ci id="S4.SS2.p1.8.m8.1.1.2.cmml" xref="S4.SS2.p1.8.m8.1.1.2">𝑝</ci><ci id="S4.SS2.p1.8.m8.1.1.3.cmml" xref="S4.SS2.p1.8.m8.1.1.3">𝑏</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.8.m8.1c">p^{b}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.8.m8.1d">italic_p start_POSTSUPERSCRIPT italic_b end_POSTSUPERSCRIPT</annotation></semantics></math>. Ultimately, we take the anthropomorphic character <math alttext="I_{a}" class="ltx_Math" display="inline" id="S4.SS2.p1.9.m9.1"><semantics id="S4.SS2.p1.9.m9.1a"><msub id="S4.SS2.p1.9.m9.1.1" xref="S4.SS2.p1.9.m9.1.1.cmml"><mi id="S4.SS2.p1.9.m9.1.1.2" xref="S4.SS2.p1.9.m9.1.1.2.cmml">I</mi><mi id="S4.SS2.p1.9.m9.1.1.3" xref="S4.SS2.p1.9.m9.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.9.m9.1b"><apply id="S4.SS2.p1.9.m9.1.1.cmml" xref="S4.SS2.p1.9.m9.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.9.m9.1.1.1.cmml" xref="S4.SS2.p1.9.m9.1.1">subscript</csymbol><ci id="S4.SS2.p1.9.m9.1.1.2.cmml" xref="S4.SS2.p1.9.m9.1.1.2">𝐼</ci><ci id="S4.SS2.p1.9.m9.1.1.3.cmml" xref="S4.SS2.p1.9.m9.1.1.3">𝑎</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.9.m9.1c">I_{a}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.9.m9.1d">italic_I start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT</annotation></semantics></math> and the aligned driving pose image <math alttext="p^{a}_{b}" class="ltx_Math" display="inline" id="S4.SS2.p1.10.m10.1"><semantics id="S4.SS2.p1.10.m10.1a"><msubsup id="S4.SS2.p1.10.m10.1.1" xref="S4.SS2.p1.10.m10.1.1.cmml"><mi id="S4.SS2.p1.10.m10.1.1.2.2" xref="S4.SS2.p1.10.m10.1.1.2.2.cmml">p</mi><mi id="S4.SS2.p1.10.m10.1.1.3" xref="S4.SS2.p1.10.m10.1.1.3.cmml">b</mi><mi id="S4.SS2.p1.10.m10.1.1.2.3" xref="S4.SS2.p1.10.m10.1.1.2.3.cmml">a</mi></msubsup><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.10.m10.1b"><apply id="S4.SS2.p1.10.m10.1.1.cmml" xref="S4.SS2.p1.10.m10.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.10.m10.1.1.1.cmml" xref="S4.SS2.p1.10.m10.1.1">subscript</csymbol><apply id="S4.SS2.p1.10.m10.1.1.2.cmml" xref="S4.SS2.p1.10.m10.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.10.m10.1.1.2.1.cmml" xref="S4.SS2.p1.10.m10.1.1">superscript</csymbol><ci id="S4.SS2.p1.10.m10.1.1.2.2.cmml" xref="S4.SS2.p1.10.m10.1.1.2.2">𝑝</ci><ci id="S4.SS2.p1.10.m10.1.1.2.3.cmml" xref="S4.SS2.p1.10.m10.1.1.2.3">𝑎</ci></apply><ci id="S4.SS2.p1.10.m10.1.1.3.cmml" xref="S4.SS2.p1.10.m10.1.1.3">𝑏</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.10.m10.1c">p^{a}_{b}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.10.m10.1d">italic_p start_POSTSUPERSCRIPT italic_a end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT</annotation></semantics></math> as inputs to the model, generating results that allow it to calculate quantitative metrics with the original anthropomorphic character dancing video in <math alttext="A^{2}" class="ltx_Math" display="inline" id="S4.SS2.p1.11.m11.1"><semantics id="S4.SS2.p1.11.m11.1a"><msup id="S4.SS2.p1.11.m11.1.1" xref="S4.SS2.p1.11.m11.1.1.cmml"><mi id="S4.SS2.p1.11.m11.1.1.2" xref="S4.SS2.p1.11.m11.1.1.2.cmml">A</mi><mn id="S4.SS2.p1.11.m11.1.1.3" xref="S4.SS2.p1.11.m11.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.11.m11.1b"><apply id="S4.SS2.p1.11.m11.1.1.cmml" xref="S4.SS2.p1.11.m11.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.11.m11.1.1.1.cmml" xref="S4.SS2.p1.11.m11.1.1">superscript</csymbol><ci id="S4.SS2.p1.11.m11.1.1.2.cmml" xref="S4.SS2.p1.11.m11.1.1.2">𝐴</ci><cn id="S4.SS2.p1.11.m11.1.1.3.cmml" type="integer" xref="S4.SS2.p1.11.m11.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.11.m11.1c">A^{2}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.11.m11.1d">italic_A start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_typewriter" id="S4.SS2.p1.13.6">Bench</span>. In this setting, we compare our method with Animate Anyone&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Hu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib21" title="">2023</a>)</cite>, Unianimate&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Wang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib61" title="">2024b</a>)</cite>, MimicMotion&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Zhang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib82" title="">2024</a>)</cite>, ControlNeXt&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Peng et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib34" title="">2024</a>)</cite> and MusePose&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Tong et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib54" title="">2024</a>)</cite>, which also use pose images (<span class="ltx_text ltx_font_italic" id="S4.SS2.p1.13.7">e.g.,</span> <math alttext="P^{b}" class="ltx_Math" display="inline" id="S4.SS2.p1.12.m12.1"><semantics id="S4.SS2.p1.12.m12.1a"><msup id="S4.SS2.p1.12.m12.1.1" xref="S4.SS2.p1.12.m12.1.1.cmml"><mi id="S4.SS2.p1.12.m12.1.1.2" xref="S4.SS2.p1.12.m12.1.1.2.cmml">P</mi><mi id="S4.SS2.p1.12.m12.1.1.3" xref="S4.SS2.p1.12.m12.1.1.3.cmml">b</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.12.m12.1b"><apply id="S4.SS2.p1.12.m12.1.1.cmml" xref="S4.SS2.p1.12.m12.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.12.m12.1.1.1.cmml" xref="S4.SS2.p1.12.m12.1.1">superscript</csymbol><ci id="S4.SS2.p1.12.m12.1.1.2.cmml" xref="S4.SS2.p1.12.m12.1.1.2">𝑃</ci><ci id="S4.SS2.p1.12.m12.1.1.3.cmml" xref="S4.SS2.p1.12.m12.1.1.3">𝑏</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.12.m12.1c">P^{b}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.12.m12.1d">italic_P start_POSTSUPERSCRIPT italic_b end_POSTSUPERSCRIPT</annotation></semantics></math> in Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#S3.F4" title="Figure 4 ‣ 3.4 𝐴²Bench ‣ 3 Method ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">4</span></a>) as input. The results of Animate Anyone&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Hu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib21" title="">2023</a>)</cite> are obtained by leveraging the publicly available reproduced code&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Corporation (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib11" title="">2024</a>)</cite>. Tab.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#S3.T1" title="Table 1 ‣ 3.4 𝐴²Bench ‣ 3 Method ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">1</span></a> presents the quantitative results, where <span class="ltx_text ltx_font_typewriter" id="S4.SS2.p1.13.8">Animate-X</span> markedly surpasses all comparative methods in terms of all metrics.
It is worth noting that, we do not use <math alttext="A^{2}" class="ltx_Math" display="inline" id="S4.SS2.p1.13.m13.1"><semantics id="S4.SS2.p1.13.m13.1a"><msup id="S4.SS2.p1.13.m13.1.1" xref="S4.SS2.p1.13.m13.1.1.cmml"><mi id="S4.SS2.p1.13.m13.1.1.2" xref="S4.SS2.p1.13.m13.1.1.2.cmml">A</mi><mn id="S4.SS2.p1.13.m13.1.1.3" xref="S4.SS2.p1.13.m13.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.13.m13.1b"><apply id="S4.SS2.p1.13.m13.1.1.cmml" xref="S4.SS2.p1.13.m13.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.13.m13.1.1.1.cmml" xref="S4.SS2.p1.13.m13.1.1">superscript</csymbol><ci id="S4.SS2.p1.13.m13.1.1.2.cmml" xref="S4.SS2.p1.13.m13.1.1.2">𝐴</ci><cn id="S4.SS2.p1.13.m13.1.1.3.cmml" type="integer" xref="S4.SS2.p1.13.m13.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.13.m13.1c">A^{2}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.13.m13.1d">italic_A start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_typewriter" id="S4.SS2.p1.13.9">Bench</span> as training data to avoid overfitting and ensure fair comparisons, in line with other comparative methods.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">Following previous works which evaluate quantitative results in self-driven and reconstruction manner, we additionally compare our method with (a) GAN-based image animate works: FOMM&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Siarohin et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib42" title="">2019a</a>)</cite>, MRAA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Siarohin et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib44" title="">2021a</a>)</cite>, LIA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Wang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib63" title="">2022</a>)</cite>. (b) Diffusion model-based image animate works: DreamPose&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Karras et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib26" title="">2023</a>)</cite>, MagicAnimate&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Xu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib68" title="">2023a</a>)</cite> and present the results in Tab.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#S3.T2" title="Table 2 ‣ 3.4 𝐴²Bench ‣ 3 Method ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">2</span></a>, which indicates that our method achieves the best performance across all the metrics. Moreover, we provide the quantitative results on the human dataset (TikTok and Fashion) in Tab.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#A4.T7" title="Table 7 ‣ D.4 More ablation study ‣ Appendix D Additional Experimental Results ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">7</span></a> and Tab.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#A4.T8" title="Table 8 ‣ D.4 More ablation study ‣ Appendix D Additional Experimental Results ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">8</span></a>, respectively. Please refer to Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#A4.SS2" title="D.2 More quantitative results ‣ Appendix D Additional Experimental Results ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">D.2</span></a> for details. <span class="ltx_text ltx_font_typewriter" id="S4.SS2.p2.1.1">Animate-X</span> reaches the comparable score to Unianimate and exceeds other SOTA methods, which demonstrates the superiority of <span class="ltx_text ltx_font_typewriter" id="S4.SS2.p2.1.2">Animate-X</span> on <span class="ltx_text ltx_font_bold" id="S4.SS2.p2.1.3">both</span> anthropomorphic and human benchmarks.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.p3.1.1">Qualitative Results.</span>
Qualitative comparisons of anthropomorphic animation are shown in Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#S4.F5" title="Figure 5 ‣ 4.1 Experimental Settings ‣ 4 Experiments ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">5</span></a>. We observe that GAN-based LIA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Wang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib63" title="">2022</a>)</cite> does not generalize well, which can only work on a specific dataset like&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Siarohin et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib43" title="">2019b</a>)</cite>.
Benefiting from the powerful generative capabilities of the diffusion model, Animate Anyone&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Hu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib21" title="">2023</a>)</cite> renders a higher resolution image, but the identity of the image changes and do not generate an accurate reference pose motion. Although MusePose&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Tong et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib54" title="">2024</a>)</cite>, Unianimate&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Wang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib61" title="">2024b</a>)</cite> and MimicMotion&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Zhang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib82" title="">2024</a>)</cite> improve the accuracy of the motion transfer, these methods generate a unseen person, which is not the desired result.
ControlNeXt combines the advantages of the above two types of methods, so maintains the consistency of identity and motion transfer to some extent, yet the results are somewhat unnatural and unsatisfactory, <span class="ltx_text ltx_font_italic" id="S4.SS2.p3.1.2">e.g.</span>, the ears of the rabbit and the legs of the banana in Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#S4.F5" title="Figure 5 ‣ 4.1 Experimental Settings ‣ 4 Experiments ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">5</span></a>.
In contrast, <span class="ltx_text ltx_font_typewriter" id="S4.SS2.p3.1.3">Animate-X</span> ensures both identity and consistency with the reference image while generating expressive and exaggerated figure motion, rather than simply adopting quasi-static motion of the target character.
Further, we present some long video comparisons in Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#S4.F6" title="Figure 6 ‣ 4.2 Experimental Results ‣ 4 Experiments ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">6</span></a>.
Unianimate generates a woman out of thin air who dances according to the given pose images. <span class="ltx_text ltx_font_typewriter" id="S4.SS2.p3.1.4">Animate-X</span> animates the reference image in a cute way while preserving appearance and temporal continuity, and it does not generate parts that do not originally exist.
In summary, <span class="ltx_text ltx_font_typewriter" id="S4.SS2.p3.1.5">Animate-X</span> excels in maintaining appearance and producing precise, vivid animations with a high temporal consistency.
Please refer to Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#A4.SS1" title="D.1 More qualitative results ‣ Appendix D Additional Experimental Results ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">D.1</span></a> for details.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S4.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="552" id="S4.F6.g1" src="./animate-x_files/x5.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Qualitative comparisons with Unianimate in terms of long video generation.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="S4.T3">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T3.3" style="width:433.6pt;height:63.2pt;vertical-align:-0.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-33.8pt,4.9pt) scale(0.865219735948581,0.865219735948581) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T3.3.3">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T3.3.3.4.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" id="S4.T3.3.3.4.1.1" style="padding-left:6.5pt;padding-right:6.5pt;">Method</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.3.3.4.1.2" style="padding-left:6.5pt;padding-right:6.5pt;">Moore-AA</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.3.3.4.1.3" style="padding-left:6.5pt;padding-right:6.5pt;">MimicMotion</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.3.3.4.1.4" style="padding-left:6.5pt;padding-right:6.5pt;">ControlNeXt</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.3.3.4.1.5" style="padding-left:6.5pt;padding-right:6.5pt;">MusePose</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.3.3.4.1.6" style="padding-left:6.5pt;padding-right:6.5pt;">Unianimate</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.3.3.4.1.7" style="padding-left:6.5pt;padding-right:6.5pt;"><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="S4.T3.3.3.4.1.7.1">Animate-X</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T3.1.1.1.1" style="padding-left:6.5pt;padding-right:6.5pt;">Identity preservation <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T3.1.1.1.1.m1.1"><semantics id="S4.T3.1.1.1.1.m1.1a"><mo id="S4.T3.1.1.1.1.m1.1.1" stretchy="false" xref="S4.T3.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T3.1.1.1.1.m1.1b"><ci id="S4.T3.1.1.1.1.m1.1.1.cmml" xref="S4.T3.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.1.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T3.1.1.1.1.m1.1d">↑</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.1.2" style="padding-left:6.5pt;padding-right:6.5pt;">60.4%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.1.3" style="padding-left:6.5pt;padding-right:6.5pt;">14.8%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.1.4" style="padding-left:6.5pt;padding-right:6.5pt;">52.0%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.1.5" style="padding-left:6.5pt;padding-right:6.5pt;">31.3%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.1.6" style="padding-left:6.5pt;padding-right:6.5pt;">43.0%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.1.7" style="padding-left:6.5pt;padding-right:6.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.7.1">98.5%</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T3.2.2.2.1" style="padding-left:6.5pt;padding-right:6.5pt;">Temporal consistency <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T3.2.2.2.1.m1.1"><semantics id="S4.T3.2.2.2.1.m1.1a"><mo id="S4.T3.2.2.2.1.m1.1.1" stretchy="false" xref="S4.T3.2.2.2.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T3.2.2.2.1.m1.1b"><ci id="S4.T3.2.2.2.1.m1.1.1.cmml" xref="S4.T3.2.2.2.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.2.2.2.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T3.2.2.2.1.m1.1d">↑</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.2.2" style="padding-left:6.5pt;padding-right:6.5pt;">19.8%</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.2.3" style="padding-left:6.5pt;padding-right:6.5pt;">24.9%</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.2.4" style="padding-left:6.5pt;padding-right:6.5pt;">36.9%</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.2.5" style="padding-left:6.5pt;padding-right:6.5pt;">43.9%</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.2.6" style="padding-left:6.5pt;padding-right:6.5pt;">81.1%</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.2.7" style="padding-left:6.5pt;padding-right:6.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.2.2.2.7.1">93.4%</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.3.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r" id="S4.T3.3.3.3.1" style="padding-left:6.5pt;padding-right:6.5pt;">Visual quality <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T3.3.3.3.1.m1.1"><semantics id="S4.T3.3.3.3.1.m1.1a"><mo id="S4.T3.3.3.3.1.m1.1.1" stretchy="false" xref="S4.T3.3.3.3.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T3.3.3.3.1.m1.1b"><ci id="S4.T3.3.3.3.1.m1.1.1.cmml" xref="S4.T3.3.3.3.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.3.3.3.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T3.3.3.3.1.m1.1d">↑</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T3.3.3.3.2" style="padding-left:6.5pt;padding-right:6.5pt;">27.0%</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T3.3.3.3.3" style="padding-left:6.5pt;padding-right:6.5pt;">17.2%</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T3.3.3.3.4" style="padding-left:6.5pt;padding-right:6.5pt;">40.4%</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T3.3.3.3.5" style="padding-left:6.5pt;padding-right:6.5pt;">40.3%</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T3.3.3.3.6" style="padding-left:6.5pt;padding-right:6.5pt;">79.3%</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T3.3.3.3.7" style="padding-left:6.5pt;padding-right:6.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.3.3.3.7.1">95.8%</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>
User study results.
</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.SS2.p4">
<p class="ltx_p" id="S4.SS2.p4.2"><span class="ltx_text ltx_font_bold" id="S4.SS2.p4.2.1">User Study.</span>
To estimate the quality of our method and SOTAs from human perspectives, we conduct a blind user study with 10 participants. Specifically, we randomly select 10 characters from <math alttext="A^{2}" class="ltx_Math" display="inline" id="S4.SS2.p4.1.m1.1"><semantics id="S4.SS2.p4.1.m1.1a"><msup id="S4.SS2.p4.1.m1.1.1" xref="S4.SS2.p4.1.m1.1.1.cmml"><mi id="S4.SS2.p4.1.m1.1.1.2" xref="S4.SS2.p4.1.m1.1.1.2.cmml">A</mi><mn id="S4.SS2.p4.1.m1.1.1.3" xref="S4.SS2.p4.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.1.m1.1b"><apply id="S4.SS2.p4.1.m1.1.1.cmml" xref="S4.SS2.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p4.1.m1.1.1.1.cmml" xref="S4.SS2.p4.1.m1.1.1">superscript</csymbol><ci id="S4.SS2.p4.1.m1.1.1.2.cmml" xref="S4.SS2.p4.1.m1.1.1.2">𝐴</ci><cn id="S4.SS2.p4.1.m1.1.1.3.cmml" type="integer" xref="S4.SS2.p4.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.1.m1.1c">A^{2}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p4.1.m1.1d">italic_A start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_typewriter" id="S4.SS2.p4.2.2">Bench</span> and collect 10 driving video from the website. For each of 6 methods tested, 10 animation clips are generated, resulting in a total of 60 clips. Each participant is presented two results generated by different methods for the same set of inputs and asked to choose which one is better in terms of <span class="ltx_text ltx_font_italic" id="S4.SS2.p4.2.3">visual quality</span>, <span class="ltx_text ltx_font_italic" id="S4.SS2.p4.2.4">identity preservation</span>, and <span class="ltx_text ltx_font_italic" id="S4.SS2.p4.2.5">temporal consistency</span>. This process is repeated <math alttext="C^{6}_{2}" class="ltx_Math" display="inline" id="S4.SS2.p4.2.m2.1"><semantics id="S4.SS2.p4.2.m2.1a"><msubsup id="S4.SS2.p4.2.m2.1.1" xref="S4.SS2.p4.2.m2.1.1.cmml"><mi id="S4.SS2.p4.2.m2.1.1.2.2" xref="S4.SS2.p4.2.m2.1.1.2.2.cmml">C</mi><mn id="S4.SS2.p4.2.m2.1.1.3" xref="S4.SS2.p4.2.m2.1.1.3.cmml">2</mn><mn id="S4.SS2.p4.2.m2.1.1.2.3" xref="S4.SS2.p4.2.m2.1.1.2.3.cmml">6</mn></msubsup><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.2.m2.1b"><apply id="S4.SS2.p4.2.m2.1.1.cmml" xref="S4.SS2.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p4.2.m2.1.1.1.cmml" xref="S4.SS2.p4.2.m2.1.1">subscript</csymbol><apply id="S4.SS2.p4.2.m2.1.1.2.cmml" xref="S4.SS2.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p4.2.m2.1.1.2.1.cmml" xref="S4.SS2.p4.2.m2.1.1">superscript</csymbol><ci id="S4.SS2.p4.2.m2.1.1.2.2.cmml" xref="S4.SS2.p4.2.m2.1.1.2.2">𝐶</ci><cn id="S4.SS2.p4.2.m2.1.1.2.3.cmml" type="integer" xref="S4.SS2.p4.2.m2.1.1.2.3">6</cn></apply><cn id="S4.SS2.p4.2.m2.1.1.3.cmml" type="integer" xref="S4.SS2.p4.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.2.m2.1c">C^{6}_{2}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p4.2.m2.1d">italic_C start_POSTSUPERSCRIPT 6 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math> times. The results are summarized in Tab.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#S4.T3" title="Table 3 ‣ 4.2 Experimental Results ‣ 4 Experiments ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">3</span></a>, where our method noticeably outperforms other methods in all aspects, demonstrating its superiority and effectiveness. <span class="ltx_text" id="S4.SS2.p4.2.6" style="color:#000000;">Details in Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#A3" title="Appendix C User Study ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">C</span></a>.</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S4.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="402" id="S4.F7.g1" src="./animate-x_files/x6.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Visualization of ablation study on IPI and EPI.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Ablation Study</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1"><span class="ltx_text ltx_font_bold" id="S4.SS3.p1.1.1">Ablation on Implicit Pose Indicator.</span>
To analyze the contributions of Implicit Pose Indicator, we remove it from <span class="ltx_text ltx_font_typewriter" id="S4.SS3.p1.1.2">Animate-X</span> as w/o IPI and compare it with Baseline and <span class="ltx_text ltx_font_typewriter" id="S4.SS3.p1.1.3">Animate-X</span>. From the first row of Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#S4.F7" title="Figure 7 ‣ 4.2 Experimental Results ‣ 4 Experiments ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">7</span></a>, we observe that Baseline generates a person whose appearance is appreciably distinct from the reference image. With the help of EPI, this problem is mildly mitigated. However, due to the absence of IPI, compared to Ours, there are still strange things and human-like hands appearing, as indicated by the blue circle. For more detailed analysis about the structure of IPI, we set up several variants: (1) remove IPI: w/o IPI. (2) remove learnable query: w/o LQ. (3) remove DWPose query: w/o DQ. The quantitative results are shown in Tab.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#S4.T4" title="Table 4 ‣ 4.3 Ablation Study ‣ 4 Experiments ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">4</span></a>. It can be seen that removing the entire IPI presents the worst performance. By modifying the IPI module, although it improves on the w/o IPI, it still falls short of the final result of <span class="ltx_text ltx_font_typewriter" id="S4.SS3.p1.1.4">Animate-X</span>, which suggests that our current IPI structure is the most reasonable and achieves the best performance.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table ltx_align_floatright" id="S4.T4">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T4.7" style="width:433.6pt;height:188.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(50.9pt,-22.1pt) scale(1.30673799336996,1.30673799336996) ;">
<table class="ltx_tabular ltx_align_middle" id="S4.T4.7.7">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T4.7.7.7">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.7.7.7.8" style="padding-left:1.0pt;padding-right:1.0pt;">Method</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T4.1.1.1.1" style="padding-left:1.0pt;padding-right:1.0pt;">PSNR* <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T4.1.1.1.1.m1.1"><semantics id="S4.T4.1.1.1.1.m1.1a"><mo id="S4.T4.1.1.1.1.m1.1.1" stretchy="false" xref="S4.T4.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T4.1.1.1.1.m1.1b"><ci id="S4.T4.1.1.1.1.m1.1.1.cmml" xref="S4.T4.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.1.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T4.1.1.1.1.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T4.2.2.2.2" style="padding-left:1.0pt;padding-right:1.0pt;">SSIM <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T4.2.2.2.2.m1.1"><semantics id="S4.T4.2.2.2.2.m1.1a"><mo id="S4.T4.2.2.2.2.m1.1.1" stretchy="false" xref="S4.T4.2.2.2.2.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T4.2.2.2.2.m1.1b"><ci id="S4.T4.2.2.2.2.m1.1.1.cmml" xref="S4.T4.2.2.2.2.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.2.2.2.2.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T4.2.2.2.2.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T4.3.3.3.3" style="padding-left:1.0pt;padding-right:1.0pt;">L1 <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T4.3.3.3.3.m1.1"><semantics id="S4.T4.3.3.3.3.m1.1a"><mo id="S4.T4.3.3.3.3.m1.1.1" stretchy="false" xref="S4.T4.3.3.3.3.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T4.3.3.3.3.m1.1b"><ci id="S4.T4.3.3.3.3.m1.1.1.cmml" xref="S4.T4.3.3.3.3.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.3.3.3.3.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T4.3.3.3.3.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T4.4.4.4.4" style="padding-left:1.0pt;padding-right:1.0pt;">LPIPS <math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T4.4.4.4.4.m1.1"><semantics id="S4.T4.4.4.4.4.m1.1a"><mo id="S4.T4.4.4.4.4.m1.1.1" stretchy="false" xref="S4.T4.4.4.4.4.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T4.4.4.4.4.m1.1b"><ci id="S4.T4.4.4.4.4.m1.1.1.cmml" xref="S4.T4.4.4.4.4.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.4.4.4.4.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T4.4.4.4.4.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.5.5.5.5" style="padding-left:1.0pt;padding-right:1.0pt;">FID <math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T4.5.5.5.5.m1.1"><semantics id="S4.T4.5.5.5.5.m1.1a"><mo id="S4.T4.5.5.5.5.m1.1.1" stretchy="false" xref="S4.T4.5.5.5.5.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T4.5.5.5.5.m1.1b"><ci id="S4.T4.5.5.5.5.m1.1.1.cmml" xref="S4.T4.5.5.5.5.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.5.5.5.5.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T4.5.5.5.5.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T4.6.6.6.6" style="padding-left:1.0pt;padding-right:1.0pt;">FID-VID <math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T4.6.6.6.6.m1.1"><semantics id="S4.T4.6.6.6.6.m1.1a"><mo id="S4.T4.6.6.6.6.m1.1.1" stretchy="false" xref="S4.T4.6.6.6.6.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T4.6.6.6.6.m1.1b"><ci id="S4.T4.6.6.6.6.m1.1.1.cmml" xref="S4.T4.6.6.6.6.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.6.6.6.6.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T4.6.6.6.6.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T4.7.7.7.7" style="padding-left:1.0pt;padding-right:1.0pt;">FVD <math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T4.7.7.7.7.m1.1"><semantics id="S4.T4.7.7.7.7.m1.1a"><mo id="S4.T4.7.7.7.7.m1.1.1" stretchy="false" xref="S4.T4.7.7.7.7.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T4.7.7.7.7.m1.1b"><ci id="S4.T4.7.7.7.7.m1.1.1.cmml" xref="S4.T4.7.7.7.7.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.7.7.7.7.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T4.7.7.7.7.m1.1d">↓</annotation></semantics></math>
</td>
</tr>
<tr class="ltx_tr" id="S4.T4.7.7.8.1">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.7.7.8.1.1" style="padding-left:1.0pt;padding-right:1.0pt;">w/o IPI</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T4.7.7.8.1.2" style="padding-left:1.0pt;padding-right:1.0pt;">13.30</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T4.7.7.8.1.3" style="padding-left:1.0pt;padding-right:1.0pt;">0.433</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T4.7.7.8.1.4" style="padding-left:1.0pt;padding-right:1.0pt;">1.35E-04</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T4.7.7.8.1.5" style="padding-left:1.0pt;padding-right:1.0pt;">0.454</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.7.7.8.1.6" style="padding-left:1.0pt;padding-right:1.0pt;">32.56</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T4.7.7.8.1.7" style="padding-left:1.0pt;padding-right:1.0pt;">64.31</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T4.7.7.8.1.8" style="padding-left:1.0pt;padding-right:1.0pt;">893.31</td>
</tr>
<tr class="ltx_tr" id="S4.T4.7.7.9.2">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_r" id="S4.T4.7.7.9.2.1" style="padding-left:1.0pt;padding-right:1.0pt;">w/o LQ</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T4.7.7.9.2.2" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T4.7.7.9.2.2.1">13.48</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T4.7.7.9.2.3" style="padding-left:1.0pt;padding-right:1.0pt;">0.445</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T4.7.7.9.2.4" style="padding-left:1.0pt;padding-right:1.0pt;">1.76E-04</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T4.7.7.9.2.5" style="padding-left:1.0pt;padding-right:1.0pt;">0.454</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" id="S4.T4.7.7.9.2.6" style="padding-left:1.0pt;padding-right:1.0pt;">28.24</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T4.7.7.9.2.7" style="padding-left:1.0pt;padding-right:1.0pt;">42.74</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T4.7.7.9.2.8" style="padding-left:1.0pt;padding-right:1.0pt;">754.37</td>
</tr>
<tr class="ltx_tr" id="S4.T4.7.7.10.3">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_r" id="S4.T4.7.7.10.3.1" style="padding-left:1.0pt;padding-right:1.0pt;">w/o DQ</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T4.7.7.10.3.2" style="padding-left:1.0pt;padding-right:1.0pt;">13.39</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T4.7.7.10.3.3" style="padding-left:1.0pt;padding-right:1.0pt;">0.445</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T4.7.7.10.3.4" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.7.7.10.3.4.1">1.01E-04</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T4.7.7.10.3.5" style="padding-left:1.0pt;padding-right:1.0pt;">0.456</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" id="S4.T4.7.7.10.3.6" style="padding-left:1.0pt;padding-right:1.0pt;">30.33</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T4.7.7.10.3.7" style="padding-left:1.0pt;padding-right:1.0pt;">62.34</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T4.7.7.10.3.8" style="padding-left:1.0pt;padding-right:1.0pt;">913.33</td>
</tr>
<tr class="ltx_tr" id="S4.T4.7.7.11.4">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.7.7.11.4.1" style="padding-left:1.0pt;padding-right:1.0pt;">w/o EPI</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T4.7.7.11.4.2" style="padding-left:1.0pt;padding-right:1.0pt;">12.63</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T4.7.7.11.4.3" style="padding-left:1.0pt;padding-right:1.0pt;">0.403</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T4.7.7.11.4.4" style="padding-left:1.0pt;padding-right:1.0pt;">1.80E-04</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T4.7.7.11.4.5" style="padding-left:1.0pt;padding-right:1.0pt;">0.509</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.7.7.11.4.6" style="padding-left:1.0pt;padding-right:1.0pt;">42.17</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T4.7.7.11.4.7" style="padding-left:1.0pt;padding-right:1.0pt;">58.17</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T4.7.7.11.4.8" style="padding-left:1.0pt;padding-right:1.0pt;">948.25</td>
</tr>
<tr class="ltx_tr" id="S4.T4.7.7.12.5">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_r" id="S4.T4.7.7.12.5.1" style="padding-left:1.0pt;padding-right:1.0pt;">w/o Realign</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T4.7.7.12.5.2" style="padding-left:1.0pt;padding-right:1.0pt;">12.27</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T4.7.7.12.5.3" style="padding-left:1.0pt;padding-right:1.0pt;">0.433</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T4.7.7.12.5.4" style="padding-left:1.0pt;padding-right:1.0pt;">1.17E-04</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T4.7.7.12.5.5" style="padding-left:1.0pt;padding-right:1.0pt;">0.434</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" id="S4.T4.7.7.12.5.6" style="padding-left:1.0pt;padding-right:1.0pt;">34.60</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T4.7.7.12.5.7" style="padding-left:1.0pt;padding-right:1.0pt;">49.33</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T4.7.7.12.5.8" style="padding-left:1.0pt;padding-right:1.0pt;">860.25</td>
</tr>
<tr class="ltx_tr" id="S4.T4.7.7.13.6">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_r" id="S4.T4.7.7.13.6.1" style="padding-left:1.0pt;padding-right:1.0pt;">w/o Rescale</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T4.7.7.13.6.2" style="padding-left:1.0pt;padding-right:1.0pt;">13.23</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T4.7.7.13.6.3" style="padding-left:1.0pt;padding-right:1.0pt;">0.438</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T4.7.7.13.6.4" style="padding-left:1.0pt;padding-right:1.0pt;">1.21E-04</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T4.7.7.13.6.5" style="padding-left:1.0pt;padding-right:1.0pt;">0.464</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" id="S4.T4.7.7.13.6.6" style="padding-left:1.0pt;padding-right:1.0pt;">27.64</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T4.7.7.13.6.7" style="padding-left:1.0pt;padding-right:1.0pt;">35.95</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T4.7.7.13.6.8" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T4.7.7.13.6.8.1">721.11</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.7.7.14.7" style="background-color:#F0F0F0;">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S4.T4.7.7.14.7.1" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="S4.T4.7.7.14.7.1.1" style="background-color:#F0F0F0;">Animate-X</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_t" id="S4.T4.7.7.14.7.2" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.7.7.14.7.2.1" style="background-color:#F0F0F0;">13.60</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_t" id="S4.T4.7.7.14.7.3" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.7.7.14.7.3.1" style="background-color:#F0F0F0;">0.452</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_t" id="S4.T4.7.7.14.7.4" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T4.7.7.14.7.4.1" style="background-color:#F0F0F0;">1.02E-04</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_t" id="S4.T4.7.7.14.7.5" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.7.7.14.7.5.1" style="background-color:#F0F0F0;">0.430</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T4.7.7.14.7.6" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.7.7.14.7.6.1" style="background-color:#F0F0F0;">26.11</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_t" id="S4.T4.7.7.14.7.7" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.7.7.14.7.7.1" style="background-color:#F0F0F0;">32.23</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_t" id="S4.T4.7.7.14.7.8" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.7.7.14.7.8.1" style="background-color:#F0F0F0;">703.87</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>
Quantitative results of ablation study.
</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS3.p2.1.1">Ablation on Explicit Pose Indicator.</span> We demonstrate the visual results of ablating EPI setting in the second row of Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#S4.F7" title="Figure 7 ‣ 4.2 Experimental Results ‣ 4 Experiments ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">7</span></a> by removing EPI. Without EPI, although the appearance of the panda is preserved thanks to IPI, the model incorrectly treats the panda’s ears as arms and forcibly stretches the legs to match the length of the legs in the pose image indicated by red circles. In contrast, these issues are completely resolved by the assistance of EPI. We further conduct more detailed ablation experiments for different pairs of pose transformations by (1) removing the entire EPI: w/o EPI. (3) remove Pose Realignment: w/o Realignment. (2) removing Pose Rescale: w/o Rescale; From the results displayed in Tab.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#S4.T4" title="Table 4 ‣ 4.3 Ablation Study ‣ 4 Experiments ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">4</span></a>, we found that Pose Realignment contributes the most. It suggests that simulating misalignment case in inference is the the key factor.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS3.p3">
<p class="ltx_p" id="S4.SS3.p3.1">In summary, we can draw conclusions: (1) IPI facilitates the preservation of appearance and prevents the generation of content that does not exist in the reference image like human arms. (2) EPI prevents the forced alignment of a pose image that is not naturally aligned with the reference image during animation, thus avoiding the unintended animation of parts that should remain static like the panda’s ears shown in Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#S4.F7" title="Figure 7 ‣ 4.2 Experimental Results ‣ 4 Experiments ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">7</span></a>. Please refer to Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#A4.SS4" title="D.4 More ablation study ‣ Appendix D Additional Experimental Results ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">D.4</span></a> for details.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusions</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">In this study, we present <span class="ltx_text ltx_font_typewriter" id="S5.p1.1.1">Animate-X</span>, a novel approach to character animation capable of generalizing across different types of characters named <span class="ltx_text ltx_font_typewriter" id="S5.p1.1.2">X</span>. To address the imbalance between identity preservation and movement consistency caused by the insufficient motion representation, we introduce the Pose Indicator, which leverages both implicit and explicit features to enhance the motion understanding of the model. In this way, <span class="ltx_text ltx_font_typewriter" id="S5.p1.1.3">Animate-X</span> demonstrates strong generalization and robustness, achieving general X character animation.
The proposed framework showcases significant improvements over state-of-the-art methods in terms of identity preservation and motion consistency, as evidenced by experiments on both public datasets and the newly introduced <math alttext="A^{2}" class="ltx_Math" display="inline" id="S5.p1.1.m1.1"><semantics id="S5.p1.1.m1.1a"><msup id="S5.p1.1.m1.1.1" xref="S5.p1.1.m1.1.1.cmml"><mi id="S5.p1.1.m1.1.1.2" xref="S5.p1.1.m1.1.1.2.cmml">A</mi><mn id="S5.p1.1.m1.1.1.3" xref="S5.p1.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S5.p1.1.m1.1b"><apply id="S5.p1.1.m1.1.1.cmml" xref="S5.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.p1.1.m1.1.1.1.cmml" xref="S5.p1.1.m1.1.1">superscript</csymbol><ci id="S5.p1.1.m1.1.1.2.cmml" xref="S5.p1.1.m1.1.1.2">𝐴</ci><cn id="S5.p1.1.m1.1.1.3.cmml" type="integer" xref="S5.p1.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.1.m1.1c">A^{2}</annotation><annotation encoding="application/x-llamapun" id="S5.p1.1.m1.1d">italic_A start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_typewriter" id="S5.p1.1.4">Bench</span>, which features anthropomorphic characters. Limitation and ethical considerations see Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#A5" title="Appendix E Discussion ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">E</span></a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">An et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jie An, Songyang Zhang, Harry Yang, Sonal Gupta, Jia-Bin Huang, Jiebo Luo, and Xi&nbsp;Yin.

</span>
<span class="ltx_bibblock">Latent-shift: Latent diffusion with temporal shift for efficient text-to-video generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">arXiv preprint arXiv:2304.08477</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Awadalla et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Anas Awadalla, Irena Gao, Josh Gardner, Jack Hessel, Yusuf Hanafy, Wanrong Zhu, Kalyani Marathe, Yonatan Bitton, Samir Gadre, Shiori Sagawa, et&nbsp;al.

</span>
<span class="ltx_bibblock">Openflamingo: An open-source framework for training large autoregressive vision-language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">arXiv preprint arXiv:2308.01390</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Balaji et&nbsp;al. (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yogesh Balaji, Martin&nbsp;Renqiang Min, Bing Bai, Rama Chellappa, and Hans&nbsp;Peter Graf.

</span>
<span class="ltx_bibblock">Conditional GAN with discriminative filter generation for text-to-video synthesis.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">IJCAI</em>, volume&nbsp;1, pp.&nbsp;&nbsp;2, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bhunia et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ankan&nbsp;Kumar Bhunia, Salman Khan, Hisham Cholakkal, Rao&nbsp;Muhammad Anwer, Jorma Laaksonen, Mubarak Shah, and Fahad&nbsp;Shahbaz Khan.

</span>
<span class="ltx_bibblock">Person image synthesis via denoising diffusion model.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">CVPR</em>, pp.&nbsp; 5968–5976, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Blattmann et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Andreas Blattmann, Robin Rombach, Huan Ling, Tim Dockhorn, Seung&nbsp;Wook Kim, Sanja Fidler, and Karsten Kreis.

</span>
<span class="ltx_bibblock">Align your latents: High-resolution video synthesis with latent diffusion models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">CVPR</em>, pp.&nbsp; 22563–22575, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Boulkenafet et&nbsp;al. (2015)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zinelabidine Boulkenafet, Jukka Komulainen, and Abdenour Hadid.

</span>
<span class="ltx_bibblock">Face anti-spoofing based on color texture analysis.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">2015 IEEE international conference on image processing (ICIP)</em>, pp.&nbsp; 2636–2640. IEEE, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ceylan et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Duygu Ceylan, Chun-Hao&nbsp;P Huang, and Niloy&nbsp;J Mitra.

</span>
<span class="ltx_bibblock">Pix2video: Video editing using image diffusion.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">ICCV</em>, pp.&nbsp; 23206–23217, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chai et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Wenhao Chai, Xun Guo, Gaoang Wang, and Yan Lu.

</span>
<span class="ltx_bibblock">Stablevideo: Text-driven consistency-aware diffusion video editing.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">ICCV</em>, pp.&nbsp; 23040–23050, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chang et&nbsp;al. (2023a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Di&nbsp;Chang, Yichun Shi, Quankai Gao, Jessica Fu, Hongyi Xu, Guoxian Song, Qing Yan, Xiao Yang, and Mohammad Soleymani.

</span>
<span class="ltx_bibblock">Magicdance: Realistic human dance video generation with motions &amp; facial expressions transfer.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">arXiv preprint arXiv:2311.12052</em>, 2023a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chang et&nbsp;al. (2023b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Di&nbsp;Chang, Yichun Shi, Quankai Gao, Hongyi Xu, Jessica Fu, Guoxian Song, Qing Yan, Yizhe Zhu, Xiao Yang, and Mohammad Soleymani.

</span>
<span class="ltx_bibblock">Magicpose: Realistic human poses and facial expressions retargeting with identity-aware diffusion.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Forty-first International Conference on Machine Learning</em>, 2023b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Corporation (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Moore&nbsp;Threads Corporation.

</span>
<span class="ltx_bibblock">Moore-AnimateAnyone.

</span>
<span class="ltx_bibblock">2024.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/MooreThreads/Moore-AnimateAnyone" title="">https://github.com/MooreThreads/Moore-AnimateAnyone</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gong et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Biao Gong, Siteng Huang, Yutong Feng, Shiwei Zhang, Yuyuan Li, and Yu&nbsp;Liu.

</span>
<span class="ltx_bibblock">Check locate rectify: A training-free layout calibration system for text-to-image generation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pp.&nbsp; 6624–6634, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goodfellow et&nbsp;al. (2014)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio.

</span>
<span class="ltx_bibblock">Generative adversarial nets.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">NeurIPS</em>, 27, 2014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gu &amp; Dao (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Albert Gu and Tri Dao.

</span>
<span class="ltx_bibblock">Mamba: Linear-time sequence modeling with selective state spaces.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">arXiv preprint arXiv:2312.00752</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gu et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Albert Gu, Karan Goel, and Christopher Ré.

</span>
<span class="ltx_bibblock">Efficiently modeling long sequences with structured state spaces.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">arXiv preprint arXiv:2111.00396</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yuwei Guo, Ceyuan Yang, Anyi Rao, Yaohui Wang, Yu&nbsp;Qiao, Dahua Lin, and Bo&nbsp;Dai.

</span>
<span class="ltx_bibblock">Animatediff: Animate your personalized text-to-image diffusion models without specific tuning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">arXiv preprint arXiv:2307.04725</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Heusel et&nbsp;al. (2017)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter.

</span>
<span class="ltx_bibblock">Gans trained by a two time-scale update rule converge to a local nash equilibrium.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">Advances in neural information processing systems</em>, 30, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ho et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jonathan Ho, Ajay Jain, and Pieter Abbeel.

</span>
<span class="ltx_bibblock">Denoising diffusion probabilistic models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">NeurIPS</em>, 33:6840–6851, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ho et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jonathan Ho, William Chan, Chitwan Saharia, Jay Whang, Ruiqi Gao, Alexey Gritsenko, Diederik&nbsp;P Kingma, Ben Poole, Mohammad Norouzi, David&nbsp;J Fleet, et&nbsp;al.

</span>
<span class="ltx_bibblock">Imagen video: High definition video generation with diffusion models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">arXiv preprint arXiv:2210.02303</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hore &amp; Ziou (2010)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Alain Hore and Djemel Ziou.

</span>
<span class="ltx_bibblock">Image quality metrics: Psnr vs. ssim.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">2010 20th international conference on pattern recognition</em>, pp.&nbsp; 2366–2369. IEEE, 2010.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Li&nbsp;Hu, Xin Gao, Peng Zhang, Ke&nbsp;Sun, Bang Zhang, and Liefeng Bo.

</span>
<span class="ltx_bibblock">Animate anyone: Consistent and controllable image-to-video synthesis for character animation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">arXiv preprint arXiv:2311.17117</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Lianghua Huang, Di&nbsp;Chen, Yu&nbsp;Liu, Yujun Shen, Deli Zhao, and Jingren Zhou.

</span>
<span class="ltx_bibblock">Composer: Creative and controllable image synthesis with composable conditions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">ICML</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jaegle et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Andrew Jaegle, Felix Gimeno, Andy Brock, Oriol Vinyals, Andrew Zisserman, and Joao Carreira.

</span>
<span class="ltx_bibblock">Perceiver: General perception with iterative attention.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">International conference on machine learning</em>, pp.&nbsp; 4651–4664. PMLR, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jafarian &amp; Park (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yasamin Jafarian and Hyun&nbsp;Soo Park.

</span>
<span class="ltx_bibblock">Learning high fidelity depths of dressed humans by watching social media dance videos.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">CVPR</em>, pp.&nbsp; 12753–12762, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yuming Jiang, Shuai Yang, Haonan Qiu, Wayne Wu, Chen&nbsp;Change Loy, and Ziwei Liu.

</span>
<span class="ltx_bibblock">Text2human: Text-driven controllable human image generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">ACM Transactions on Graphics</em>, 41(4):1–11, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karras et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Johanna Karras, Aleksander Holynski, Ting-Chun Wang, and Ira Kemelmacher-Shlizerman.

</span>
<span class="ltx_bibblock">Dreampose: Fashion video synthesis with stable diffusion.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">ICCV</em>, pp.&nbsp; 22680–22690, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kingma (2013)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Diederik&nbsp;P Kingma.

</span>
<span class="ltx_bibblock">Auto-encoding variational bayes.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">arXiv preprint arXiv:1312.6114</em>, 2013.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et&nbsp;al. (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yining Li, Chen Huang, and Chen&nbsp;Change Loy.

</span>
<span class="ltx_bibblock">Dense intrinsic appearance flow for human pose transfer.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pp.&nbsp; 3693–3702, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ming Liu, Yuxiang Wei, Xiaohe Wu, Wangmeng Zuo, and Lei Zhang.

</span>
<span class="ltx_bibblock">Survey on leveraging pre-trained generative adversarial networks for image editing and restoration.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">Science China Information Sciences</em>, 66(5):151101, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Loshchilov &amp; Hutter (2017)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ilya Loshchilov and Frank Hutter.

</span>
<span class="ltx_bibblock">Decoupled weight decay regularization.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">arXiv preprint arXiv:1711.05101</em>, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mou et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Chong Mou, Xintao Wang, Liangbin Xie, Jian Zhang, Zhongang Qi, Ying Shan, and Xiaohu Qie.

</span>
<span class="ltx_bibblock">T2i-adapter: Learning adapters to dig out more controllable ability for text-to-image diffusion models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">arXiv preprint arXiv:2302.08453</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nichol et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Alexander&nbsp;Quinn Nichol, Prafulla Dhariwal, Aditya Ramesh, Pranav Shyam, Pamela Mishkin, Bob Mcgrew, Ilya Sutskever, and Mark Chen.

</span>
<span class="ltx_bibblock">Glide: Towards photorealistic image generation and editing with text-guided diffusion models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">ICML</em>, pp.&nbsp; 16784–16804, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
OpenAI.

</span>
<span class="ltx_bibblock">Chatgpt-4o.

</span>
<span class="ltx_bibblock">2024.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://chat.openai.com/chat" title="">https://chat.openai.com/chat</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Peng et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Bohao Peng, Jian Wang, Yuechen Zhang, Wenbo Li, Ming-Chang Yang, and Jiaya Jia.

</span>
<span class="ltx_bibblock">Controlnext: Powerful and efficient control for image and video generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">arXiv preprint arXiv:2408.06070</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qing et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhiwu Qing, Shiwei Zhang, Jiayu Wang, Xiang Wang, Yujie Wei, Yingya Zhang, Changxin Gao, and Nong Sang.

</span>
<span class="ltx_bibblock">Hierarchical spatio-temporal decoupling for text-to-video generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">arXiv preprint arXiv:2312.04483</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Alec Radford, Jong&nbsp;Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et&nbsp;al.

</span>
<span class="ltx_bibblock">Learning transferable visual models from natural language supervision.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">ICML</em>, pp.&nbsp; 8748–8763, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ramesh et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen.

</span>
<span class="ltx_bibblock">Hierarchical text-conditional image generation with clip latents.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">arXiv preprint arXiv:2204.06125</em>, 1(2):3, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ren et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yurui Ren, Xiaoqing Fan, Ge&nbsp;Li, Shan Liu, and Thomas&nbsp;H Li.

</span>
<span class="ltx_bibblock">Neural texture extraction and distribution for controllable person image synthesis.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">CVPR</em>, pp.&nbsp; 13535–13544, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rombach et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn Ommer.

</span>
<span class="ltx_bibblock">High-resolution image synthesis with latent diffusion models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">CVPR</em>, pp.&nbsp; 10684–10695, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Saharia et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily&nbsp;L Denton, Kamyar Ghasemipour, Raphael Gontijo&nbsp;Lopes, Burcu Karagol&nbsp;Ayan, Tim Salimans, et&nbsp;al.

</span>
<span class="ltx_bibblock">Photorealistic text-to-image diffusion models with deep language understanding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">NeurIPS</em>, 35:36479–36494, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shen et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Fei Shen, Hu&nbsp;Ye, Jun Zhang, Cong Wang, Xiao Han, and Yang Wei.

</span>
<span class="ltx_bibblock">Advancing pose-guided image synthesis with progressive conditional diffusion models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">The Twelfth International Conference on Learning Representations</em>, 2024.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=rHzapPnCgT" title="">https://openreview.net/forum?id=rHzapPnCgT</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Siarohin et&nbsp;al. (2019a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Aliaksandr Siarohin, Stéphane Lathuilière, Sergey Tulyakov, Elisa Ricci, and Nicu Sebe.

</span>
<span class="ltx_bibblock">First order motion model for image animation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">NeurIPS</em>, 32, 2019a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Siarohin et&nbsp;al. (2019b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Aliaksandr Siarohin, Stéphane Lathuilière, Sergey Tulyakov, Elisa Ricci, and Nicu Sebe.

</span>
<span class="ltx_bibblock">First order motion model for image animation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">Advances in neural information processing systems</em>, 32, 2019b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Siarohin et&nbsp;al. (2021a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Aliaksandr Siarohin, Oliver&nbsp;J Woodford, Jian Ren, Menglei Chai, and Sergey Tulyakov.

</span>
<span class="ltx_bibblock">Motion representations for articulated animation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">CVPR</em>, pp.&nbsp; 13653–13662, 2021a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Siarohin et&nbsp;al. (2021b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Aliaksandr Siarohin, Oliver&nbsp;J Woodford, Jian Ren, Menglei Chai, and Sergey Tulyakov.

</span>
<span class="ltx_bibblock">Motion representations for articulated animation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pp.&nbsp; 13653–13662, 2021b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Singer et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Uriel Singer, Adam Polyak, Thomas Hayes, Xi&nbsp;Yin, Jie An, Songyang Zhang, Qiyuan Hu, Harry Yang, Oron Ashual, Oran Gafni, et&nbsp;al.

</span>
<span class="ltx_bibblock">Make-a-video: Text-to-video generation without text-video data.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">ICLR</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Song et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jiaming Song, Chenlin Meng, and Stefano Ermon.

</span>
<span class="ltx_bibblock">Denoising diffusion implicit models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">ICLR</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tan et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Shuai Tan, Bin Ji, and Ye&nbsp;Pan.

</span>
<span class="ltx_bibblock">Emmn: Emotional motion memory network for audio-driven emotional talking face generation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib48.1.1">Proceedings of the IEEE/CVF International Conference on Computer Vision</em>, pp.&nbsp; 22146–22156, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tan et&nbsp;al. (2024a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Shuai Tan, Bin Ji, Mengxiao Bi, and Ye&nbsp;Pan.

</span>
<span class="ltx_bibblock">Edtalk: Efficient disentanglement for emotional talking head synthesis.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">arXiv preprint arXiv:2404.01647</em>, 2024a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tan et&nbsp;al. (2024b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Shuai Tan, Bin Ji, Yu&nbsp;Ding, and Ye&nbsp;Pan.

</span>
<span class="ltx_bibblock">Say anything with any style.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib50.1.1">Proceedings of the AAAI Conference on Artificial Intelligence</em>, volume&nbsp;38, pp.&nbsp; 5088–5096, 2024b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tan et&nbsp;al. (2024c)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Shuai Tan, Bin Ji, and Ye&nbsp;Pan.

</span>
<span class="ltx_bibblock">Flowvqtalker: High-quality emotional talking face generation through normalizing flow and quantization.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib51.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pp.&nbsp; 26317–26327, 2024c.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tan et&nbsp;al. (2024d)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Shuai Tan, Bin Ji, and Ye&nbsp;Pan.

</span>
<span class="ltx_bibblock">Style2talker: High-resolution talking head generation with emotion style and art style.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib52.1.1">Proceedings of the AAAI Conference on Artificial Intelligence</em>, volume&nbsp;38, pp.&nbsp; 5079–5087, 2024d.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Technology (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Kuaishou Technology.

</span>
<span class="ltx_bibblock">Kling ai.

</span>
<span class="ltx_bibblock">2024.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://klingai.kuaishou.com/" title="">https://klingai.kuaishou.com</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tong et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhengyan Tong, Chao Li, Zhaokang Chen, Bin Wu, and Wenjiang Zhou.

</span>
<span class="ltx_bibblock">Musepose: a pose-driven image-to-video framework for virtual human generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib54.1.1">arxiv</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Unterthiner et&nbsp;al. (2018)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Thomas Unterthiner, Sjoerd Van&nbsp;Steenkiste, Karol Kurach, Raphael Marinier, Marcin Michalski, and Sylvain Gelly.

</span>
<span class="ltx_bibblock">Towards accurate generative models of video: A new metric &amp; challenges.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib55.1.1">arXiv preprint arXiv:1812.01717</em>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaswani (2017)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
A&nbsp;Vaswani.

</span>
<span class="ltx_bibblock">Attention is all you need.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib56.1.1">Advances in Neural Information Processing Systems</em>, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2023a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jiuniu Wang, Hangjie Yuan, Dayou Chen, Yingya Zhang, Xiang Wang, and Shiwei Zhang.

</span>
<span class="ltx_bibblock">Modelscope text-to-video technical report.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib57.1.1">arXiv preprint arXiv:2308.06571</em>, 2023a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2023b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Tan Wang, Linjie Li, Kevin Lin, Chung-Ching Lin, Zhengyuan Yang, Hanwang Zhang, Zicheng Liu, and Lijuan Wang.

</span>
<span class="ltx_bibblock">Disco: Disentangled control for referring human dance generation in real world.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib58.1.1">arXiv e-prints</em>, pp.&nbsp; arXiv–2307, 2023b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2024a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Tan Wang, Linjie Li, Kevin Lin, Chung-Ching Lin, Zhengyuan Yang, Hanwang Zhang, Zicheng Liu, and Lijuan Wang.

</span>
<span class="ltx_bibblock">Disco: Disentangled control for referring human dance generation in real world.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib59.1.1">ICLR</em>, 2024a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2023c)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Xiang Wang, Hangjie Yuan, Shiwei Zhang, Dayou Chen, Jiuniu Wang, Yingya Zhang, Yujun Shen, Deli Zhao, and Jingren Zhou.

</span>
<span class="ltx_bibblock">Videocomposer: Compositional video synthesis with motion controllability.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib60.1.1">NeurIPS</em>, 2023c.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2024b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Xiang Wang, Shiwei Zhang, Changxin Gao, Jiayu Wang, Xiaoqiang Zhou, Yingya Zhang, Luxin Yan, and Nong Sang.

</span>
<span class="ltx_bibblock">Unianimate: Taming unified video diffusion models for consistent human image animation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib61.1.1">arXiv preprint arXiv:2406.01188</em>, 2024b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2024c)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Xiang Wang, Shiwei Zhang, Hangjie Yuan, Zhiwu Qing, Biao Gong, Yingya Zhang, Yujun Shen, Changxin Gao, and Nong Sang.

</span>
<span class="ltx_bibblock">A recipe for scaling up text-to-video generation with text-free videos.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib62.1.1">CVPR</em>, 2024c.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yaohui Wang, Di&nbsp;Yang, Francois Bremond, and Antitza Dantcheva.

</span>
<span class="ltx_bibblock">Latent image animator: Learning to animate images via latent space navigation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib63.1.1">arXiv preprint arXiv:2203.09043</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zezheng Wang, Zitong Yu, Chenxu Zhao, Xiangyu Zhu, Yunxiao Qin, Qiusheng Zhou, Feng Zhou, and Zhen Lei.

</span>
<span class="ltx_bibblock">Deep spatial gradient and temporal depth learning for face anti-spoofing.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib64.1.1">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>, pp.&nbsp; 5042–5051, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2004)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhou Wang, Alan&nbsp;C Bovik, Hamid&nbsp;R Sheikh, and Eero&nbsp;P Simoncelli.

</span>
<span class="ltx_bibblock">Image quality assessment: from error visibility to structural similarity.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib65.1.1">IEEE Transactions on Image Processing</em>, 13(4):600–612, 2004.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jay&nbsp;Zhangjie Wu, Yixiao Ge, Xintao Wang, Stan&nbsp;Weixian Lei, Yuchao Gu, Yufei Shi, Wynne Hsu, Ying Shan, Xiaohu Qie, and Mike&nbsp;Zheng Shou.

</span>
<span class="ltx_bibblock">Tune-a-video: One-shot tuning of image diffusion models for text-to-video generation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib66.1.1">ICCV</em>, pp.&nbsp; 7623–7633, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib67">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xing et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhen Xing, Qi&nbsp;Dai, Han Hu, Zuxuan Wu, and Yu-Gang Jiang.

</span>
<span class="ltx_bibblock">Simda: Simple diffusion adapter for efficient video generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib67.1.1">arXiv preprint arXiv:2308.09710</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib68">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et&nbsp;al. (2023a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhongcong Xu, Jianfeng Zhang, Jun&nbsp;Hao Liew, Hanshu Yan, Jia-Wei Liu, Chenxu Zhang, Jiashi Feng, and Mike&nbsp;Zheng Shou.

</span>
<span class="ltx_bibblock">Magicanimate: Temporally consistent human image animation using diffusion model.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib68.1.1">arXiv preprint arXiv:2311.16498</em>, 2023a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib69">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et&nbsp;al. (2023b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhongcong Xu, Jianfeng Zhang, Jun&nbsp;Hao Liew, Hanshu Yan, Jia-Wei Liu, Chenxu Zhang, Jiashi Feng, and Mike&nbsp;Zheng Shou.

</span>
<span class="ltx_bibblock">Magicanimate: Temporally consistent human image animation using diffusion model.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib69.1.1">arXiv</em>, 2023b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib70">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et&nbsp;al. (2018)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ceyuan Yang, Zhe Wang, Xinge Zhu, Chen Huang, Jianping Shi, and Dahua Lin.

</span>
<span class="ltx_bibblock">Pose guided human video generation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib70.1.1">ECCV</em>, pp.&nbsp; 201–216, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib71">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhendong Yang, Ailing Zeng, Chun Yuan, and Yu&nbsp;Li.

</span>
<span class="ltx_bibblock">Effective whole-body pose estimation with two-stages distillation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib71.1.1">ICCV</em>, pp.&nbsp; 4210–4220, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib72">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Wing-Yin Yu, Lai-Man Po, Ray&nbsp;CC Cheung, Yuzhi Zhao, Yu&nbsp;Xue, and Kun Li.

</span>
<span class="ltx_bibblock">Bidirectionally deformable motion modulation for video-based human pose transfer.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib72.1.1">ICCV</em>, pp.&nbsp; 7502–7512, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib73">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zitong Yu, Chenxu Zhao, Zezheng Wang, Yunxiao Qin, Zhuo Su, Xiaobai Li, Feng Zhou, and Guoying Zhao.

</span>
<span class="ltx_bibblock">Searching central difference convolutional networks for face anti-spoofing.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib73.1.1">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>, pp.&nbsp; 5295–5305, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib74">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yuan et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Hangjie Yuan, Shiwei Zhang, Xiang Wang, Yujie Wei, Tao Feng, Yining Pan, Yingya Zhang, Ziwei Liu, Samuel Albanie, and Dong Ni.

</span>
<span class="ltx_bibblock">Instructvideo: Instructing video diffusion models with human feedback.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib74.1.1">arXiv preprint arXiv:2312.12490</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib75">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zablotskaia et&nbsp;al. (2019a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Polina Zablotskaia, Aliaksandr Siarohin, Bo&nbsp;Zhao, and Leonid Sigal.

</span>
<span class="ltx_bibblock">Dwnet: Dense warp-based network for pose-guided human video generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib75.1.1">arXiv preprint arXiv:1910.09139</em>, 2019a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib76">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zablotskaia et&nbsp;al. (2019b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Polina Zablotskaia, Aliaksandr Siarohin, Bo&nbsp;Zhao, and Leonid Sigal.

</span>
<span class="ltx_bibblock">Dwnet: Dense warp-based network for pose-guided human video generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib76.1.1">arXiv preprint arXiv:1910.09139</em>, 2019b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib77">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al. (2023a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Lvmin Zhang, Anyi Rao, and Maneesh Agrawala.

</span>
<span class="ltx_bibblock">Adding conditional control to text-to-image diffusion models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib77.1.1">ICCV</em>, pp.&nbsp; 3836–3847, 2023a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib78">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al. (2023b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Lvmin Zhang, Anyi Rao, and Maneesh Agrawala.

</span>
<span class="ltx_bibblock">Adding conditional control to text-to-image diffusion models, 2023b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib79">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al. (2022a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Pengze Zhang, Lingxiao Yang, Jian-Huang Lai, and Xiaohua Xie.

</span>
<span class="ltx_bibblock">Exploring dual-task correlation for pose guided person image generation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib79.1.1">CVPR</em>, pp.&nbsp; 7713–7722, 2022a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib80">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al. (2022b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Pengze Zhang, Lingxiao Yang, Jian-Huang Lai, and Xiaohua Xie.

</span>
<span class="ltx_bibblock">Exploring dual-task correlation for pose guided person image generation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib80.1.1">CVPR</em>, pp.&nbsp; 7713–7722, 2022b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib81">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al. (2018)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Richard Zhang, Phillip Isola, Alexei&nbsp;A Efros, Eli Shechtman, and Oliver Wang.

</span>
<span class="ltx_bibblock">The unreasonable effectiveness of deep features as a perceptual metric.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib81.1.1">CVPR</em>, pp.&nbsp; 586–595, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib82">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yuang Zhang, Jiaxi Gu, Li-Wen Wang, Han Wang, Junqi Cheng, Yuefeng Zhu, and Fangyuan Zou.

</span>
<span class="ltx_bibblock">Mimicmotion: High-quality human motion video generation with confidence-aware pose guidance.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib82.1.1">arXiv preprint arXiv:2406.19680</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib83">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao &amp; Zhang (2022a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jian Zhao and Hui Zhang.

</span>
<span class="ltx_bibblock">Thin-plate spline motion model for image animation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib83.1.1">CVPR</em>, pp.&nbsp; 3657–3666, 2022a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib84">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao &amp; Zhang (2022b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jian Zhao and Hui Zhang.

</span>
<span class="ltx_bibblock">Thin-plate spline motion model for image animation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib84.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pp.&nbsp; 3657–3666, 2022b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib85">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Daquan Zhou, Weimin Wang, Hanshu Yan, Weiwei Lv, Yizhe Zhu, and Jiashi Feng.

</span>
<span class="ltx_bibblock">Magicvideo: Efficient video generation with latent diffusion models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib85.1.1">arXiv preprint arXiv:2211.11018</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib86">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Shenhao Zhu, Junming&nbsp;Leo Chen, Zuozhuo Dai, Yinghui Xu, Xun Cao, Yao Yao, Hao Zhu, and Siyu Zhu.

</span>
<span class="ltx_bibblock">Champ: Controllable and consistent human image animation with 3d parametric guidance.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib86.1.1">European Conference on Computer Vision (ECCV)</em>, 2024.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_appendix" id="Ax1">
<h2 class="ltx_title ltx_title_appendix">Appendices</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Network Details</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A1.p1">
<p class="ltx_p" id="A1.p1.12">Due to space constraints in the main paper, we only present a brief overview of the EPI process. Here, in Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#A1.F8" title="Figure 8 ‣ Appendix A Network Details ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">8</span></a>, we provide a more detailed explanation of the pose transformation in EPI, along with additional case examples. First, we sample a driving pose <math alttext="I^{p}" class="ltx_Math" display="inline" id="A1.p1.1.m1.1"><semantics id="A1.p1.1.m1.1a"><msup id="A1.p1.1.m1.1.1" xref="A1.p1.1.m1.1.1.cmml"><mi id="A1.p1.1.m1.1.1.2" xref="A1.p1.1.m1.1.1.2.cmml">I</mi><mi id="A1.p1.1.m1.1.1.3" xref="A1.p1.1.m1.1.1.3.cmml">p</mi></msup><annotation-xml encoding="MathML-Content" id="A1.p1.1.m1.1b"><apply id="A1.p1.1.m1.1.1.cmml" xref="A1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A1.p1.1.m1.1.1.1.cmml" xref="A1.p1.1.m1.1.1">superscript</csymbol><ci id="A1.p1.1.m1.1.1.2.cmml" xref="A1.p1.1.m1.1.1.2">𝐼</ci><ci id="A1.p1.1.m1.1.1.3.cmml" xref="A1.p1.1.m1.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.1.m1.1c">I^{p}</annotation><annotation encoding="application/x-llamapun" id="A1.p1.1.m1.1d">italic_I start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT</annotation></semantics></math> and then randomly select an anchor pose <math alttext="I^{p}_{anchor}" class="ltx_Math" display="inline" id="A1.p1.2.m2.1"><semantics id="A1.p1.2.m2.1a"><msubsup id="A1.p1.2.m2.1.1" xref="A1.p1.2.m2.1.1.cmml"><mi id="A1.p1.2.m2.1.1.2.2" xref="A1.p1.2.m2.1.1.2.2.cmml">I</mi><mrow id="A1.p1.2.m2.1.1.3" xref="A1.p1.2.m2.1.1.3.cmml"><mi id="A1.p1.2.m2.1.1.3.2" xref="A1.p1.2.m2.1.1.3.2.cmml">a</mi><mo id="A1.p1.2.m2.1.1.3.1" xref="A1.p1.2.m2.1.1.3.1.cmml">⁢</mo><mi id="A1.p1.2.m2.1.1.3.3" xref="A1.p1.2.m2.1.1.3.3.cmml">n</mi><mo id="A1.p1.2.m2.1.1.3.1a" xref="A1.p1.2.m2.1.1.3.1.cmml">⁢</mo><mi id="A1.p1.2.m2.1.1.3.4" xref="A1.p1.2.m2.1.1.3.4.cmml">c</mi><mo id="A1.p1.2.m2.1.1.3.1b" xref="A1.p1.2.m2.1.1.3.1.cmml">⁢</mo><mi id="A1.p1.2.m2.1.1.3.5" xref="A1.p1.2.m2.1.1.3.5.cmml">h</mi><mo id="A1.p1.2.m2.1.1.3.1c" xref="A1.p1.2.m2.1.1.3.1.cmml">⁢</mo><mi id="A1.p1.2.m2.1.1.3.6" xref="A1.p1.2.m2.1.1.3.6.cmml">o</mi><mo id="A1.p1.2.m2.1.1.3.1d" xref="A1.p1.2.m2.1.1.3.1.cmml">⁢</mo><mi id="A1.p1.2.m2.1.1.3.7" xref="A1.p1.2.m2.1.1.3.7.cmml">r</mi></mrow><mi id="A1.p1.2.m2.1.1.2.3" xref="A1.p1.2.m2.1.1.2.3.cmml">p</mi></msubsup><annotation-xml encoding="MathML-Content" id="A1.p1.2.m2.1b"><apply id="A1.p1.2.m2.1.1.cmml" xref="A1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="A1.p1.2.m2.1.1.1.cmml" xref="A1.p1.2.m2.1.1">subscript</csymbol><apply id="A1.p1.2.m2.1.1.2.cmml" xref="A1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="A1.p1.2.m2.1.1.2.1.cmml" xref="A1.p1.2.m2.1.1">superscript</csymbol><ci id="A1.p1.2.m2.1.1.2.2.cmml" xref="A1.p1.2.m2.1.1.2.2">𝐼</ci><ci id="A1.p1.2.m2.1.1.2.3.cmml" xref="A1.p1.2.m2.1.1.2.3">𝑝</ci></apply><apply id="A1.p1.2.m2.1.1.3.cmml" xref="A1.p1.2.m2.1.1.3"><times id="A1.p1.2.m2.1.1.3.1.cmml" xref="A1.p1.2.m2.1.1.3.1"></times><ci id="A1.p1.2.m2.1.1.3.2.cmml" xref="A1.p1.2.m2.1.1.3.2">𝑎</ci><ci id="A1.p1.2.m2.1.1.3.3.cmml" xref="A1.p1.2.m2.1.1.3.3">𝑛</ci><ci id="A1.p1.2.m2.1.1.3.4.cmml" xref="A1.p1.2.m2.1.1.3.4">𝑐</ci><ci id="A1.p1.2.m2.1.1.3.5.cmml" xref="A1.p1.2.m2.1.1.3.5">ℎ</ci><ci id="A1.p1.2.m2.1.1.3.6.cmml" xref="A1.p1.2.m2.1.1.3.6">𝑜</ci><ci id="A1.p1.2.m2.1.1.3.7.cmml" xref="A1.p1.2.m2.1.1.3.7">𝑟</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.2.m2.1c">I^{p}_{anchor}</annotation><annotation encoding="application/x-llamapun" id="A1.p1.2.m2.1d">italic_I start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_a italic_n italic_c italic_h italic_o italic_r end_POSTSUBSCRIPT</annotation></semantics></math> from the pose pool (two examples are shown in Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#A1.F8" title="Figure 8 ‣ Appendix A Network Details ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">8</span></a>). The driving pose <math alttext="I^{p}" class="ltx_Math" display="inline" id="A1.p1.3.m3.1"><semantics id="A1.p1.3.m3.1a"><msup id="A1.p1.3.m3.1.1" xref="A1.p1.3.m3.1.1.cmml"><mi id="A1.p1.3.m3.1.1.2" xref="A1.p1.3.m3.1.1.2.cmml">I</mi><mi id="A1.p1.3.m3.1.1.3" xref="A1.p1.3.m3.1.1.3.cmml">p</mi></msup><annotation-xml encoding="MathML-Content" id="A1.p1.3.m3.1b"><apply id="A1.p1.3.m3.1.1.cmml" xref="A1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="A1.p1.3.m3.1.1.1.cmml" xref="A1.p1.3.m3.1.1">superscript</csymbol><ci id="A1.p1.3.m3.1.1.2.cmml" xref="A1.p1.3.m3.1.1.2">𝐼</ci><ci id="A1.p1.3.m3.1.1.3.cmml" xref="A1.p1.3.m3.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.3.m3.1c">I^{p}</annotation><annotation encoding="application/x-llamapun" id="A1.p1.3.m3.1d">italic_I start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT</annotation></semantics></math> is aligned to the anchor pose <math alttext="I^{p}_{anchor}" class="ltx_Math" display="inline" id="A1.p1.4.m4.1"><semantics id="A1.p1.4.m4.1a"><msubsup id="A1.p1.4.m4.1.1" xref="A1.p1.4.m4.1.1.cmml"><mi id="A1.p1.4.m4.1.1.2.2" xref="A1.p1.4.m4.1.1.2.2.cmml">I</mi><mrow id="A1.p1.4.m4.1.1.3" xref="A1.p1.4.m4.1.1.3.cmml"><mi id="A1.p1.4.m4.1.1.3.2" xref="A1.p1.4.m4.1.1.3.2.cmml">a</mi><mo id="A1.p1.4.m4.1.1.3.1" xref="A1.p1.4.m4.1.1.3.1.cmml">⁢</mo><mi id="A1.p1.4.m4.1.1.3.3" xref="A1.p1.4.m4.1.1.3.3.cmml">n</mi><mo id="A1.p1.4.m4.1.1.3.1a" xref="A1.p1.4.m4.1.1.3.1.cmml">⁢</mo><mi id="A1.p1.4.m4.1.1.3.4" xref="A1.p1.4.m4.1.1.3.4.cmml">c</mi><mo id="A1.p1.4.m4.1.1.3.1b" xref="A1.p1.4.m4.1.1.3.1.cmml">⁢</mo><mi id="A1.p1.4.m4.1.1.3.5" xref="A1.p1.4.m4.1.1.3.5.cmml">h</mi><mo id="A1.p1.4.m4.1.1.3.1c" xref="A1.p1.4.m4.1.1.3.1.cmml">⁢</mo><mi id="A1.p1.4.m4.1.1.3.6" xref="A1.p1.4.m4.1.1.3.6.cmml">o</mi><mo id="A1.p1.4.m4.1.1.3.1d" xref="A1.p1.4.m4.1.1.3.1.cmml">⁢</mo><mi id="A1.p1.4.m4.1.1.3.7" xref="A1.p1.4.m4.1.1.3.7.cmml">r</mi></mrow><mi id="A1.p1.4.m4.1.1.2.3" xref="A1.p1.4.m4.1.1.2.3.cmml">p</mi></msubsup><annotation-xml encoding="MathML-Content" id="A1.p1.4.m4.1b"><apply id="A1.p1.4.m4.1.1.cmml" xref="A1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="A1.p1.4.m4.1.1.1.cmml" xref="A1.p1.4.m4.1.1">subscript</csymbol><apply id="A1.p1.4.m4.1.1.2.cmml" xref="A1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="A1.p1.4.m4.1.1.2.1.cmml" xref="A1.p1.4.m4.1.1">superscript</csymbol><ci id="A1.p1.4.m4.1.1.2.2.cmml" xref="A1.p1.4.m4.1.1.2.2">𝐼</ci><ci id="A1.p1.4.m4.1.1.2.3.cmml" xref="A1.p1.4.m4.1.1.2.3">𝑝</ci></apply><apply id="A1.p1.4.m4.1.1.3.cmml" xref="A1.p1.4.m4.1.1.3"><times id="A1.p1.4.m4.1.1.3.1.cmml" xref="A1.p1.4.m4.1.1.3.1"></times><ci id="A1.p1.4.m4.1.1.3.2.cmml" xref="A1.p1.4.m4.1.1.3.2">𝑎</ci><ci id="A1.p1.4.m4.1.1.3.3.cmml" xref="A1.p1.4.m4.1.1.3.3">𝑛</ci><ci id="A1.p1.4.m4.1.1.3.4.cmml" xref="A1.p1.4.m4.1.1.3.4">𝑐</ci><ci id="A1.p1.4.m4.1.1.3.5.cmml" xref="A1.p1.4.m4.1.1.3.5">ℎ</ci><ci id="A1.p1.4.m4.1.1.3.6.cmml" xref="A1.p1.4.m4.1.1.3.6">𝑜</ci><ci id="A1.p1.4.m4.1.1.3.7.cmml" xref="A1.p1.4.m4.1.1.3.7">𝑟</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.4.m4.1c">I^{p}_{anchor}</annotation><annotation encoding="application/x-llamapun" id="A1.p1.4.m4.1d">italic_I start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_a italic_n italic_c italic_h italic_o italic_r end_POSTSUBSCRIPT</annotation></semantics></math>, resulting in the aligned pose <math alttext="I^{p}_{realign}" class="ltx_Math" display="inline" id="A1.p1.5.m5.1"><semantics id="A1.p1.5.m5.1a"><msubsup id="A1.p1.5.m5.1.1" xref="A1.p1.5.m5.1.1.cmml"><mi id="A1.p1.5.m5.1.1.2.2" xref="A1.p1.5.m5.1.1.2.2.cmml">I</mi><mrow id="A1.p1.5.m5.1.1.3" xref="A1.p1.5.m5.1.1.3.cmml"><mi id="A1.p1.5.m5.1.1.3.2" xref="A1.p1.5.m5.1.1.3.2.cmml">r</mi><mo id="A1.p1.5.m5.1.1.3.1" xref="A1.p1.5.m5.1.1.3.1.cmml">⁢</mo><mi id="A1.p1.5.m5.1.1.3.3" xref="A1.p1.5.m5.1.1.3.3.cmml">e</mi><mo id="A1.p1.5.m5.1.1.3.1a" xref="A1.p1.5.m5.1.1.3.1.cmml">⁢</mo><mi id="A1.p1.5.m5.1.1.3.4" xref="A1.p1.5.m5.1.1.3.4.cmml">a</mi><mo id="A1.p1.5.m5.1.1.3.1b" xref="A1.p1.5.m5.1.1.3.1.cmml">⁢</mo><mi id="A1.p1.5.m5.1.1.3.5" xref="A1.p1.5.m5.1.1.3.5.cmml">l</mi><mo id="A1.p1.5.m5.1.1.3.1c" xref="A1.p1.5.m5.1.1.3.1.cmml">⁢</mo><mi id="A1.p1.5.m5.1.1.3.6" xref="A1.p1.5.m5.1.1.3.6.cmml">i</mi><mo id="A1.p1.5.m5.1.1.3.1d" xref="A1.p1.5.m5.1.1.3.1.cmml">⁢</mo><mi id="A1.p1.5.m5.1.1.3.7" xref="A1.p1.5.m5.1.1.3.7.cmml">g</mi><mo id="A1.p1.5.m5.1.1.3.1e" xref="A1.p1.5.m5.1.1.3.1.cmml">⁢</mo><mi id="A1.p1.5.m5.1.1.3.8" xref="A1.p1.5.m5.1.1.3.8.cmml">n</mi></mrow><mi id="A1.p1.5.m5.1.1.2.3" xref="A1.p1.5.m5.1.1.2.3.cmml">p</mi></msubsup><annotation-xml encoding="MathML-Content" id="A1.p1.5.m5.1b"><apply id="A1.p1.5.m5.1.1.cmml" xref="A1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="A1.p1.5.m5.1.1.1.cmml" xref="A1.p1.5.m5.1.1">subscript</csymbol><apply id="A1.p1.5.m5.1.1.2.cmml" xref="A1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="A1.p1.5.m5.1.1.2.1.cmml" xref="A1.p1.5.m5.1.1">superscript</csymbol><ci id="A1.p1.5.m5.1.1.2.2.cmml" xref="A1.p1.5.m5.1.1.2.2">𝐼</ci><ci id="A1.p1.5.m5.1.1.2.3.cmml" xref="A1.p1.5.m5.1.1.2.3">𝑝</ci></apply><apply id="A1.p1.5.m5.1.1.3.cmml" xref="A1.p1.5.m5.1.1.3"><times id="A1.p1.5.m5.1.1.3.1.cmml" xref="A1.p1.5.m5.1.1.3.1"></times><ci id="A1.p1.5.m5.1.1.3.2.cmml" xref="A1.p1.5.m5.1.1.3.2">𝑟</ci><ci id="A1.p1.5.m5.1.1.3.3.cmml" xref="A1.p1.5.m5.1.1.3.3">𝑒</ci><ci id="A1.p1.5.m5.1.1.3.4.cmml" xref="A1.p1.5.m5.1.1.3.4">𝑎</ci><ci id="A1.p1.5.m5.1.1.3.5.cmml" xref="A1.p1.5.m5.1.1.3.5">𝑙</ci><ci id="A1.p1.5.m5.1.1.3.6.cmml" xref="A1.p1.5.m5.1.1.3.6">𝑖</ci><ci id="A1.p1.5.m5.1.1.3.7.cmml" xref="A1.p1.5.m5.1.1.3.7">𝑔</ci><ci id="A1.p1.5.m5.1.1.3.8.cmml" xref="A1.p1.5.m5.1.1.3.8">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.5.m5.1c">I^{p}_{realign}</annotation><annotation encoding="application/x-llamapun" id="A1.p1.5.m5.1d">italic_I start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_r italic_e italic_a italic_l italic_i italic_g italic_n end_POSTSUBSCRIPT</annotation></semantics></math>. Next, we apply several rescaling operations randomly chosen from the rescale pool to further modify the aligned pose <math alttext="I^{p}_{realign}" class="ltx_Math" display="inline" id="A1.p1.6.m6.1"><semantics id="A1.p1.6.m6.1a"><msubsup id="A1.p1.6.m6.1.1" xref="A1.p1.6.m6.1.1.cmml"><mi id="A1.p1.6.m6.1.1.2.2" xref="A1.p1.6.m6.1.1.2.2.cmml">I</mi><mrow id="A1.p1.6.m6.1.1.3" xref="A1.p1.6.m6.1.1.3.cmml"><mi id="A1.p1.6.m6.1.1.3.2" xref="A1.p1.6.m6.1.1.3.2.cmml">r</mi><mo id="A1.p1.6.m6.1.1.3.1" xref="A1.p1.6.m6.1.1.3.1.cmml">⁢</mo><mi id="A1.p1.6.m6.1.1.3.3" xref="A1.p1.6.m6.1.1.3.3.cmml">e</mi><mo id="A1.p1.6.m6.1.1.3.1a" xref="A1.p1.6.m6.1.1.3.1.cmml">⁢</mo><mi id="A1.p1.6.m6.1.1.3.4" xref="A1.p1.6.m6.1.1.3.4.cmml">a</mi><mo id="A1.p1.6.m6.1.1.3.1b" xref="A1.p1.6.m6.1.1.3.1.cmml">⁢</mo><mi id="A1.p1.6.m6.1.1.3.5" xref="A1.p1.6.m6.1.1.3.5.cmml">l</mi><mo id="A1.p1.6.m6.1.1.3.1c" xref="A1.p1.6.m6.1.1.3.1.cmml">⁢</mo><mi id="A1.p1.6.m6.1.1.3.6" xref="A1.p1.6.m6.1.1.3.6.cmml">i</mi><mo id="A1.p1.6.m6.1.1.3.1d" xref="A1.p1.6.m6.1.1.3.1.cmml">⁢</mo><mi id="A1.p1.6.m6.1.1.3.7" xref="A1.p1.6.m6.1.1.3.7.cmml">g</mi><mo id="A1.p1.6.m6.1.1.3.1e" xref="A1.p1.6.m6.1.1.3.1.cmml">⁢</mo><mi id="A1.p1.6.m6.1.1.3.8" xref="A1.p1.6.m6.1.1.3.8.cmml">n</mi></mrow><mi id="A1.p1.6.m6.1.1.2.3" xref="A1.p1.6.m6.1.1.2.3.cmml">p</mi></msubsup><annotation-xml encoding="MathML-Content" id="A1.p1.6.m6.1b"><apply id="A1.p1.6.m6.1.1.cmml" xref="A1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="A1.p1.6.m6.1.1.1.cmml" xref="A1.p1.6.m6.1.1">subscript</csymbol><apply id="A1.p1.6.m6.1.1.2.cmml" xref="A1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="A1.p1.6.m6.1.1.2.1.cmml" xref="A1.p1.6.m6.1.1">superscript</csymbol><ci id="A1.p1.6.m6.1.1.2.2.cmml" xref="A1.p1.6.m6.1.1.2.2">𝐼</ci><ci id="A1.p1.6.m6.1.1.2.3.cmml" xref="A1.p1.6.m6.1.1.2.3">𝑝</ci></apply><apply id="A1.p1.6.m6.1.1.3.cmml" xref="A1.p1.6.m6.1.1.3"><times id="A1.p1.6.m6.1.1.3.1.cmml" xref="A1.p1.6.m6.1.1.3.1"></times><ci id="A1.p1.6.m6.1.1.3.2.cmml" xref="A1.p1.6.m6.1.1.3.2">𝑟</ci><ci id="A1.p1.6.m6.1.1.3.3.cmml" xref="A1.p1.6.m6.1.1.3.3">𝑒</ci><ci id="A1.p1.6.m6.1.1.3.4.cmml" xref="A1.p1.6.m6.1.1.3.4">𝑎</ci><ci id="A1.p1.6.m6.1.1.3.5.cmml" xref="A1.p1.6.m6.1.1.3.5">𝑙</ci><ci id="A1.p1.6.m6.1.1.3.6.cmml" xref="A1.p1.6.m6.1.1.3.6">𝑖</ci><ci id="A1.p1.6.m6.1.1.3.7.cmml" xref="A1.p1.6.m6.1.1.3.7">𝑔</ci><ci id="A1.p1.6.m6.1.1.3.8.cmml" xref="A1.p1.6.m6.1.1.3.8">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.6.m6.1c">I^{p}_{realign}</annotation><annotation encoding="application/x-llamapun" id="A1.p1.6.m6.1d">italic_I start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_r italic_e italic_a italic_l italic_i italic_g italic_n end_POSTSUBSCRIPT</annotation></semantics></math>. By combining different rescaling options, we can obtain multiple transformed poses <math alttext="I^{p}_{n}" class="ltx_Math" display="inline" id="A1.p1.7.m7.1"><semantics id="A1.p1.7.m7.1a"><msubsup id="A1.p1.7.m7.1.1" xref="A1.p1.7.m7.1.1.cmml"><mi id="A1.p1.7.m7.1.1.2.2" xref="A1.p1.7.m7.1.1.2.2.cmml">I</mi><mi id="A1.p1.7.m7.1.1.3" xref="A1.p1.7.m7.1.1.3.cmml">n</mi><mi id="A1.p1.7.m7.1.1.2.3" xref="A1.p1.7.m7.1.1.2.3.cmml">p</mi></msubsup><annotation-xml encoding="MathML-Content" id="A1.p1.7.m7.1b"><apply id="A1.p1.7.m7.1.1.cmml" xref="A1.p1.7.m7.1.1"><csymbol cd="ambiguous" id="A1.p1.7.m7.1.1.1.cmml" xref="A1.p1.7.m7.1.1">subscript</csymbol><apply id="A1.p1.7.m7.1.1.2.cmml" xref="A1.p1.7.m7.1.1"><csymbol cd="ambiguous" id="A1.p1.7.m7.1.1.2.1.cmml" xref="A1.p1.7.m7.1.1">superscript</csymbol><ci id="A1.p1.7.m7.1.1.2.2.cmml" xref="A1.p1.7.m7.1.1.2.2">𝐼</ci><ci id="A1.p1.7.m7.1.1.2.3.cmml" xref="A1.p1.7.m7.1.1.2.3">𝑝</ci></apply><ci id="A1.p1.7.m7.1.1.3.cmml" xref="A1.p1.7.m7.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.7.m7.1c">I^{p}_{n}</annotation><annotation encoding="application/x-llamapun" id="A1.p1.7.m7.1d">italic_I start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT</annotation></semantics></math>. However, it is important to note that in each training step, only one anchor pose <math alttext="I^{p}_{anchor}" class="ltx_Math" display="inline" id="A1.p1.8.m8.1"><semantics id="A1.p1.8.m8.1a"><msubsup id="A1.p1.8.m8.1.1" xref="A1.p1.8.m8.1.1.cmml"><mi id="A1.p1.8.m8.1.1.2.2" xref="A1.p1.8.m8.1.1.2.2.cmml">I</mi><mrow id="A1.p1.8.m8.1.1.3" xref="A1.p1.8.m8.1.1.3.cmml"><mi id="A1.p1.8.m8.1.1.3.2" xref="A1.p1.8.m8.1.1.3.2.cmml">a</mi><mo id="A1.p1.8.m8.1.1.3.1" xref="A1.p1.8.m8.1.1.3.1.cmml">⁢</mo><mi id="A1.p1.8.m8.1.1.3.3" xref="A1.p1.8.m8.1.1.3.3.cmml">n</mi><mo id="A1.p1.8.m8.1.1.3.1a" xref="A1.p1.8.m8.1.1.3.1.cmml">⁢</mo><mi id="A1.p1.8.m8.1.1.3.4" xref="A1.p1.8.m8.1.1.3.4.cmml">c</mi><mo id="A1.p1.8.m8.1.1.3.1b" xref="A1.p1.8.m8.1.1.3.1.cmml">⁢</mo><mi id="A1.p1.8.m8.1.1.3.5" xref="A1.p1.8.m8.1.1.3.5.cmml">h</mi><mo id="A1.p1.8.m8.1.1.3.1c" xref="A1.p1.8.m8.1.1.3.1.cmml">⁢</mo><mi id="A1.p1.8.m8.1.1.3.6" xref="A1.p1.8.m8.1.1.3.6.cmml">o</mi><mo id="A1.p1.8.m8.1.1.3.1d" xref="A1.p1.8.m8.1.1.3.1.cmml">⁢</mo><mi id="A1.p1.8.m8.1.1.3.7" xref="A1.p1.8.m8.1.1.3.7.cmml">r</mi></mrow><mi id="A1.p1.8.m8.1.1.2.3" xref="A1.p1.8.m8.1.1.2.3.cmml">p</mi></msubsup><annotation-xml encoding="MathML-Content" id="A1.p1.8.m8.1b"><apply id="A1.p1.8.m8.1.1.cmml" xref="A1.p1.8.m8.1.1"><csymbol cd="ambiguous" id="A1.p1.8.m8.1.1.1.cmml" xref="A1.p1.8.m8.1.1">subscript</csymbol><apply id="A1.p1.8.m8.1.1.2.cmml" xref="A1.p1.8.m8.1.1"><csymbol cd="ambiguous" id="A1.p1.8.m8.1.1.2.1.cmml" xref="A1.p1.8.m8.1.1">superscript</csymbol><ci id="A1.p1.8.m8.1.1.2.2.cmml" xref="A1.p1.8.m8.1.1.2.2">𝐼</ci><ci id="A1.p1.8.m8.1.1.2.3.cmml" xref="A1.p1.8.m8.1.1.2.3">𝑝</ci></apply><apply id="A1.p1.8.m8.1.1.3.cmml" xref="A1.p1.8.m8.1.1.3"><times id="A1.p1.8.m8.1.1.3.1.cmml" xref="A1.p1.8.m8.1.1.3.1"></times><ci id="A1.p1.8.m8.1.1.3.2.cmml" xref="A1.p1.8.m8.1.1.3.2">𝑎</ci><ci id="A1.p1.8.m8.1.1.3.3.cmml" xref="A1.p1.8.m8.1.1.3.3">𝑛</ci><ci id="A1.p1.8.m8.1.1.3.4.cmml" xref="A1.p1.8.m8.1.1.3.4">𝑐</ci><ci id="A1.p1.8.m8.1.1.3.5.cmml" xref="A1.p1.8.m8.1.1.3.5">ℎ</ci><ci id="A1.p1.8.m8.1.1.3.6.cmml" xref="A1.p1.8.m8.1.1.3.6">𝑜</ci><ci id="A1.p1.8.m8.1.1.3.7.cmml" xref="A1.p1.8.m8.1.1.3.7">𝑟</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.8.m8.1c">I^{p}_{anchor}</annotation><annotation encoding="application/x-llamapun" id="A1.p1.8.m8.1d">italic_I start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_a italic_n italic_c italic_h italic_o italic_r end_POSTSUBSCRIPT</annotation></semantics></math> and one rescaling combination are selected, so only one transformed pose <math alttext="I^{p}_{n}" class="ltx_Math" display="inline" id="A1.p1.9.m9.1"><semantics id="A1.p1.9.m9.1a"><msubsup id="A1.p1.9.m9.1.1" xref="A1.p1.9.m9.1.1.cmml"><mi id="A1.p1.9.m9.1.1.2.2" xref="A1.p1.9.m9.1.1.2.2.cmml">I</mi><mi id="A1.p1.9.m9.1.1.3" xref="A1.p1.9.m9.1.1.3.cmml">n</mi><mi id="A1.p1.9.m9.1.1.2.3" xref="A1.p1.9.m9.1.1.2.3.cmml">p</mi></msubsup><annotation-xml encoding="MathML-Content" id="A1.p1.9.m9.1b"><apply id="A1.p1.9.m9.1.1.cmml" xref="A1.p1.9.m9.1.1"><csymbol cd="ambiguous" id="A1.p1.9.m9.1.1.1.cmml" xref="A1.p1.9.m9.1.1">subscript</csymbol><apply id="A1.p1.9.m9.1.1.2.cmml" xref="A1.p1.9.m9.1.1"><csymbol cd="ambiguous" id="A1.p1.9.m9.1.1.2.1.cmml" xref="A1.p1.9.m9.1.1">superscript</csymbol><ci id="A1.p1.9.m9.1.1.2.2.cmml" xref="A1.p1.9.m9.1.1.2.2">𝐼</ci><ci id="A1.p1.9.m9.1.1.2.3.cmml" xref="A1.p1.9.m9.1.1.2.3">𝑝</ci></apply><ci id="A1.p1.9.m9.1.1.3.cmml" xref="A1.p1.9.m9.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.9.m9.1c">I^{p}_{n}</annotation><annotation encoding="application/x-llamapun" id="A1.p1.9.m9.1d">italic_I start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT</annotation></semantics></math> is used for training. As shown in the Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#A1.F8" title="Figure 8 ‣ Appendix A Network Details ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">8</span></a>, the transformed pose <math alttext="I^{p}_{n}" class="ltx_Math" display="inline" id="A1.p1.10.m10.1"><semantics id="A1.p1.10.m10.1a"><msubsup id="A1.p1.10.m10.1.1" xref="A1.p1.10.m10.1.1.cmml"><mi id="A1.p1.10.m10.1.1.2.2" xref="A1.p1.10.m10.1.1.2.2.cmml">I</mi><mi id="A1.p1.10.m10.1.1.3" xref="A1.p1.10.m10.1.1.3.cmml">n</mi><mi id="A1.p1.10.m10.1.1.2.3" xref="A1.p1.10.m10.1.1.2.3.cmml">p</mi></msubsup><annotation-xml encoding="MathML-Content" id="A1.p1.10.m10.1b"><apply id="A1.p1.10.m10.1.1.cmml" xref="A1.p1.10.m10.1.1"><csymbol cd="ambiguous" id="A1.p1.10.m10.1.1.1.cmml" xref="A1.p1.10.m10.1.1">subscript</csymbol><apply id="A1.p1.10.m10.1.1.2.cmml" xref="A1.p1.10.m10.1.1"><csymbol cd="ambiguous" id="A1.p1.10.m10.1.1.2.1.cmml" xref="A1.p1.10.m10.1.1">superscript</csymbol><ci id="A1.p1.10.m10.1.1.2.2.cmml" xref="A1.p1.10.m10.1.1.2.2">𝐼</ci><ci id="A1.p1.10.m10.1.1.2.3.cmml" xref="A1.p1.10.m10.1.1.2.3">𝑝</ci></apply><ci id="A1.p1.10.m10.1.1.3.cmml" xref="A1.p1.10.m10.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.10.m10.1c">I^{p}_{n}</annotation><annotation encoding="application/x-llamapun" id="A1.p1.10.m10.1d">italic_I start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT</annotation></semantics></math> retains the same motion as the sampled pose <math alttext="I^{p}" class="ltx_Math" display="inline" id="A1.p1.11.m11.1"><semantics id="A1.p1.11.m11.1a"><msup id="A1.p1.11.m11.1.1" xref="A1.p1.11.m11.1.1.cmml"><mi id="A1.p1.11.m11.1.1.2" xref="A1.p1.11.m11.1.1.2.cmml">I</mi><mi id="A1.p1.11.m11.1.1.3" xref="A1.p1.11.m11.1.1.3.cmml">p</mi></msup><annotation-xml encoding="MathML-Content" id="A1.p1.11.m11.1b"><apply id="A1.p1.11.m11.1.1.cmml" xref="A1.p1.11.m11.1.1"><csymbol cd="ambiguous" id="A1.p1.11.m11.1.1.1.cmml" xref="A1.p1.11.m11.1.1">superscript</csymbol><ci id="A1.p1.11.m11.1.1.2.cmml" xref="A1.p1.11.m11.1.1.2">𝐼</ci><ci id="A1.p1.11.m11.1.1.3.cmml" xref="A1.p1.11.m11.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.11.m11.1c">I^{p}</annotation><annotation encoding="application/x-llamapun" id="A1.p1.11.m11.1d">italic_I start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT</annotation></semantics></math> but has a body shape similar to the anchor pose <math alttext="I^{p}_{anchor}" class="ltx_Math" display="inline" id="A1.p1.12.m12.1"><semantics id="A1.p1.12.m12.1a"><msubsup id="A1.p1.12.m12.1.1" xref="A1.p1.12.m12.1.1.cmml"><mi id="A1.p1.12.m12.1.1.2.2" xref="A1.p1.12.m12.1.1.2.2.cmml">I</mi><mrow id="A1.p1.12.m12.1.1.3" xref="A1.p1.12.m12.1.1.3.cmml"><mi id="A1.p1.12.m12.1.1.3.2" xref="A1.p1.12.m12.1.1.3.2.cmml">a</mi><mo id="A1.p1.12.m12.1.1.3.1" xref="A1.p1.12.m12.1.1.3.1.cmml">⁢</mo><mi id="A1.p1.12.m12.1.1.3.3" xref="A1.p1.12.m12.1.1.3.3.cmml">n</mi><mo id="A1.p1.12.m12.1.1.3.1a" xref="A1.p1.12.m12.1.1.3.1.cmml">⁢</mo><mi id="A1.p1.12.m12.1.1.3.4" xref="A1.p1.12.m12.1.1.3.4.cmml">c</mi><mo id="A1.p1.12.m12.1.1.3.1b" xref="A1.p1.12.m12.1.1.3.1.cmml">⁢</mo><mi id="A1.p1.12.m12.1.1.3.5" xref="A1.p1.12.m12.1.1.3.5.cmml">h</mi><mo id="A1.p1.12.m12.1.1.3.1c" xref="A1.p1.12.m12.1.1.3.1.cmml">⁢</mo><mi id="A1.p1.12.m12.1.1.3.6" xref="A1.p1.12.m12.1.1.3.6.cmml">o</mi><mo id="A1.p1.12.m12.1.1.3.1d" xref="A1.p1.12.m12.1.1.3.1.cmml">⁢</mo><mi id="A1.p1.12.m12.1.1.3.7" xref="A1.p1.12.m12.1.1.3.7.cmml">r</mi></mrow><mi id="A1.p1.12.m12.1.1.2.3" xref="A1.p1.12.m12.1.1.2.3.cmml">p</mi></msubsup><annotation-xml encoding="MathML-Content" id="A1.p1.12.m12.1b"><apply id="A1.p1.12.m12.1.1.cmml" xref="A1.p1.12.m12.1.1"><csymbol cd="ambiguous" id="A1.p1.12.m12.1.1.1.cmml" xref="A1.p1.12.m12.1.1">subscript</csymbol><apply id="A1.p1.12.m12.1.1.2.cmml" xref="A1.p1.12.m12.1.1"><csymbol cd="ambiguous" id="A1.p1.12.m12.1.1.2.1.cmml" xref="A1.p1.12.m12.1.1">superscript</csymbol><ci id="A1.p1.12.m12.1.1.2.2.cmml" xref="A1.p1.12.m12.1.1.2.2">𝐼</ci><ci id="A1.p1.12.m12.1.1.2.3.cmml" xref="A1.p1.12.m12.1.1.2.3">𝑝</ci></apply><apply id="A1.p1.12.m12.1.1.3.cmml" xref="A1.p1.12.m12.1.1.3"><times id="A1.p1.12.m12.1.1.3.1.cmml" xref="A1.p1.12.m12.1.1.3.1"></times><ci id="A1.p1.12.m12.1.1.3.2.cmml" xref="A1.p1.12.m12.1.1.3.2">𝑎</ci><ci id="A1.p1.12.m12.1.1.3.3.cmml" xref="A1.p1.12.m12.1.1.3.3">𝑛</ci><ci id="A1.p1.12.m12.1.1.3.4.cmml" xref="A1.p1.12.m12.1.1.3.4">𝑐</ci><ci id="A1.p1.12.m12.1.1.3.5.cmml" xref="A1.p1.12.m12.1.1.3.5">ℎ</ci><ci id="A1.p1.12.m12.1.1.3.6.cmml" xref="A1.p1.12.m12.1.1.3.6">𝑜</ci><ci id="A1.p1.12.m12.1.1.3.7.cmml" xref="A1.p1.12.m12.1.1.3.7">𝑟</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.12.m12.1c">I^{p}_{anchor}</annotation><annotation encoding="application/x-llamapun" id="A1.p1.12.m12.1d">italic_I start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_a italic_n italic_c italic_h italic_o italic_r end_POSTSUBSCRIPT</annotation></semantics></math>. This simulates scenarios during inference where there are body shape differences between the reference image and the driving pose, enabling the model to generalize to such cases.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="A1.F8"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="515" id="A1.F8.g1" src="./animate-x_files/x7.png" width="789">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>More example for EPI.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="A1.F9"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="458" id="A1.F9.g1" src="./animate-x_files/x8.png" width="789">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>The difference of training and inference pipeline. During training, the reference image and the driven video come from the same video, while in the inference pipeline, the reference image and the driven video can be from any sources and appreciably different.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A1.p2">
<p class="ltx_p" id="A1.p2.1">In the experiments, we use the visual encoder of the multi-modal CLIP-Huge model&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Radford et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib36" title="">2021</a>)</cite> in Stable Diffusion v2.1&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Rombach et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib39" title="">2022</a>)</cite> to encode the CLIP embedding of the reference image and driving videos. The pose encoder, composed of several convolutional layers, follows a similar structure to the STC-encoder in VideoComposer&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Wang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib60" title="">2023c</a>)</cite>. For model initialization, we employ a pre-trained video generation model&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Wang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib62" title="">2024c</a>)</cite>, as done in previous approaches&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Xu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib68" title="">2023a</a>); Hu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib21" title="">2023</a>); Zhu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib86" title="">2024</a>); Wang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib61" title="">2024b</a>)</cite>. The experiments are carried out using 8 NVIDIA A100 GPUs. During training, videos are resized to a spatial resolution of 768×512 pixels, and we feed the model with uniformly sampled video segments of 32 frames to ensure temporal consistency. We use the AdamW optimizer&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Loshchilov &amp; Hutter (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib30" title="">2017</a>)</cite> with learning rates of 5e-7 for the implicit pose indicator and 5e-5 for other modules. For noise sampling, DDPM&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Ho et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib18" title="">2020</a>)</cite> with 1000 steps is applied during training. In the inference phase, we adjust the length of the driving pose to align roughly with the reference pose and used the DDIM sampler&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Song et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib47" title="">2021</a>)</cite> with 50 steps for faster sampling.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="A1.F10"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="1094" id="A1.F10.g1" src="./animate-x_files/x9.png" width="789">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>Detailed pipeline for building <math alttext="A^{2}" class="ltx_Math" display="inline" id="A1.F10.2.m1.1"><semantics id="A1.F10.2.m1.1b"><msup id="A1.F10.2.m1.1.1" xref="A1.F10.2.m1.1.1.cmml"><mi id="A1.F10.2.m1.1.1.2" xref="A1.F10.2.m1.1.1.2.cmml">A</mi><mn id="A1.F10.2.m1.1.1.3" xref="A1.F10.2.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="A1.F10.2.m1.1c"><apply id="A1.F10.2.m1.1.1.cmml" xref="A1.F10.2.m1.1.1"><csymbol cd="ambiguous" id="A1.F10.2.m1.1.1.1.cmml" xref="A1.F10.2.m1.1.1">superscript</csymbol><ci id="A1.F10.2.m1.1.1.2.cmml" xref="A1.F10.2.m1.1.1.2">𝐴</ci><cn id="A1.F10.2.m1.1.1.3.cmml" type="integer" xref="A1.F10.2.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.F10.2.m1.1d">A^{2}</annotation><annotation encoding="application/x-llamapun" id="A1.F10.2.m1.1e">italic_A start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_typewriter" id="A1.F10.4.1">Bench</span> based on large-scale pretrained models, including Open-ChatGPT 4o and KLing AI.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Benchmark Details</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="A2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.1 </span>Evaluation Metric</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A2.SS1.p1">
<p class="ltx_p" id="A2.SS1.p1.1">We employ several evaluation metrics to quantitatively assess our results, including PSNR, SSIM, L1, LPIPS, FID, FID-VID and FVD. The detailed metrics are introduced as follows:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A2.SS1.p2">
<ul class="ltx_itemize" id="A2.I1">
<li class="ltx_item" id="A2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I1.i1.p1">
<p class="ltx_p" id="A2.I1.i1.p1.1">PSNR is a measure used to evaluate the quality of reconstructed images compared to the original ones. It is expressed in decibels (dB) and higher values indicate better quality. PSNR is commonly used in image compression and restoration fields.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A2.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I1.i2.p1">
<p class="ltx_p" id="A2.I1.i2.p1.1">SSIM assesses the similarity between two images based on their luminance, contrast, and structural information. It considers perceptual phenomena affecting human vision and thus provides a better correlation with perceived image quality than PSNR.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A2.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I1.i3.p1">
<p class="ltx_p" id="A2.I1.i3.p1.1">The L1 metric refers to the mean absolute difference between the corresponding pixel values of two images. It quantifies the average magnitude of errors in predictions without considering their direction, making it useful for measuring the extent of differences.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A2.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I1.i4.p1">
<p class="ltx_p" id="A2.I1.i4.p1.1">LPIPS is a perceptual distance metric based on deep learning. It evaluates the similarity between images by analyzing the feature representations of image patches and tends to align well with human visual perception, making it suitable for tasks like image generation.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A2.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I1.i5.p1">
<p class="ltx_p" id="A2.I1.i5.p1.1">FID is used to assess the quality of images generated by generative models (like GANs) by comparing the distribution of generated images to that of real images in feature space (extracted by a pretrained CNN). Lower FID values suggest that the generated images are more similar to real images.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A2.I1.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I1.i6.p1">
<p class="ltx_p" id="A2.I1.i6.p1.1">FID-VID extends the FID metric to video data. It measures the quality of generated videos by comparing the distribution of generated video features to real video features, providing insights into the temporal aspects of video generation.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A2.I1.i7" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="A2.I1.i7.p1">
<p class="ltx_p" id="A2.I1.i7.p1.1">FVD is another metric for evaluating video generation, similar to FID. It measures the distance between the feature distributions of real and generated videos, taking both spatial and temporal dimensions into account. Lower FVD indicates that generated videos are closer to real ones regarding visual quality and dynamics.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_subsection" id="A2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.2 </span>Data Details</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A2.SS2.p1">
<p class="ltx_p" id="A2.SS2.p1.2">The detailed process for constructing <math alttext="A^{2}" class="ltx_Math" display="inline" id="A2.SS2.p1.1.m1.1"><semantics id="A2.SS2.p1.1.m1.1a"><msup id="A2.SS2.p1.1.m1.1.1" xref="A2.SS2.p1.1.m1.1.1.cmml"><mi id="A2.SS2.p1.1.m1.1.1.2" xref="A2.SS2.p1.1.m1.1.1.2.cmml">A</mi><mn id="A2.SS2.p1.1.m1.1.1.3" xref="A2.SS2.p1.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="A2.SS2.p1.1.m1.1b"><apply id="A2.SS2.p1.1.m1.1.1.cmml" xref="A2.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A2.SS2.p1.1.m1.1.1.1.cmml" xref="A2.SS2.p1.1.m1.1.1">superscript</csymbol><ci id="A2.SS2.p1.1.m1.1.1.2.cmml" xref="A2.SS2.p1.1.m1.1.1.2">𝐴</ci><cn id="A2.SS2.p1.1.m1.1.1.3.cmml" type="integer" xref="A2.SS2.p1.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS2.p1.1.m1.1c">A^{2}</annotation><annotation encoding="application/x-llamapun" id="A2.SS2.p1.1.m1.1d">italic_A start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_typewriter" id="A2.SS2.p1.2.1">Bench</span> is outlined in Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#A1.F10" title="Figure 10 ‣ Appendix A Network Details ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">10</span></a>. We initially provide GPT-4o with a template that clearly specifies the demand to generate ‘anthropomorphized’ images. The images were required to be cute, with arms and legs, standing, dancing, and of high quality. To allow for a variety of image outputs, we left the fields for ‘object’, ‘season’, ‘province’, and ‘specific location’ empty. For the key factor influencing diversity and relevance, i.e., ‘object’, we provide a selectable range, such as everyday items, furniture, fruits, and natural creatures. To help GPT-4o better understand our intent, we additionally provide two examples, where the prompts had already been proven to generate satisfactory images by text-to-image module of KLing AI. Thanks to the text understanding and generation capabilities of GPT-4o, we collect 500 prompts for image generation. We then fed these 500 prompts into the text-to-image module of Keling AI, obtaining corresponding anthropomorphic characters images. Based on these images, we further generate videos of them dancing using the image-to-video module of Keling AI. In this way, we collect 500 pairs of images and videos of anthropomorphic characters, forming our <math alttext="A^{2}" class="ltx_Math" display="inline" id="A2.SS2.p1.2.m2.1"><semantics id="A2.SS2.p1.2.m2.1a"><msup id="A2.SS2.p1.2.m2.1.1" xref="A2.SS2.p1.2.m2.1.1.cmml"><mi id="A2.SS2.p1.2.m2.1.1.2" xref="A2.SS2.p1.2.m2.1.1.2.cmml">A</mi><mn id="A2.SS2.p1.2.m2.1.1.3" xref="A2.SS2.p1.2.m2.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="A2.SS2.p1.2.m2.1b"><apply id="A2.SS2.p1.2.m2.1.1.cmml" xref="A2.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="A2.SS2.p1.2.m2.1.1.1.cmml" xref="A2.SS2.p1.2.m2.1.1">superscript</csymbol><ci id="A2.SS2.p1.2.m2.1.1.2.cmml" xref="A2.SS2.p1.2.m2.1.1.2">𝐴</ci><cn id="A2.SS2.p1.2.m2.1.1.3.cmml" type="integer" xref="A2.SS2.p1.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS2.p1.2.m2.1c">A^{2}</annotation><annotation encoding="application/x-llamapun" id="A2.SS2.p1.2.m2.1d">italic_A start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_typewriter" id="A2.SS2.p1.2.2">Bench</span>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A2.SS2.p2">
<p class="ltx_p" id="A2.SS2.p2.1">Since most current animation methods&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Wang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib61" title="">2024b</a>); Hu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib21" title="">2023</a>); Zhang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib82" title="">2024</a>)</cite> take a pose image sequence as motion source, we also provide our <math alttext="A^{2}" class="ltx_Math" display="inline" id="A2.SS2.p2.1.m1.1"><semantics id="A2.SS2.p2.1.m1.1a"><msup id="A2.SS2.p2.1.m1.1.1" xref="A2.SS2.p2.1.m1.1.1.cmml"><mi id="A2.SS2.p2.1.m1.1.1.2" xref="A2.SS2.p2.1.m1.1.1.2.cmml">A</mi><mn id="A2.SS2.p2.1.m1.1.1.3" xref="A2.SS2.p2.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="A2.SS2.p2.1.m1.1b"><apply id="A2.SS2.p2.1.m1.1.1.cmml" xref="A2.SS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="A2.SS2.p2.1.m1.1.1.1.cmml" xref="A2.SS2.p2.1.m1.1.1">superscript</csymbol><ci id="A2.SS2.p2.1.m1.1.1.2.cmml" xref="A2.SS2.p2.1.m1.1.1.2">𝐴</ci><cn id="A2.SS2.p2.1.m1.1.1.3.cmml" type="integer" xref="A2.SS2.p2.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS2.p2.1.m1.1c">A^{2}</annotation><annotation encoding="application/x-llamapun" id="A2.SS2.p2.1.m1.1d">italic_A start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_typewriter" id="A2.SS2.p2.1.1">Bench</span> with additional pose images. To achieve this, we employ DWPose&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Yang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib71" title="">2023</a>)</cite> to extract pose sequences from the videos. However, since DWPose is trained on human data, it does not accurately extract every pose in the dancing video of the anthropomorphic character, so after extraction, we manually screen 100 videos with accurate poses, and view them as test videos for calculating quantitative metrics. Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#S3.F3" title="Figure 3 ‣ 3.3 Framework and Implement Details ‣ 3 Method ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">3</span></a> displays several examples, which include anthropomorphic characters of plants, animals, food, furniture, etc. For images and videos where pose extraction is not feasible, we take them as key sources of reference images in our qualitative demonstrations. This will inspire the community to animate a wider range of interesting cases. We also anticipate that these data could serve as an important resource for future pose extraction algorithms tailored to anthropomorphic datasets, making them accessible for broader use.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_appendix" id="A3">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>User Study</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="A3.F11"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="1011" id="A3.F11.g1" src="./animate-x_files/x10.png" width="789">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 11: </span>Visualization of cases in the user study</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A3.p1">
<p class="ltx_p" id="A3.p1.1">In Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#A3.F11" title="Figure 11 ‣ Appendix C User Study ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">11</span></a>, we present examples shown to participants for evaluation in our user study. To obtain genuine feedback reflective of practical applications, the ten participants in our user study experiment come from diverse academic backgrounds. Since many of them do not major in computer vision, we provide detailed explanations for each question to assist their judgments.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_itemize" id="A3.I1">
<li class="ltx_item" id="A3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I1.i1.p1">
<p class="ltx_p" id="A3.I1.i1.p1.1">Identity Preservation: By comparing the reference image with the two generated videos by different methods, determine which video’s character more closely resembles the character in the image.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I1.i2.p1">
<p class="ltx_p" id="A3.I1.i2.p1.1">Temporal Consistency: Evaluate the motion changes of the character within the video and compare which video exhibits more coherent movement.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="A3.I1.i3.p1">
<p class="ltx_p" id="A3.I1.i3.p1.1">Visual Quality: Compared to the previous two questions, this one involves more subjective judgment. Participants should assess the videos comprehensively based on visual content (e.g., flashes, distortions, afterimages), motion effects (e.g., smoothness, physical logic), and overall plausibility.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_appendix" id="A4">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Additional Experimental Results</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="A4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">D.1 </span>More qualitative results</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A4.SS1.p1">
<p class="ltx_p" id="A4.SS1.p1.1">In the main paper, we present qualitative comparison results between our method and the state-of-the-art (SOTA) methods under a cross-driven setting on a human-like character, where our approach demonstrates outstanding performance. Considering that the other methods are primarily self-driven and trained on human characters, making them more suitable for inference in such settings, we additionally provide comparison results under a self-reconstruction setting on Tiktok and Abench. As shown in Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#A4.F14" title="Figure 14 ‣ D.4 More ablation study ‣ Appendix D Additional Experimental Results ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">14</span></a>, when there is a appreciably difference between the reference pose and the reference image, the GAN-based LIA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Wang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib63" title="">2022</a>)</cite> produces noticeable artifacts. Thanks to the powerful generative capabilities of diffusion models, diffusion-based models generate higher-quality results. However, MusePose&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Tong et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib54" title="">2024</a>)</cite> and MimicMotion&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Zhang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib82" title="">2024</a>)</cite> generate awkward arms and blurry hands, respectively, while ControlNeXt&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Peng et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib34" title="">2024</a>)</cite> synthesizes incorrect movements. Only Unianimate&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Wang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib61" title="">2024b</a>)</cite> can obtain results comparable to ours. Yet, when the reference image is a non-human character, even in a self-driven setting with the same training strategy as Unianimate, their results still show distorted heads. Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#A4.F15" title="Figure 15 ‣ D.4 More ablation study ‣ Appendix D Additional Experimental Results ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">15</span></a> provides results of more comparison results, including MRAA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Siarohin et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib44" title="">2021a</a>)</cite>, MagicAnimate&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Xu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib68" title="">2023a</a>)</cite> and Moore-AnimateAnyone&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Corporation (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib11" title="">2024</a>)</cite>. In contrast, our method consistently generates satisfactory results for both human and anthropomorphic characters, demonstrating its ability to drive <span class="ltx_text ltx_markedasmath ltx_font_typewriter" id="A4.SS1.p1.1.1">X</span> character and highlighting its strong generalization and robustness.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="A4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">D.2 </span>More quantitative results</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A4.SS2.p1">
<p class="ltx_p" id="A4.SS2.p1.1">Tab.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#A4.T7" title="Table 7 ‣ D.4 More ablation study ‣ Appendix D Additional Experimental Results ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">7</span></a> and Tab.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#A4.T8" title="Table 8 ‣ D.4 More ablation study ‣ Appendix D Additional Experimental Results ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">8</span></a> presents the quantitative results on TikTok&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Jafarian &amp; Park (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib24" title="">2021</a>)</cite> and Fashion&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Zablotskaia et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib75" title="">2019a</a>)</cite> dataset, which suggests the superiority of methods over the comparison SOTA methods. Only Unianimate achieves comparable performance; however, our method is applicable to a wider range of characters and various unaligned pose inputs, as demonstrated in Tab.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#S3.T1" title="Table 1 ‣ 3.4 𝐴²Bench ‣ 3 Method ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">1</span></a>. This addresses the main issue that this paper aims to solve: developing a universal character image animation model.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="A4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">D.3 </span>Robustness</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="A4.F12"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="1026" id="A4.F12.g1" src="./animate-x_files/x11.png" width="789">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 12: </span>Visualization of the robustness of <span class="ltx_text ltx_font_typewriter" id="A4.F12.2.1">Animate-X</span>.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A4.SS3.p1">
<p class="ltx_p" id="A4.SS3.p1.1">Our method demonstrates robustness to both input <span class="ltx_text ltx_font_typewriter" id="A4.SS3.p1.1.1">X</span> character and pose variations. On the one hand, as shown in Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#S0.F1" title="Figure 1 ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">1</span></a>, our approach successfully handles inputs from diverse subjects, including characters vastly different from humans, such as those without limbs, as well as game characters or those generated by other models. Despite these variations, our method consistently produces satisfactory results without crashing, showcasing its robustness to the input reference images. On the other hand, as illustrated in Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#A4.F12" title="Figure 12 ‣ D.3 Robustness ‣ Appendix D Additional Experimental Results ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">12</span></a>, even when the pose images exhibit body part omissions (highlighted by the red circles), our method correctly interprets the intended motion and generates coherent results for the reference images. This highlights the robustness of our approach to different pose images.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="A4.T5">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A4.T5.7" style="width:433.6pt;height:259.5pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-9.6pt,5.7pt) scale(0.957569591781143,0.957569591781143) ;">
<table class="ltx_tabular ltx_align_middle" id="A4.T5.7.7">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A4.T5.7.7.7">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A4.T5.7.7.7.8" style="padding:0.75pt 8.0pt;">Method</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T5.1.1.1.1" style="padding:0.75pt 8.0pt;">PSNR* <math alttext="\uparrow" class="ltx_Math" display="inline" id="A4.T5.1.1.1.1.m1.1"><semantics id="A4.T5.1.1.1.1.m1.1a"><mo id="A4.T5.1.1.1.1.m1.1.1" stretchy="false" xref="A4.T5.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A4.T5.1.1.1.1.m1.1b"><ci id="A4.T5.1.1.1.1.m1.1.1.cmml" xref="A4.T5.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T5.1.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A4.T5.1.1.1.1.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T5.2.2.2.2" style="padding:0.75pt 8.0pt;">SSIM <math alttext="\uparrow" class="ltx_Math" display="inline" id="A4.T5.2.2.2.2.m1.1"><semantics id="A4.T5.2.2.2.2.m1.1a"><mo id="A4.T5.2.2.2.2.m1.1.1" stretchy="false" xref="A4.T5.2.2.2.2.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A4.T5.2.2.2.2.m1.1b"><ci id="A4.T5.2.2.2.2.m1.1.1.cmml" xref="A4.T5.2.2.2.2.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T5.2.2.2.2.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A4.T5.2.2.2.2.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T5.3.3.3.3" style="padding:0.75pt 8.0pt;">L1 <math alttext="\uparrow" class="ltx_Math" display="inline" id="A4.T5.3.3.3.3.m1.1"><semantics id="A4.T5.3.3.3.3.m1.1a"><mo id="A4.T5.3.3.3.3.m1.1.1" stretchy="false" xref="A4.T5.3.3.3.3.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A4.T5.3.3.3.3.m1.1b"><ci id="A4.T5.3.3.3.3.m1.1.1.cmml" xref="A4.T5.3.3.3.3.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T5.3.3.3.3.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A4.T5.3.3.3.3.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T5.4.4.4.4" style="padding:0.75pt 8.0pt;">LPIPS <math alttext="\downarrow" class="ltx_Math" display="inline" id="A4.T5.4.4.4.4.m1.1"><semantics id="A4.T5.4.4.4.4.m1.1a"><mo id="A4.T5.4.4.4.4.m1.1.1" stretchy="false" xref="A4.T5.4.4.4.4.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A4.T5.4.4.4.4.m1.1b"><ci id="A4.T5.4.4.4.4.m1.1.1.cmml" xref="A4.T5.4.4.4.4.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T5.4.4.4.4.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="A4.T5.4.4.4.4.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A4.T5.5.5.5.5" style="padding:0.75pt 8.0pt;">FID <math alttext="\downarrow" class="ltx_Math" display="inline" id="A4.T5.5.5.5.5.m1.1"><semantics id="A4.T5.5.5.5.5.m1.1a"><mo id="A4.T5.5.5.5.5.m1.1.1" stretchy="false" xref="A4.T5.5.5.5.5.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A4.T5.5.5.5.5.m1.1b"><ci id="A4.T5.5.5.5.5.m1.1.1.cmml" xref="A4.T5.5.5.5.5.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T5.5.5.5.5.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="A4.T5.5.5.5.5.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T5.6.6.6.6" style="padding:0.75pt 8.0pt;">FID-VID <math alttext="\downarrow" class="ltx_Math" display="inline" id="A4.T5.6.6.6.6.m1.1"><semantics id="A4.T5.6.6.6.6.m1.1a"><mo id="A4.T5.6.6.6.6.m1.1.1" stretchy="false" xref="A4.T5.6.6.6.6.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A4.T5.6.6.6.6.m1.1b"><ci id="A4.T5.6.6.6.6.m1.1.1.cmml" xref="A4.T5.6.6.6.6.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T5.6.6.6.6.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="A4.T5.6.6.6.6.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T5.7.7.7.7" style="padding:0.75pt 8.0pt;">FVD <math alttext="\downarrow" class="ltx_Math" display="inline" id="A4.T5.7.7.7.7.m1.1"><semantics id="A4.T5.7.7.7.7.m1.1a"><mo id="A4.T5.7.7.7.7.m1.1.1" stretchy="false" xref="A4.T5.7.7.7.7.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A4.T5.7.7.7.7.m1.1b"><ci id="A4.T5.7.7.7.7.m1.1.1.cmml" xref="A4.T5.7.7.7.7.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T5.7.7.7.7.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="A4.T5.7.7.7.7.m1.1d">↓</annotation></semantics></math>
</td>
</tr>
<tr class="ltx_tr" id="A4.T5.7.7.8.1">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A4.T5.7.7.8.1.1" style="padding:0.75pt 8.0pt;">w/o IPI</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T5.7.7.8.1.2" style="padding:0.75pt 8.0pt;">13.30</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T5.7.7.8.1.3" style="padding:0.75pt 8.0pt;">0.433</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T5.7.7.8.1.4" style="padding:0.75pt 8.0pt;">1.35E-04</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T5.7.7.8.1.5" style="padding:0.75pt 8.0pt;">0.454</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A4.T5.7.7.8.1.6" style="padding:0.75pt 8.0pt;">32.56</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T5.7.7.8.1.7" style="padding:0.75pt 8.0pt;">64.31</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T5.7.7.8.1.8" style="padding:0.75pt 8.0pt;">893.31</td>
</tr>
<tr class="ltx_tr" id="A4.T5.7.7.9.2">
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T5.7.7.9.2.1" style="padding:0.75pt 8.0pt;">w/o LQ</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.9.2.2" style="padding:0.75pt 8.0pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="A4.T5.7.7.9.2.2.1">13.48</span></td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.9.2.3" style="padding:0.75pt 8.0pt;">0.445</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.9.2.4" style="padding:0.75pt 8.0pt;">1.76E-04</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.9.2.5" style="padding:0.75pt 8.0pt;">0.454</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T5.7.7.9.2.6" style="padding:0.75pt 8.0pt;">28.24</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.9.2.7" style="padding:0.75pt 8.0pt;">42.74</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.9.2.8" style="padding:0.75pt 8.0pt;">754.37</td>
</tr>
<tr class="ltx_tr" id="A4.T5.7.7.10.3">
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T5.7.7.10.3.1" style="padding:0.75pt 8.0pt;">w/o DQ</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.10.3.2" style="padding:0.75pt 8.0pt;">13.39</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.10.3.3" style="padding:0.75pt 8.0pt;">0.445</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.10.3.4" style="padding:0.75pt 8.0pt;"><span class="ltx_text ltx_font_bold" id="A4.T5.7.7.10.3.4.1">1.01E-04</span></td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.10.3.5" style="padding:0.75pt 8.0pt;">0.456</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T5.7.7.10.3.6" style="padding:0.75pt 8.0pt;">30.33</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.10.3.7" style="padding:0.75pt 8.0pt;">62.34</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.10.3.8" style="padding:0.75pt 8.0pt;">913.33</td>
</tr>
<tr class="ltx_tr" id="A4.T5.7.7.11.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T5.7.7.11.4.1" style="padding:0.75pt 8.0pt;">PA</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.11.4.2" style="padding:0.75pt 8.0pt;">13.25</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.11.4.3" style="padding:0.75pt 8.0pt;">0.436</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.11.4.4" style="padding:0.75pt 8.0pt;">1.11E-04</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.11.4.5" style="padding:0.75pt 8.0pt;">0.464</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T5.7.7.11.4.6" style="padding:0.75pt 8.0pt;">27.63</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.11.4.7" style="padding:0.75pt 8.0pt;">46.54</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.11.4.8" style="padding:0.75pt 8.0pt;">785.36</td>
</tr>
<tr class="ltx_tr" id="A4.T5.7.7.12.5">
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T5.7.7.12.5.1" style="padding:0.75pt 8.0pt;">KV_Q</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.12.5.2" style="padding:0.75pt 8.0pt;">13.34</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.12.5.3" style="padding:0.75pt 8.0pt;">0.443</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.12.5.4" style="padding:0.75pt 8.0pt;">1.17E-04</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.12.5.5" style="padding:0.75pt 8.0pt;">0.459</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T5.7.7.12.5.6" style="padding:0.75pt 8.0pt;">26.75</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.12.5.7" style="padding:0.75pt 8.0pt;">42.14</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.12.5.8" style="padding:0.75pt 8.0pt;">785.69</td>
</tr>
<tr class="ltx_tr" id="A4.T5.7.7.13.6">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A4.T5.7.7.13.6.1" style="padding:0.75pt 8.0pt;">w/o EPI</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T5.7.7.13.6.2" style="padding:0.75pt 8.0pt;">12.63</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T5.7.7.13.6.3" style="padding:0.75pt 8.0pt;">0.403</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T5.7.7.13.6.4" style="padding:0.75pt 8.0pt;">1.80E-04</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T5.7.7.13.6.5" style="padding:0.75pt 8.0pt;">0.509</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A4.T5.7.7.13.6.6" style="padding:0.75pt 8.0pt;">42.17</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T5.7.7.13.6.7" style="padding:0.75pt 8.0pt;">58.17</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T5.7.7.13.6.8" style="padding:0.75pt 8.0pt;">948.25</td>
</tr>
<tr class="ltx_tr" id="A4.T5.7.7.14.7">
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T5.7.7.14.7.1" style="padding:0.75pt 8.0pt;">w/o Add</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.14.7.2" style="padding:0.75pt 8.0pt;">13.28</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.14.7.3" style="padding:0.75pt 8.0pt;">0.442</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.14.7.4" style="padding:0.75pt 8.0pt;">1.56E-04</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.14.7.5" style="padding:0.75pt 8.0pt;">0.459</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T5.7.7.14.7.6" style="padding:0.75pt 8.0pt;">34.24</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.14.7.7" style="padding:0.75pt 8.0pt;">52.94</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.14.7.8" style="padding:0.75pt 8.0pt;">804.37</td>
</tr>
<tr class="ltx_tr" id="A4.T5.7.7.15.8">
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T5.7.7.15.8.1" style="padding:0.75pt 8.0pt;">w/o Drop</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.15.8.2" style="padding:0.75pt 8.0pt;">13.36</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.15.8.3" style="padding:0.75pt 8.0pt;">0.441</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.15.8.4" style="padding:0.75pt 8.0pt;">1.94E-04</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.15.8.5" style="padding:0.75pt 8.0pt;">0.458</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T5.7.7.15.8.6" style="padding:0.75pt 8.0pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="A4.T5.7.7.15.8.6.1">26.65</span></td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.15.8.7" style="padding:0.75pt 8.0pt;">44.55</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.15.8.8" style="padding:0.75pt 8.0pt;">764.52</td>
</tr>
<tr class="ltx_tr" id="A4.T5.7.7.16.9">
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T5.7.7.16.9.1" style="padding:0.75pt 8.0pt;">w/o BS</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.16.9.2" style="padding:0.75pt 8.0pt;">13.27</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.16.9.3" style="padding:0.75pt 8.0pt;">0.443</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.16.9.4" style="padding:0.75pt 8.0pt;">1.08E-04</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.16.9.5" style="padding:0.75pt 8.0pt;">0.461</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T5.7.7.16.9.6" style="padding:0.75pt 8.0pt;">29.60</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.16.9.7" style="padding:0.75pt 8.0pt;">56.56</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.16.9.8" style="padding:0.75pt 8.0pt;">850.17</td>
</tr>
<tr class="ltx_tr" id="A4.T5.7.7.17.10">
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T5.7.7.17.10.1" style="padding:0.75pt 8.0pt;">w/o NF</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.17.10.2" style="padding:0.75pt 8.0pt;">13.41</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.17.10.3" style="padding:0.75pt 8.0pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="A4.T5.7.7.17.10.3.1">0.446</span></td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.17.10.4" style="padding:0.75pt 8.0pt;">1.82E-04</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.17.10.5" style="padding:0.75pt 8.0pt;">0.455</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T5.7.7.17.10.6" style="padding:0.75pt 8.0pt;">29.21</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.17.10.7" style="padding:0.75pt 8.0pt;">56.48</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.17.10.8" style="padding:0.75pt 8.0pt;">878.11</td>
</tr>
<tr class="ltx_tr" id="A4.T5.7.7.18.11">
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T5.7.7.18.11.1" style="padding:0.75pt 8.0pt;">w/o AL</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.18.11.2" style="padding:0.75pt 8.0pt;">13.04</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.18.11.3" style="padding:0.75pt 8.0pt;">0.429</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.18.11.4" style="padding:0.75pt 8.0pt;">1.04E-04</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.18.11.5" style="padding:0.75pt 8.0pt;">0.474</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T5.7.7.18.11.6" style="padding:0.75pt 8.0pt;">27.17</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.18.11.7" style="padding:0.75pt 8.0pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="A4.T5.7.7.18.11.7.1">33.97</span></td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.18.11.8" style="padding:0.75pt 8.0pt;">765.69</td>
</tr>
<tr class="ltx_tr" id="A4.T5.7.7.19.12">
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T5.7.7.19.12.1" style="padding:0.75pt 8.0pt;">w/o Rescalings</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.19.12.2" style="padding:0.75pt 8.0pt;">13.23</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.19.12.3" style="padding:0.75pt 8.0pt;">0.438</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.19.12.4" style="padding:0.75pt 8.0pt;">1.21E-04</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.19.12.5" style="padding:0.75pt 8.0pt;">0.464</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T5.7.7.19.12.6" style="padding:0.75pt 8.0pt;">27.64</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.19.12.7" style="padding:0.75pt 8.0pt;">35.95</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.19.12.8" style="padding:0.75pt 8.0pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="A4.T5.7.7.19.12.8.1">721.11</span></td>
</tr>
<tr class="ltx_tr" id="A4.T5.7.7.20.13">
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T5.7.7.20.13.1" style="padding:0.75pt 8.0pt;">w/o Realign</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.20.13.2" style="padding:0.75pt 8.0pt;">12.27</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.20.13.3" style="padding:0.75pt 8.0pt;">0.433</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.20.13.4" style="padding:0.75pt 8.0pt;">1.17E-04</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.20.13.5" style="padding:0.75pt 8.0pt;">0.434</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T5.7.7.20.13.6" style="padding:0.75pt 8.0pt;">34.60</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.20.13.7" style="padding:0.75pt 8.0pt;">49.33</td>
<td class="ltx_td ltx_align_center" id="A4.T5.7.7.20.13.8" style="padding:0.75pt 8.0pt;">860.25</td>
</tr>
<tr class="ltx_tr" id="A4.T5.7.7.21.14" style="background-color:#F0F0F0;">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="A4.T5.7.7.21.14.1" style="padding:0.75pt 8.0pt;"><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="A4.T5.7.7.21.14.1.1" style="background-color:#F0F0F0;">Animate-X</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A4.T5.7.7.21.14.2" style="padding:0.75pt 8.0pt;"><span class="ltx_text ltx_font_bold" id="A4.T5.7.7.21.14.2.1" style="background-color:#F0F0F0;">13.60</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A4.T5.7.7.21.14.3" style="padding:0.75pt 8.0pt;"><span class="ltx_text ltx_font_bold" id="A4.T5.7.7.21.14.3.1" style="background-color:#F0F0F0;">0.452</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A4.T5.7.7.21.14.4" style="padding:0.75pt 8.0pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="A4.T5.7.7.21.14.4.1" style="background-color:#F0F0F0;">1.02E-04</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A4.T5.7.7.21.14.5" style="padding:0.75pt 8.0pt;"><span class="ltx_text ltx_font_bold" id="A4.T5.7.7.21.14.5.1" style="background-color:#F0F0F0;">0.430</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="A4.T5.7.7.21.14.6" style="padding:0.75pt 8.0pt;"><span class="ltx_text ltx_font_bold" id="A4.T5.7.7.21.14.6.1" style="background-color:#F0F0F0;">26.11</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A4.T5.7.7.21.14.7" style="padding:0.75pt 8.0pt;"><span class="ltx_text ltx_font_bold" id="A4.T5.7.7.21.14.7.1" style="background-color:#F0F0F0;">32.23</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A4.T5.7.7.21.14.8" style="padding:0.75pt 8.0pt;"><span class="ltx_text ltx_font_bold" id="A4.T5.7.7.21.14.8.1" style="background-color:#F0F0F0;">703.87</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>
Quantitative results of ablation study.
</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_subsection" id="A4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">D.4 </span>More ablation study</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A4.SS4.p1">
<p class="ltx_p" id="A4.SS4.p1.1">In the main paper, we present the results of the primary ablation experiments for IPI and EPI. In this section, we supplement those results with additional ablation experiments to further demonstrate the contribution of each individual module.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A4.SS4.p2">
<p class="ltx_p" id="A4.SS4.p2.1"><span class="ltx_text ltx_font_bold" id="A4.SS4.p2.1.1">Ablation on Implicit Pose Indicator.</span> For more detailed analysis about the structure of IPI, we set up several variants: (1) remove IPI: w/o IPI. (2) remove learnable query: w/o LQ. (3) remove DWPose query: w/o DQ. (4) set IPI and spatial Attention to Parallel: PA. (5) set CLIP features as Q and DWPose as K,V in IPI: KV_Q. The quantitative results are shown in Tab.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#A4.T5" title="Table 5 ‣ D.3 Robustness ‣ Appendix D Additional Experimental Results ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">5</span></a>. It can be seen that removing the entire IPI presents the worst performance. By modifying the IPI module, although it improves on the w/o IPI, it still falls short of the final result of <span class="ltx_text ltx_font_typewriter" id="A4.SS4.p2.1.2">Animate-X</span>, which suggests that our current IPI structure is the most reasonable and achieves the best performance.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A4.SS4.p3">
<p class="ltx_p" id="A4.SS4.p3.5">Since IPI is embedded in <span class="ltx_text ltx_font_typewriter" id="A4.SS4.p3.5.1">Animate-X</span> in the form of residual connection, i.e., <math alttext="x=x+\alpha IPI(x)" class="ltx_Math" display="inline" id="A4.SS4.p3.1.m1.1"><semantics id="A4.SS4.p3.1.m1.1a"><mrow id="A4.SS4.p3.1.m1.1.2" xref="A4.SS4.p3.1.m1.1.2.cmml"><mi id="A4.SS4.p3.1.m1.1.2.2" xref="A4.SS4.p3.1.m1.1.2.2.cmml">x</mi><mo id="A4.SS4.p3.1.m1.1.2.1" xref="A4.SS4.p3.1.m1.1.2.1.cmml">=</mo><mrow id="A4.SS4.p3.1.m1.1.2.3" xref="A4.SS4.p3.1.m1.1.2.3.cmml"><mi id="A4.SS4.p3.1.m1.1.2.3.2" xref="A4.SS4.p3.1.m1.1.2.3.2.cmml">x</mi><mo id="A4.SS4.p3.1.m1.1.2.3.1" xref="A4.SS4.p3.1.m1.1.2.3.1.cmml">+</mo><mrow id="A4.SS4.p3.1.m1.1.2.3.3" xref="A4.SS4.p3.1.m1.1.2.3.3.cmml"><mi id="A4.SS4.p3.1.m1.1.2.3.3.2" xref="A4.SS4.p3.1.m1.1.2.3.3.2.cmml">α</mi><mo id="A4.SS4.p3.1.m1.1.2.3.3.1" xref="A4.SS4.p3.1.m1.1.2.3.3.1.cmml">⁢</mo><mi id="A4.SS4.p3.1.m1.1.2.3.3.3" xref="A4.SS4.p3.1.m1.1.2.3.3.3.cmml">I</mi><mo id="A4.SS4.p3.1.m1.1.2.3.3.1a" xref="A4.SS4.p3.1.m1.1.2.3.3.1.cmml">⁢</mo><mi id="A4.SS4.p3.1.m1.1.2.3.3.4" xref="A4.SS4.p3.1.m1.1.2.3.3.4.cmml">P</mi><mo id="A4.SS4.p3.1.m1.1.2.3.3.1b" xref="A4.SS4.p3.1.m1.1.2.3.3.1.cmml">⁢</mo><mi id="A4.SS4.p3.1.m1.1.2.3.3.5" xref="A4.SS4.p3.1.m1.1.2.3.3.5.cmml">I</mi><mo id="A4.SS4.p3.1.m1.1.2.3.3.1c" xref="A4.SS4.p3.1.m1.1.2.3.3.1.cmml">⁢</mo><mrow id="A4.SS4.p3.1.m1.1.2.3.3.6.2" xref="A4.SS4.p3.1.m1.1.2.3.3.cmml"><mo id="A4.SS4.p3.1.m1.1.2.3.3.6.2.1" stretchy="false" xref="A4.SS4.p3.1.m1.1.2.3.3.cmml">(</mo><mi id="A4.SS4.p3.1.m1.1.1" xref="A4.SS4.p3.1.m1.1.1.cmml">x</mi><mo id="A4.SS4.p3.1.m1.1.2.3.3.6.2.2" stretchy="false" xref="A4.SS4.p3.1.m1.1.2.3.3.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A4.SS4.p3.1.m1.1b"><apply id="A4.SS4.p3.1.m1.1.2.cmml" xref="A4.SS4.p3.1.m1.1.2"><eq id="A4.SS4.p3.1.m1.1.2.1.cmml" xref="A4.SS4.p3.1.m1.1.2.1"></eq><ci id="A4.SS4.p3.1.m1.1.2.2.cmml" xref="A4.SS4.p3.1.m1.1.2.2">𝑥</ci><apply id="A4.SS4.p3.1.m1.1.2.3.cmml" xref="A4.SS4.p3.1.m1.1.2.3"><plus id="A4.SS4.p3.1.m1.1.2.3.1.cmml" xref="A4.SS4.p3.1.m1.1.2.3.1"></plus><ci id="A4.SS4.p3.1.m1.1.2.3.2.cmml" xref="A4.SS4.p3.1.m1.1.2.3.2">𝑥</ci><apply id="A4.SS4.p3.1.m1.1.2.3.3.cmml" xref="A4.SS4.p3.1.m1.1.2.3.3"><times id="A4.SS4.p3.1.m1.1.2.3.3.1.cmml" xref="A4.SS4.p3.1.m1.1.2.3.3.1"></times><ci id="A4.SS4.p3.1.m1.1.2.3.3.2.cmml" xref="A4.SS4.p3.1.m1.1.2.3.3.2">𝛼</ci><ci id="A4.SS4.p3.1.m1.1.2.3.3.3.cmml" xref="A4.SS4.p3.1.m1.1.2.3.3.3">𝐼</ci><ci id="A4.SS4.p3.1.m1.1.2.3.3.4.cmml" xref="A4.SS4.p3.1.m1.1.2.3.3.4">𝑃</ci><ci id="A4.SS4.p3.1.m1.1.2.3.3.5.cmml" xref="A4.SS4.p3.1.m1.1.2.3.3.5">𝐼</ci><ci id="A4.SS4.p3.1.m1.1.1.cmml" xref="A4.SS4.p3.1.m1.1.1">𝑥</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.SS4.p3.1.m1.1c">x=x+\alpha IPI(x)</annotation><annotation encoding="application/x-llamapun" id="A4.SS4.p3.1.m1.1d">italic_x = italic_x + italic_α italic_I italic_P italic_I ( italic_x )</annotation></semantics></math>, we also explore the impact of the weight <math alttext="\alpha" class="ltx_Math" display="inline" id="A4.SS4.p3.2.m2.1"><semantics id="A4.SS4.p3.2.m2.1a"><mi id="A4.SS4.p3.2.m2.1.1" xref="A4.SS4.p3.2.m2.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="A4.SS4.p3.2.m2.1b"><ci id="A4.SS4.p3.2.m2.1.1.cmml" xref="A4.SS4.p3.2.m2.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.SS4.p3.2.m2.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="A4.SS4.p3.2.m2.1d">italic_α</annotation></semantics></math> of IPI on performance as illustrated in Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#A4.F13" title="Figure 13 ‣ D.4 More ablation study ‣ Appendix D Additional Experimental Results ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">13</span></a>, as <math alttext="\alpha" class="ltx_Math" display="inline" id="A4.SS4.p3.3.m3.1"><semantics id="A4.SS4.p3.3.m3.1a"><mi id="A4.SS4.p3.3.m3.1.1" xref="A4.SS4.p3.3.m3.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="A4.SS4.p3.3.m3.1b"><ci id="A4.SS4.p3.3.m3.1.1.cmml" xref="A4.SS4.p3.3.m3.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.SS4.p3.3.m3.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="A4.SS4.p3.3.m3.1d">italic_α</annotation></semantics></math> increases from 0 to 1, all metrics show a stable improvement despite some fluctuations. The best performance is achieved when <math alttext="\alpha" class="ltx_Math" display="inline" id="A4.SS4.p3.4.m4.1"><semantics id="A4.SS4.p3.4.m4.1a"><mi id="A4.SS4.p3.4.m4.1.1" xref="A4.SS4.p3.4.m4.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="A4.SS4.p3.4.m4.1b"><ci id="A4.SS4.p3.4.m4.1.1.cmml" xref="A4.SS4.p3.4.m4.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.SS4.p3.4.m4.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="A4.SS4.p3.4.m4.1d">italic_α</annotation></semantics></math> is set to 1, so we empirically set <math alttext="\alpha" class="ltx_Math" display="inline" id="A4.SS4.p3.5.m5.1"><semantics id="A4.SS4.p3.5.m5.1a"><mi id="A4.SS4.p3.5.m5.1.1" xref="A4.SS4.p3.5.m5.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="A4.SS4.p3.5.m5.1b"><ci id="A4.SS4.p3.5.m5.1.1.cmml" xref="A4.SS4.p3.5.m5.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.SS4.p3.5.m5.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="A4.SS4.p3.5.m5.1d">italic_α</annotation></semantics></math> to 1 in the final configuration.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="A4.F13"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="498" id="A4.F13.g1" src="./animate-x_files/x12.png" width="830">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 13: </span>Ablation study on the weight <math alttext="\alpha" class="ltx_Math" display="inline" id="A4.F13.3.m1.1"><semantics id="A4.F13.3.m1.1b"><mi id="A4.F13.3.m1.1.1" xref="A4.F13.3.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="A4.F13.3.m1.1c"><ci id="A4.F13.3.m1.1.1.cmml" xref="A4.F13.3.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.F13.3.m1.1d">\alpha</annotation><annotation encoding="application/x-llamapun" id="A4.F13.3.m1.1e">italic_α</annotation></semantics></math> of Implicit Pose Indicator. To better visualize the impact of <math alttext="\alpha" class="ltx_Math" display="inline" id="A4.F13.4.m2.1"><semantics id="A4.F13.4.m2.1b"><mi id="A4.F13.4.m2.1.1" xref="A4.F13.4.m2.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="A4.F13.4.m2.1c"><ci id="A4.F13.4.m2.1.1.cmml" xref="A4.F13.4.m2.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.F13.4.m2.1d">\alpha</annotation><annotation encoding="application/x-llamapun" id="A4.F13.4.m2.1e">italic_α</annotation></semantics></math> on performance, we normalize all the values to the range of 0 to 1.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A4.SS4.p4">
<p class="ltx_p" id="A4.SS4.p4.1"><span class="ltx_text ltx_font_bold" id="A4.SS4.p4.1.1">Ablation on Explicit Pose Indicator.</span> We conduct more detailed ablation experiments for different pairs of pose transformations by (1) removing the entire EPI: w/o EPI; (2)&amp;(3) removing adding and dropping parts; canceling the change of the length of (4) body and should: w/o BS; (5) neck and face: w/o NF; (6) arm and leg: w/o AL; (7) removing all rescaling process: w/o Rescalings; (8) remove another person pose alignment: w/o Realign. From the results displayed in Tab.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#A4.T5" title="Table 5 ‣ D.3 Robustness ‣ Appendix D Additional Experimental Results ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">5</span></a>, we found that each pose transformation contributes compared to w/o EPI, with aligned transformations with another person’s pose contributing the most. It suggests that maintaining the overall integrity of the pose while allowing for some variations is the most important factor, and EPI also learns the overall integrity of the pose. The final result indicates that all the transformations together achieve the best performance.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A4.SS4.p5">
<p class="ltx_p" id="A4.SS4.p5.7">To explore the effect of different probabilities <math alttext="\lambda" class="ltx_Math" display="inline" id="A4.SS4.p5.1.m1.1"><semantics id="A4.SS4.p5.1.m1.1a"><mi id="A4.SS4.p5.1.m1.1.1" xref="A4.SS4.p5.1.m1.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="A4.SS4.p5.1.m1.1b"><ci id="A4.SS4.p5.1.m1.1.1.cmml" xref="A4.SS4.p5.1.m1.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.SS4.p5.1.m1.1c">\lambda</annotation><annotation encoding="application/x-llamapun" id="A4.SS4.p5.1.m1.1d">italic_λ</annotation></semantics></math> of using pose transformation for EPI on the model performance, we set <math alttext="\lambda" class="ltx_Math" display="inline" id="A4.SS4.p5.2.m2.1"><semantics id="A4.SS4.p5.2.m2.1a"><mi id="A4.SS4.p5.2.m2.1.1" xref="A4.SS4.p5.2.m2.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="A4.SS4.p5.2.m2.1b"><ci id="A4.SS4.p5.2.m2.1.1.cmml" xref="A4.SS4.p5.2.m2.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.SS4.p5.2.m2.1c">\lambda</annotation><annotation encoding="application/x-llamapun" id="A4.SS4.p5.2.m2.1d">italic_λ</annotation></semantics></math> as 100%, 98%, 95%, 90% and 80% for the ablation experiments on two datasets. The results presented in Tab.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#A4.T6" title="Table 6 ‣ D.4 More ablation study ‣ Appendix D Additional Experimental Results ‣ Animate-X: Universal Character Image Animation with Enhanced Motion Representation"><span class="ltx_text ltx_ref_tag">6</span></a> suggest that a high <math alttext="\lambda" class="ltx_Math" display="inline" id="A4.SS4.p5.3.m3.1"><semantics id="A4.SS4.p5.3.m3.1a"><mi id="A4.SS4.p5.3.m3.1.1" xref="A4.SS4.p5.3.m3.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="A4.SS4.p5.3.m3.1b"><ci id="A4.SS4.p5.3.m3.1.1.cmml" xref="A4.SS4.p5.3.m3.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.SS4.p5.3.m3.1c">\lambda</annotation><annotation encoding="application/x-llamapun" id="A4.SS4.p5.3.m3.1d">italic_λ</annotation></semantics></math> performs better on <math alttext="A^{2}" class="ltx_Math" display="inline" id="A4.SS4.p5.4.m4.1"><semantics id="A4.SS4.p5.4.m4.1a"><msup id="A4.SS4.p5.4.m4.1.1" xref="A4.SS4.p5.4.m4.1.1.cmml"><mi id="A4.SS4.p5.4.m4.1.1.2" xref="A4.SS4.p5.4.m4.1.1.2.cmml">A</mi><mn id="A4.SS4.p5.4.m4.1.1.3" xref="A4.SS4.p5.4.m4.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="A4.SS4.p5.4.m4.1b"><apply id="A4.SS4.p5.4.m4.1.1.cmml" xref="A4.SS4.p5.4.m4.1.1"><csymbol cd="ambiguous" id="A4.SS4.p5.4.m4.1.1.1.cmml" xref="A4.SS4.p5.4.m4.1.1">superscript</csymbol><ci id="A4.SS4.p5.4.m4.1.1.2.cmml" xref="A4.SS4.p5.4.m4.1.1.2">𝐴</ci><cn id="A4.SS4.p5.4.m4.1.1.3.cmml" type="integer" xref="A4.SS4.p5.4.m4.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.SS4.p5.4.m4.1c">A^{2}</annotation><annotation encoding="application/x-llamapun" id="A4.SS4.p5.4.m4.1d">italic_A start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_typewriter" id="A4.SS4.p5.7.1">Bench</span>, i.e., it performs better when the reference image and pose image are not aligned, but harms performance on the TikTok dataset, i.e., when the reference image and pose image are strictly aligned. In contrast, a relatively low <math alttext="\lambda" class="ltx_Math" display="inline" id="A4.SS4.p5.5.m5.1"><semantics id="A4.SS4.p5.5.m5.1a"><mi id="A4.SS4.p5.5.m5.1.1" xref="A4.SS4.p5.5.m5.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="A4.SS4.p5.5.m5.1b"><ci id="A4.SS4.p5.5.m5.1.1.cmml" xref="A4.SS4.p5.5.m5.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.SS4.p5.5.m5.1c">\lambda</annotation><annotation encoding="application/x-llamapun" id="A4.SS4.p5.5.m5.1d">italic_λ</annotation></semantics></math>, e.g., 90%, would be in this case perform better. It is reasonable that in the case of strict alignment, we expect the pose to provide a strictly accurate motion source, and thus need to reduce the percentage <math alttext="\lambda" class="ltx_Math" display="inline" id="A4.SS4.p5.6.m6.1"><semantics id="A4.SS4.p5.6.m6.1a"><mi id="A4.SS4.p5.6.m6.1.1" xref="A4.SS4.p5.6.m6.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="A4.SS4.p5.6.m6.1b"><ci id="A4.SS4.p5.6.m6.1.1.cmml" xref="A4.SS4.p5.6.m6.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.SS4.p5.6.m6.1c">\lambda</annotation><annotation encoding="application/x-llamapun" id="A4.SS4.p5.6.m6.1d">italic_λ</annotation></semantics></math> of pose transformation. However, in the non-strictly aligned case, we expect the pose image to provide an approximate motion trend, so we need to increase <math alttext="\lambda" class="ltx_Math" display="inline" id="A4.SS4.p5.7.m7.1"><semantics id="A4.SS4.p5.7.m7.1a"><mi id="A4.SS4.p5.7.m7.1.1" xref="A4.SS4.p5.7.m7.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="A4.SS4.p5.7.m7.1b"><ci id="A4.SS4.p5.7.m7.1.1.cmml" xref="A4.SS4.p5.7.m7.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.SS4.p5.7.m7.1c">\lambda</annotation><annotation encoding="application/x-llamapun" id="A4.SS4.p5.7.m7.1d">italic_λ</annotation></semantics></math>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="A4.T6">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A4.T6.9" style="width:368.6pt;height:112.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-22.6pt,6.9pt) scale(0.890646094681156,0.890646094681156) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A4.T6.9.9">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A4.T6.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="A4.T6.1.1.1.2" rowspan="2"><span class="ltx_text ltx_font_bold" id="A4.T6.1.1.1.2.1">Method</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4" id="A4.T6.1.1.1.1">
<math alttext="A^{2}" class="ltx_Math" display="inline" id="A4.T6.1.1.1.1.m1.1"><semantics id="A4.T6.1.1.1.1.m1.1a"><msup id="A4.T6.1.1.1.1.m1.1.1" xref="A4.T6.1.1.1.1.m1.1.1.cmml"><mi id="A4.T6.1.1.1.1.m1.1.1.2" xref="A4.T6.1.1.1.1.m1.1.1.2.cmml">A</mi><mn id="A4.T6.1.1.1.1.m1.1.1.3" xref="A4.T6.1.1.1.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="A4.T6.1.1.1.1.m1.1b"><apply id="A4.T6.1.1.1.1.m1.1.1.cmml" xref="A4.T6.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="A4.T6.1.1.1.1.m1.1.1.1.cmml" xref="A4.T6.1.1.1.1.m1.1.1">superscript</csymbol><ci id="A4.T6.1.1.1.1.m1.1.1.2.cmml" xref="A4.T6.1.1.1.1.m1.1.1.2">𝐴</ci><cn id="A4.T6.1.1.1.1.m1.1.1.3.cmml" type="integer" xref="A4.T6.1.1.1.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T6.1.1.1.1.m1.1c">A^{2}</annotation><annotation encoding="application/x-llamapun" id="A4.T6.1.1.1.1.m1.1d">italic_A start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_typewriter" id="A4.T6.1.1.1.1.1">Bench</span>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4" id="A4.T6.1.1.1.3"><span class="ltx_text ltx_font_bold" id="A4.T6.1.1.1.3.1">TikTok&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Jafarian &amp; Park (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib24" title="">2021</a>)</cite></span></th>
</tr>
<tr class="ltx_tr" id="A4.T6.9.9.9">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A4.T6.2.2.2.1">SSIM<math alttext="\uparrow" class="ltx_Math" display="inline" id="A4.T6.2.2.2.1.m1.1"><semantics id="A4.T6.2.2.2.1.m1.1a"><mo id="A4.T6.2.2.2.1.m1.1.1" stretchy="false" xref="A4.T6.2.2.2.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A4.T6.2.2.2.1.m1.1b"><ci id="A4.T6.2.2.2.1.m1.1.1.cmml" xref="A4.T6.2.2.2.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T6.2.2.2.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A4.T6.2.2.2.1.m1.1d">↑</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A4.T6.3.3.3.2">FID<math alttext="\downarrow" class="ltx_Math" display="inline" id="A4.T6.3.3.3.2.m1.1"><semantics id="A4.T6.3.3.3.2.m1.1a"><mo id="A4.T6.3.3.3.2.m1.1.1" stretchy="false" xref="A4.T6.3.3.3.2.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A4.T6.3.3.3.2.m1.1b"><ci id="A4.T6.3.3.3.2.m1.1.1.cmml" xref="A4.T6.3.3.3.2.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T6.3.3.3.2.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="A4.T6.3.3.3.2.m1.1d">↓</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A4.T6.4.4.4.3">FID-VID<math alttext="\downarrow" class="ltx_Math" display="inline" id="A4.T6.4.4.4.3.m1.1"><semantics id="A4.T6.4.4.4.3.m1.1a"><mo id="A4.T6.4.4.4.3.m1.1.1" stretchy="false" xref="A4.T6.4.4.4.3.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A4.T6.4.4.4.3.m1.1b"><ci id="A4.T6.4.4.4.3.m1.1.1.cmml" xref="A4.T6.4.4.4.3.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T6.4.4.4.3.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="A4.T6.4.4.4.3.m1.1d">↓</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A4.T6.5.5.5.4">FVD<math alttext="\downarrow" class="ltx_Math" display="inline" id="A4.T6.5.5.5.4.m1.1"><semantics id="A4.T6.5.5.5.4.m1.1a"><mo id="A4.T6.5.5.5.4.m1.1.1" stretchy="false" xref="A4.T6.5.5.5.4.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A4.T6.5.5.5.4.m1.1b"><ci id="A4.T6.5.5.5.4.m1.1.1.cmml" xref="A4.T6.5.5.5.4.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T6.5.5.5.4.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="A4.T6.5.5.5.4.m1.1d">↓</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A4.T6.6.6.6.5">SSIM<math alttext="\uparrow" class="ltx_Math" display="inline" id="A4.T6.6.6.6.5.m1.1"><semantics id="A4.T6.6.6.6.5.m1.1a"><mo id="A4.T6.6.6.6.5.m1.1.1" stretchy="false" xref="A4.T6.6.6.6.5.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A4.T6.6.6.6.5.m1.1b"><ci id="A4.T6.6.6.6.5.m1.1.1.cmml" xref="A4.T6.6.6.6.5.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T6.6.6.6.5.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A4.T6.6.6.6.5.m1.1d">↑</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A4.T6.7.7.7.6">FID<math alttext="\downarrow" class="ltx_Math" display="inline" id="A4.T6.7.7.7.6.m1.1"><semantics id="A4.T6.7.7.7.6.m1.1a"><mo id="A4.T6.7.7.7.6.m1.1.1" stretchy="false" xref="A4.T6.7.7.7.6.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A4.T6.7.7.7.6.m1.1b"><ci id="A4.T6.7.7.7.6.m1.1.1.cmml" xref="A4.T6.7.7.7.6.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T6.7.7.7.6.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="A4.T6.7.7.7.6.m1.1d">↓</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A4.T6.8.8.8.7">FID-VID<math alttext="\downarrow" class="ltx_Math" display="inline" id="A4.T6.8.8.8.7.m1.1"><semantics id="A4.T6.8.8.8.7.m1.1a"><mo id="A4.T6.8.8.8.7.m1.1.1" stretchy="false" xref="A4.T6.8.8.8.7.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A4.T6.8.8.8.7.m1.1b"><ci id="A4.T6.8.8.8.7.m1.1.1.cmml" xref="A4.T6.8.8.8.7.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T6.8.8.8.7.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="A4.T6.8.8.8.7.m1.1d">↓</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A4.T6.9.9.9.8">FVD<math alttext="\downarrow" class="ltx_Math" display="inline" id="A4.T6.9.9.9.8.m1.1"><semantics id="A4.T6.9.9.9.8.m1.1a"><mo id="A4.T6.9.9.9.8.m1.1.1" stretchy="false" xref="A4.T6.9.9.9.8.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A4.T6.9.9.9.8.m1.1b"><ci id="A4.T6.9.9.9.8.m1.1.1.cmml" xref="A4.T6.9.9.9.8.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T6.9.9.9.8.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="A4.T6.9.9.9.8.m1.1d">↓</annotation></semantics></math>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A4.T6.9.9.10.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A4.T6.9.9.10.1.1"><span class="ltx_text ltx_font_bold" id="A4.T6.9.9.10.1.1.1">100%</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T6.9.9.10.1.2"><span class="ltx_text ltx_font_bold" id="A4.T6.9.9.10.1.2.1">0.452</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T6.9.9.10.1.3"><span class="ltx_text ltx_font_bold" id="A4.T6.9.9.10.1.3.1">26.11</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T6.9.9.10.1.4"><span class="ltx_text ltx_font_bold" id="A4.T6.9.9.10.1.4.1">32.23</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A4.T6.9.9.10.1.5"><span class="ltx_text ltx_font_bold" id="A4.T6.9.9.10.1.5.1">703.87</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T6.9.9.10.1.6">0.802</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T6.9.9.10.1.7">55.26</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T6.9.9.10.1.8">17.47</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T6.9.9.10.1.9">138.36</td>
</tr>
<tr class="ltx_tr" id="A4.T6.9.9.11.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A4.T6.9.9.11.2.1"><span class="ltx_text ltx_font_bold" id="A4.T6.9.9.11.2.1.1">98%</span></th>
<td class="ltx_td ltx_align_center" id="A4.T6.9.9.11.2.2"><span class="ltx_text ltx_framed ltx_framed_underline" id="A4.T6.9.9.11.2.2.1">0.448</span>
</td>
<td class="ltx_td ltx_align_center" id="A4.T6.9.9.11.2.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="A4.T6.9.9.11.2.3.1">26.93</span></td>
<td class="ltx_td ltx_align_center" id="A4.T6.9.9.11.2.4"><span class="ltx_text ltx_framed ltx_framed_underline" id="A4.T6.9.9.11.2.4.1">37.67</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T6.9.9.11.2.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="A4.T6.9.9.11.2.5.1">775.24</span></td>
<td class="ltx_td ltx_align_center" id="A4.T6.9.9.11.2.6">0.797</td>
<td class="ltx_td ltx_align_center" id="A4.T6.9.9.11.2.7">55.81</td>
<td class="ltx_td ltx_align_center" id="A4.T6.9.9.11.2.8">16.28</td>
<td class="ltx_td ltx_align_center" id="A4.T6.9.9.11.2.9"><span class="ltx_text ltx_framed ltx_framed_underline" id="A4.T6.9.9.11.2.9.1">129.48</span></td>
</tr>
<tr class="ltx_tr" id="A4.T6.9.9.12.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A4.T6.9.9.12.3.1"><span class="ltx_text ltx_font_bold" id="A4.T6.9.9.12.3.1.1">95%</span></th>
<td class="ltx_td ltx_align_center" id="A4.T6.9.9.12.3.2">0.447</td>
<td class="ltx_td ltx_align_center" id="A4.T6.9.9.12.3.3">27.46</td>
<td class="ltx_td ltx_align_center" id="A4.T6.9.9.12.3.4">39.21</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T6.9.9.12.3.5">785.55</td>
<td class="ltx_td ltx_align_center" id="A4.T6.9.9.12.3.6"><span class="ltx_text ltx_framed ltx_framed_underline" id="A4.T6.9.9.12.3.6.1">0.804</span></td>
<td class="ltx_td ltx_align_center" id="A4.T6.9.9.12.3.7"><span class="ltx_text ltx_font_bold" id="A4.T6.9.9.12.3.7.1">52.72</span></td>
<td class="ltx_td ltx_align_center" id="A4.T6.9.9.12.3.8"><span class="ltx_text ltx_framed ltx_framed_underline" id="A4.T6.9.9.12.3.8.1">14.61</span></td>
<td class="ltx_td ltx_align_center" id="A4.T6.9.9.12.3.9"><span class="ltx_text ltx_font_bold" id="A4.T6.9.9.12.3.9.1">124.92</span></td>
</tr>
<tr class="ltx_tr" id="A4.T6.9.9.13.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A4.T6.9.9.13.4.1"><span class="ltx_text ltx_font_bold" id="A4.T6.9.9.13.4.1.1">90%</span></th>
<td class="ltx_td ltx_align_center" id="A4.T6.9.9.13.4.2">0.444</td>
<td class="ltx_td ltx_align_center" id="A4.T6.9.9.13.4.3">27.15</td>
<td class="ltx_td ltx_align_center" id="A4.T6.9.9.13.4.4">38.03</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T6.9.9.13.4.5">775.38</td>
<td class="ltx_td ltx_align_center" id="A4.T6.9.9.13.4.6"><span class="ltx_text ltx_font_bold" id="A4.T6.9.9.13.4.6.1">0.806</span></td>
<td class="ltx_td ltx_align_center" id="A4.T6.9.9.13.4.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="A4.T6.9.9.13.4.7.1">52.81</span></td>
<td class="ltx_td ltx_align_center" id="A4.T6.9.9.13.4.8">14.82</td>
<td class="ltx_td ltx_align_center" id="A4.T6.9.9.13.4.9">139.01</td>
</tr>
<tr class="ltx_tr" id="A4.T6.9.9.14.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="A4.T6.9.9.14.5.1"><span class="ltx_text ltx_font_bold" id="A4.T6.9.9.14.5.1.1">80%</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A4.T6.9.9.14.5.2">0.442</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A4.T6.9.9.14.5.3">29.13</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A4.T6.9.9.14.5.4">47.93</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="A4.T6.9.9.14.5.5">803.97</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A4.T6.9.9.14.5.6">0.802</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A4.T6.9.9.14.5.7">54.51</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A4.T6.9.9.14.5.8"><span class="ltx_text ltx_font_bold" id="A4.T6.9.9.14.5.8.1">14.42</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A4.T6.9.9.14.5.9">133.78</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>Quantitative results for different probabilities of using pose transformation.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="A4.T7">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A4.T7.18" style="width:433.6pt;height:172pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-102.2pt,40.4pt) scale(0.679593726267912,0.679593726267912) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A4.T7.18.18">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A4.T7.6.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A4.T7.6.6.6.7" style="padding:0.75pt 6.5pt;">Method</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T7.1.1.1.1" style="padding:0.75pt 6.5pt;">L1 <math alttext="\downarrow" class="ltx_Math" display="inline" id="A4.T7.1.1.1.1.m1.1"><semantics id="A4.T7.1.1.1.1.m1.1a"><mo id="A4.T7.1.1.1.1.m1.1.1" stretchy="false" xref="A4.T7.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A4.T7.1.1.1.1.m1.1b"><ci id="A4.T7.1.1.1.1.m1.1.1.cmml" xref="A4.T7.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T7.1.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="A4.T7.1.1.1.1.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T7.2.2.2.2" style="padding:0.75pt 6.5pt;">PSNR <math alttext="\uparrow" class="ltx_Math" display="inline" id="A4.T7.2.2.2.2.m1.1"><semantics id="A4.T7.2.2.2.2.m1.1a"><mo id="A4.T7.2.2.2.2.m1.1.1" stretchy="false" xref="A4.T7.2.2.2.2.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A4.T7.2.2.2.2.m1.1b"><ci id="A4.T7.2.2.2.2.m1.1.1.cmml" xref="A4.T7.2.2.2.2.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T7.2.2.2.2.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A4.T7.2.2.2.2.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T7.3.3.3.3" style="padding:0.75pt 6.5pt;">PSNR* <math alttext="\uparrow" class="ltx_Math" display="inline" id="A4.T7.3.3.3.3.m1.1"><semantics id="A4.T7.3.3.3.3.m1.1a"><mo id="A4.T7.3.3.3.3.m1.1.1" stretchy="false" xref="A4.T7.3.3.3.3.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A4.T7.3.3.3.3.m1.1b"><ci id="A4.T7.3.3.3.3.m1.1.1.cmml" xref="A4.T7.3.3.3.3.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T7.3.3.3.3.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A4.T7.3.3.3.3.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T7.4.4.4.4" style="padding:0.75pt 6.5pt;">SSIM <math alttext="\uparrow" class="ltx_Math" display="inline" id="A4.T7.4.4.4.4.m1.1"><semantics id="A4.T7.4.4.4.4.m1.1a"><mo id="A4.T7.4.4.4.4.m1.1.1" stretchy="false" xref="A4.T7.4.4.4.4.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A4.T7.4.4.4.4.m1.1b"><ci id="A4.T7.4.4.4.4.m1.1.1.cmml" xref="A4.T7.4.4.4.4.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T7.4.4.4.4.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A4.T7.4.4.4.4.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A4.T7.5.5.5.5" style="padding:0.75pt 6.5pt;">LPIPS <math alttext="\downarrow" class="ltx_Math" display="inline" id="A4.T7.5.5.5.5.m1.1"><semantics id="A4.T7.5.5.5.5.m1.1a"><mo id="A4.T7.5.5.5.5.m1.1.1" stretchy="false" xref="A4.T7.5.5.5.5.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A4.T7.5.5.5.5.m1.1b"><ci id="A4.T7.5.5.5.5.m1.1.1.cmml" xref="A4.T7.5.5.5.5.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T7.5.5.5.5.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="A4.T7.5.5.5.5.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T7.6.6.6.6" style="padding:0.75pt 6.5pt;">FVD <math alttext="\downarrow" class="ltx_Math" display="inline" id="A4.T7.6.6.6.6.m1.1"><semantics id="A4.T7.6.6.6.6.m1.1a"><mo id="A4.T7.6.6.6.6.m1.1.1" stretchy="false" xref="A4.T7.6.6.6.6.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A4.T7.6.6.6.6.m1.1b"><ci id="A4.T7.6.6.6.6.m1.1.1.cmml" xref="A4.T7.6.6.6.6.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T7.6.6.6.6.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="A4.T7.6.6.6.6.m1.1d">↓</annotation></semantics></math>
</td>
</tr>
<tr class="ltx_tr" id="A4.T7.7.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A4.T7.7.7.7.1" style="padding:0.75pt 6.5pt;">FOMM&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Siarohin et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib42" title="">2019a</a>)</cite> <math alttext="{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(NeurIPS19)}}}" class="ltx_Math" display="inline" id="A4.T7.7.7.7.1.m1.1"><semantics id="A4.T7.7.7.7.1.m1.1a"><msub id="A4.T7.7.7.7.1.m1.1.1" xref="A4.T7.7.7.7.1.m1.1.1.cmml"><mi id="A4.T7.7.7.7.1.m1.1.1a" xref="A4.T7.7.7.7.1.m1.1.1.cmml"></mi><mtext id="A4.T7.7.7.7.1.m1.1.1.1" mathcolor="#808080" xref="A4.T7.7.7.7.1.m1.1.1.1a.cmml">(NeurIPS19)</mtext></msub><annotation-xml encoding="MathML-Content" id="A4.T7.7.7.7.1.m1.1b"><apply id="A4.T7.7.7.7.1.m1.1.1.cmml" xref="A4.T7.7.7.7.1.m1.1.1"><ci id="A4.T7.7.7.7.1.m1.1.1.1a.cmml" xref="A4.T7.7.7.7.1.m1.1.1.1"><mtext id="A4.T7.7.7.7.1.m1.1.1.1.cmml" mathsize="70%" xref="A4.T7.7.7.7.1.m1.1.1.1">(NeurIPS19)</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T7.7.7.7.1.m1.1c">{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(NeurIPS19)}}}</annotation><annotation encoding="application/x-llamapun" id="A4.T7.7.7.7.1.m1.1d">start_FLOATSUBSCRIPT (NeurIPS19) end_FLOATSUBSCRIPT</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T7.7.7.7.2" style="padding:0.75pt 6.5pt;">3.61E-04</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T7.7.7.7.3" style="padding:0.75pt 6.5pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T7.7.7.7.4" style="padding:0.75pt 6.5pt;">17.26</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T7.7.7.7.5" style="padding:0.75pt 6.5pt;">0.648</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A4.T7.7.7.7.6" style="padding:0.75pt 6.5pt;">0.335</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T7.7.7.7.7" style="padding:0.75pt 6.5pt;">405.22</td>
</tr>
<tr class="ltx_tr" id="A4.T7.8.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A4.T7.8.8.8.1" style="padding:0.75pt 6.5pt;">MRAA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Siarohin et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib44" title="">2021a</a>)</cite> <math alttext="{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(CVPR21)}}}" class="ltx_Math" display="inline" id="A4.T7.8.8.8.1.m1.1"><semantics id="A4.T7.8.8.8.1.m1.1a"><msub id="A4.T7.8.8.8.1.m1.1.1" xref="A4.T7.8.8.8.1.m1.1.1.cmml"><mi id="A4.T7.8.8.8.1.m1.1.1a" xref="A4.T7.8.8.8.1.m1.1.1.cmml"></mi><mtext id="A4.T7.8.8.8.1.m1.1.1.1" mathcolor="#808080" xref="A4.T7.8.8.8.1.m1.1.1.1a.cmml">(CVPR21)</mtext></msub><annotation-xml encoding="MathML-Content" id="A4.T7.8.8.8.1.m1.1b"><apply id="A4.T7.8.8.8.1.m1.1.1.cmml" xref="A4.T7.8.8.8.1.m1.1.1"><ci id="A4.T7.8.8.8.1.m1.1.1.1a.cmml" xref="A4.T7.8.8.8.1.m1.1.1.1"><mtext id="A4.T7.8.8.8.1.m1.1.1.1.cmml" mathsize="70%" xref="A4.T7.8.8.8.1.m1.1.1.1">(CVPR21)</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T7.8.8.8.1.m1.1c">{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(CVPR21)}}}</annotation><annotation encoding="application/x-llamapun" id="A4.T7.8.8.8.1.m1.1d">start_FLOATSUBSCRIPT (CVPR21) end_FLOATSUBSCRIPT</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center" id="A4.T7.8.8.8.2" style="padding:0.75pt 6.5pt;">3.21E-04</td>
<td class="ltx_td ltx_align_center" id="A4.T7.8.8.8.3" style="padding:0.75pt 6.5pt;">-</td>
<td class="ltx_td ltx_align_center" id="A4.T7.8.8.8.4" style="padding:0.75pt 6.5pt;">18.14</td>
<td class="ltx_td ltx_align_center" id="A4.T7.8.8.8.5" style="padding:0.75pt 6.5pt;">0.672</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T7.8.8.8.6" style="padding:0.75pt 6.5pt;">0.296</td>
<td class="ltx_td ltx_align_center" id="A4.T7.8.8.8.7" style="padding:0.75pt 6.5pt;">284.82</td>
</tr>
<tr class="ltx_tr" id="A4.T7.9.9.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A4.T7.9.9.9.1" style="padding:0.75pt 6.5pt;">TPS&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Zhao &amp; Zhang (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib83" title="">2022a</a>)</cite> <math alttext="{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(CVPR22)}}}" class="ltx_Math" display="inline" id="A4.T7.9.9.9.1.m1.1"><semantics id="A4.T7.9.9.9.1.m1.1a"><msub id="A4.T7.9.9.9.1.m1.1.1" xref="A4.T7.9.9.9.1.m1.1.1.cmml"><mi id="A4.T7.9.9.9.1.m1.1.1a" xref="A4.T7.9.9.9.1.m1.1.1.cmml"></mi><mtext id="A4.T7.9.9.9.1.m1.1.1.1" mathcolor="#808080" xref="A4.T7.9.9.9.1.m1.1.1.1a.cmml">(CVPR22)</mtext></msub><annotation-xml encoding="MathML-Content" id="A4.T7.9.9.9.1.m1.1b"><apply id="A4.T7.9.9.9.1.m1.1.1.cmml" xref="A4.T7.9.9.9.1.m1.1.1"><ci id="A4.T7.9.9.9.1.m1.1.1.1a.cmml" xref="A4.T7.9.9.9.1.m1.1.1.1"><mtext id="A4.T7.9.9.9.1.m1.1.1.1.cmml" mathsize="70%" xref="A4.T7.9.9.9.1.m1.1.1.1">(CVPR22)</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T7.9.9.9.1.m1.1c">{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(CVPR22)}}}</annotation><annotation encoding="application/x-llamapun" id="A4.T7.9.9.9.1.m1.1d">start_FLOATSUBSCRIPT (CVPR22) end_FLOATSUBSCRIPT</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center" id="A4.T7.9.9.9.2" style="padding:0.75pt 6.5pt;">3.23E-04</td>
<td class="ltx_td ltx_align_center" id="A4.T7.9.9.9.3" style="padding:0.75pt 6.5pt;">-</td>
<td class="ltx_td ltx_align_center" id="A4.T7.9.9.9.4" style="padding:0.75pt 6.5pt;">18.32</td>
<td class="ltx_td ltx_align_center" id="A4.T7.9.9.9.5" style="padding:0.75pt 6.5pt;">0.673</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T7.9.9.9.6" style="padding:0.75pt 6.5pt;">0.299</td>
<td class="ltx_td ltx_align_center" id="A4.T7.9.9.9.7" style="padding:0.75pt 6.5pt;">306.17</td>
</tr>
<tr class="ltx_tr" id="A4.T7.10.10.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A4.T7.10.10.10.1" style="padding:0.75pt 6.5pt;">DreamPose&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Karras et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib26" title="">2023</a>)</cite> <math alttext="{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(ICCV23)}}}" class="ltx_Math" display="inline" id="A4.T7.10.10.10.1.m1.1"><semantics id="A4.T7.10.10.10.1.m1.1a"><msub id="A4.T7.10.10.10.1.m1.1.1" xref="A4.T7.10.10.10.1.m1.1.1.cmml"><mi id="A4.T7.10.10.10.1.m1.1.1a" xref="A4.T7.10.10.10.1.m1.1.1.cmml"></mi><mtext id="A4.T7.10.10.10.1.m1.1.1.1" mathcolor="#808080" xref="A4.T7.10.10.10.1.m1.1.1.1a.cmml">(ICCV23)</mtext></msub><annotation-xml encoding="MathML-Content" id="A4.T7.10.10.10.1.m1.1b"><apply id="A4.T7.10.10.10.1.m1.1.1.cmml" xref="A4.T7.10.10.10.1.m1.1.1"><ci id="A4.T7.10.10.10.1.m1.1.1.1a.cmml" xref="A4.T7.10.10.10.1.m1.1.1.1"><mtext id="A4.T7.10.10.10.1.m1.1.1.1.cmml" mathsize="70%" xref="A4.T7.10.10.10.1.m1.1.1.1">(ICCV23)</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T7.10.10.10.1.m1.1c">{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(ICCV23)}}}</annotation><annotation encoding="application/x-llamapun" id="A4.T7.10.10.10.1.m1.1d">start_FLOATSUBSCRIPT (ICCV23) end_FLOATSUBSCRIPT</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T7.10.10.10.2" style="padding:0.75pt 6.5pt;">6.88E-04</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T7.10.10.10.3" style="padding:0.75pt 6.5pt;">28.11</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T7.10.10.10.4" style="padding:0.75pt 6.5pt;">12.82</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T7.10.10.10.5" style="padding:0.75pt 6.5pt;">0.511</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A4.T7.10.10.10.6" style="padding:0.75pt 6.5pt;">0.442</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T7.10.10.10.7" style="padding:0.75pt 6.5pt;">551.02</td>
</tr>
<tr class="ltx_tr" id="A4.T7.11.11.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A4.T7.11.11.11.1" style="padding:0.75pt 6.5pt;">DisCo&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Wang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib59" title="">2024a</a>)</cite> <math alttext="{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(CVPR24)}}}" class="ltx_Math" display="inline" id="A4.T7.11.11.11.1.m1.1"><semantics id="A4.T7.11.11.11.1.m1.1a"><msub id="A4.T7.11.11.11.1.m1.1.1" xref="A4.T7.11.11.11.1.m1.1.1.cmml"><mi id="A4.T7.11.11.11.1.m1.1.1a" xref="A4.T7.11.11.11.1.m1.1.1.cmml"></mi><mtext id="A4.T7.11.11.11.1.m1.1.1.1" mathcolor="#808080" xref="A4.T7.11.11.11.1.m1.1.1.1a.cmml">(CVPR24)</mtext></msub><annotation-xml encoding="MathML-Content" id="A4.T7.11.11.11.1.m1.1b"><apply id="A4.T7.11.11.11.1.m1.1.1.cmml" xref="A4.T7.11.11.11.1.m1.1.1"><ci id="A4.T7.11.11.11.1.m1.1.1.1a.cmml" xref="A4.T7.11.11.11.1.m1.1.1.1"><mtext id="A4.T7.11.11.11.1.m1.1.1.1.cmml" mathsize="70%" xref="A4.T7.11.11.11.1.m1.1.1.1">(CVPR24)</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T7.11.11.11.1.m1.1c">{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(CVPR24)}}}</annotation><annotation encoding="application/x-llamapun" id="A4.T7.11.11.11.1.m1.1d">start_FLOATSUBSCRIPT (CVPR24) end_FLOATSUBSCRIPT</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center" id="A4.T7.11.11.11.2" style="padding:0.75pt 6.5pt;">3.78E-04</td>
<td class="ltx_td ltx_align_center" id="A4.T7.11.11.11.3" style="padding:0.75pt 6.5pt;">29.03</td>
<td class="ltx_td ltx_align_center" id="A4.T7.11.11.11.4" style="padding:0.75pt 6.5pt;">16.55</td>
<td class="ltx_td ltx_align_center" id="A4.T7.11.11.11.5" style="padding:0.75pt 6.5pt;">0.668</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T7.11.11.11.6" style="padding:0.75pt 6.5pt;">0.292</td>
<td class="ltx_td ltx_align_center" id="A4.T7.11.11.11.7" style="padding:0.75pt 6.5pt;">292.80</td>
</tr>
<tr class="ltx_tr" id="A4.T7.12.12.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A4.T7.12.12.12.1" style="padding:0.75pt 6.5pt;">MagicAnimate&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Xu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib68" title="">2023a</a>)</cite> <math alttext="{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(CVPR24)}}}" class="ltx_Math" display="inline" id="A4.T7.12.12.12.1.m1.1"><semantics id="A4.T7.12.12.12.1.m1.1a"><msub id="A4.T7.12.12.12.1.m1.1.1" xref="A4.T7.12.12.12.1.m1.1.1.cmml"><mi id="A4.T7.12.12.12.1.m1.1.1a" xref="A4.T7.12.12.12.1.m1.1.1.cmml"></mi><mtext id="A4.T7.12.12.12.1.m1.1.1.1" mathcolor="#808080" xref="A4.T7.12.12.12.1.m1.1.1.1a.cmml">(CVPR24)</mtext></msub><annotation-xml encoding="MathML-Content" id="A4.T7.12.12.12.1.m1.1b"><apply id="A4.T7.12.12.12.1.m1.1.1.cmml" xref="A4.T7.12.12.12.1.m1.1.1"><ci id="A4.T7.12.12.12.1.m1.1.1.1a.cmml" xref="A4.T7.12.12.12.1.m1.1.1.1"><mtext id="A4.T7.12.12.12.1.m1.1.1.1.cmml" mathsize="70%" xref="A4.T7.12.12.12.1.m1.1.1.1">(CVPR24)</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T7.12.12.12.1.m1.1c">{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(CVPR24)}}}</annotation><annotation encoding="application/x-llamapun" id="A4.T7.12.12.12.1.m1.1d">start_FLOATSUBSCRIPT (CVPR24) end_FLOATSUBSCRIPT</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center" id="A4.T7.12.12.12.2" style="padding:0.75pt 6.5pt;">3.13E-04</td>
<td class="ltx_td ltx_align_center" id="A4.T7.12.12.12.3" style="padding:0.75pt 6.5pt;">29.16</td>
<td class="ltx_td ltx_align_center" id="A4.T7.12.12.12.4" style="padding:0.75pt 6.5pt;">-</td>
<td class="ltx_td ltx_align_center" id="A4.T7.12.12.12.5" style="padding:0.75pt 6.5pt;">0.714</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T7.12.12.12.6" style="padding:0.75pt 6.5pt;">0.239</td>
<td class="ltx_td ltx_align_center" id="A4.T7.12.12.12.7" style="padding:0.75pt 6.5pt;">179.07</td>
</tr>
<tr class="ltx_tr" id="A4.T7.13.13.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A4.T7.13.13.13.1" style="padding:0.75pt 6.5pt;">Animate Anyone&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Hu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib21" title="">2023</a>)</cite> <math alttext="{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(CVPR24)}}}" class="ltx_Math" display="inline" id="A4.T7.13.13.13.1.m1.1"><semantics id="A4.T7.13.13.13.1.m1.1a"><msub id="A4.T7.13.13.13.1.m1.1.1" xref="A4.T7.13.13.13.1.m1.1.1.cmml"><mi id="A4.T7.13.13.13.1.m1.1.1a" xref="A4.T7.13.13.13.1.m1.1.1.cmml"></mi><mtext id="A4.T7.13.13.13.1.m1.1.1.1" mathcolor="#808080" xref="A4.T7.13.13.13.1.m1.1.1.1a.cmml">(CVPR24)</mtext></msub><annotation-xml encoding="MathML-Content" id="A4.T7.13.13.13.1.m1.1b"><apply id="A4.T7.13.13.13.1.m1.1.1.cmml" xref="A4.T7.13.13.13.1.m1.1.1"><ci id="A4.T7.13.13.13.1.m1.1.1.1a.cmml" xref="A4.T7.13.13.13.1.m1.1.1.1"><mtext id="A4.T7.13.13.13.1.m1.1.1.1.cmml" mathsize="70%" xref="A4.T7.13.13.13.1.m1.1.1.1">(CVPR24)</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T7.13.13.13.1.m1.1c">{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(CVPR24)}}}</annotation><annotation encoding="application/x-llamapun" id="A4.T7.13.13.13.1.m1.1d">start_FLOATSUBSCRIPT (CVPR24) end_FLOATSUBSCRIPT</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center" id="A4.T7.13.13.13.2" style="padding:0.75pt 6.5pt;">-</td>
<td class="ltx_td ltx_align_center" id="A4.T7.13.13.13.3" style="padding:0.75pt 6.5pt;">29.56</td>
<td class="ltx_td ltx_align_center" id="A4.T7.13.13.13.4" style="padding:0.75pt 6.5pt;">-</td>
<td class="ltx_td ltx_align_center" id="A4.T7.13.13.13.5" style="padding:0.75pt 6.5pt;">0.718</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T7.13.13.13.6" style="padding:0.75pt 6.5pt;">0.285</td>
<td class="ltx_td ltx_align_center" id="A4.T7.13.13.13.7" style="padding:0.75pt 6.5pt;">171.90</td>
</tr>
<tr class="ltx_tr" id="A4.T7.14.14.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A4.T7.14.14.14.1" style="padding:0.75pt 6.5pt;">Champ&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Zhu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib86" title="">2024</a>)</cite> <math alttext="{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(ECCV24)}}}" class="ltx_Math" display="inline" id="A4.T7.14.14.14.1.m1.1"><semantics id="A4.T7.14.14.14.1.m1.1a"><msub id="A4.T7.14.14.14.1.m1.1.1" xref="A4.T7.14.14.14.1.m1.1.1.cmml"><mi id="A4.T7.14.14.14.1.m1.1.1a" xref="A4.T7.14.14.14.1.m1.1.1.cmml"></mi><mtext id="A4.T7.14.14.14.1.m1.1.1.1" mathcolor="#808080" xref="A4.T7.14.14.14.1.m1.1.1.1a.cmml">(ECCV24)</mtext></msub><annotation-xml encoding="MathML-Content" id="A4.T7.14.14.14.1.m1.1b"><apply id="A4.T7.14.14.14.1.m1.1.1.cmml" xref="A4.T7.14.14.14.1.m1.1.1"><ci id="A4.T7.14.14.14.1.m1.1.1.1a.cmml" xref="A4.T7.14.14.14.1.m1.1.1.1"><mtext id="A4.T7.14.14.14.1.m1.1.1.1.cmml" mathsize="70%" xref="A4.T7.14.14.14.1.m1.1.1.1">(ECCV24)</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T7.14.14.14.1.m1.1c">{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(ECCV24)}}}</annotation><annotation encoding="application/x-llamapun" id="A4.T7.14.14.14.1.m1.1d">start_FLOATSUBSCRIPT (ECCV24) end_FLOATSUBSCRIPT</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center" id="A4.T7.14.14.14.2" style="padding:0.75pt 6.5pt;">2.94E-04</td>
<td class="ltx_td ltx_align_center" id="A4.T7.14.14.14.3" style="padding:0.75pt 6.5pt;">29.91</td>
<td class="ltx_td ltx_align_center" id="A4.T7.14.14.14.4" style="padding:0.75pt 6.5pt;">-</td>
<td class="ltx_td ltx_align_center" id="A4.T7.14.14.14.5" style="padding:0.75pt 6.5pt;">0.802</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T7.14.14.14.6" style="padding:0.75pt 6.5pt;">0.234</td>
<td class="ltx_td ltx_align_center" id="A4.T7.14.14.14.7" style="padding:0.75pt 6.5pt;">160.82</td>
</tr>
<tr class="ltx_tr" id="A4.T7.15.15.15">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A4.T7.15.15.15.1" style="padding:0.75pt 6.5pt;">Unianimate&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Wang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib61" title="">2024b</a>)</cite> <math alttext="{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(ArXiv24)}}}" class="ltx_Math" display="inline" id="A4.T7.15.15.15.1.m1.1"><semantics id="A4.T7.15.15.15.1.m1.1a"><msub id="A4.T7.15.15.15.1.m1.1.1" xref="A4.T7.15.15.15.1.m1.1.1.cmml"><mi id="A4.T7.15.15.15.1.m1.1.1a" xref="A4.T7.15.15.15.1.m1.1.1.cmml"></mi><mtext id="A4.T7.15.15.15.1.m1.1.1.1" mathcolor="#808080" xref="A4.T7.15.15.15.1.m1.1.1.1a.cmml">(ArXiv24)</mtext></msub><annotation-xml encoding="MathML-Content" id="A4.T7.15.15.15.1.m1.1b"><apply id="A4.T7.15.15.15.1.m1.1.1.cmml" xref="A4.T7.15.15.15.1.m1.1.1"><ci id="A4.T7.15.15.15.1.m1.1.1.1a.cmml" xref="A4.T7.15.15.15.1.m1.1.1.1"><mtext id="A4.T7.15.15.15.1.m1.1.1.1.cmml" mathsize="70%" xref="A4.T7.15.15.15.1.m1.1.1.1">(ArXiv24)</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T7.15.15.15.1.m1.1c">{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(ArXiv24)}}}</annotation><annotation encoding="application/x-llamapun" id="A4.T7.15.15.15.1.m1.1d">start_FLOATSUBSCRIPT (ArXiv24) end_FLOATSUBSCRIPT</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center" id="A4.T7.15.15.15.2" style="padding:0.75pt 6.5pt;"><span class="ltx_text ltx_font_bold" id="A4.T7.15.15.15.2.1">2.66E-04</span></td>
<td class="ltx_td ltx_align_center" id="A4.T7.15.15.15.3" style="padding:0.75pt 6.5pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="A4.T7.15.15.15.3.1">30.77</span></td>
<td class="ltx_td ltx_align_center" id="A4.T7.15.15.15.4" style="padding:0.75pt 6.5pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="A4.T7.15.15.15.4.1">20.58</span></td>
<td class="ltx_td ltx_align_center" id="A4.T7.15.15.15.5" style="padding:0.75pt 6.5pt;"><span class="ltx_text ltx_font_bold" id="A4.T7.15.15.15.5.1">0.811</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T7.15.15.15.6" style="padding:0.75pt 6.5pt;"><span class="ltx_text ltx_font_bold" id="A4.T7.15.15.15.6.1">0.231</span></td>
<td class="ltx_td ltx_align_center" id="A4.T7.15.15.15.7" style="padding:0.75pt 6.5pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="A4.T7.15.15.15.7.1">148.06</span></td>
</tr>
<tr class="ltx_tr" id="A4.T7.16.16.16">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A4.T7.16.16.16.1" style="padding:0.75pt 6.5pt;">MusePose&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Tong et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib54" title="">2024</a>)</cite> <math alttext="{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(ArXiv24)}}}" class="ltx_Math" display="inline" id="A4.T7.16.16.16.1.m1.1"><semantics id="A4.T7.16.16.16.1.m1.1a"><msub id="A4.T7.16.16.16.1.m1.1.1" xref="A4.T7.16.16.16.1.m1.1.1.cmml"><mi id="A4.T7.16.16.16.1.m1.1.1a" xref="A4.T7.16.16.16.1.m1.1.1.cmml"></mi><mtext id="A4.T7.16.16.16.1.m1.1.1.1" mathcolor="#808080" xref="A4.T7.16.16.16.1.m1.1.1.1a.cmml">(ArXiv24)</mtext></msub><annotation-xml encoding="MathML-Content" id="A4.T7.16.16.16.1.m1.1b"><apply id="A4.T7.16.16.16.1.m1.1.1.cmml" xref="A4.T7.16.16.16.1.m1.1.1"><ci id="A4.T7.16.16.16.1.m1.1.1.1a.cmml" xref="A4.T7.16.16.16.1.m1.1.1.1"><mtext id="A4.T7.16.16.16.1.m1.1.1.1.cmml" mathsize="70%" xref="A4.T7.16.16.16.1.m1.1.1.1">(ArXiv24)</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T7.16.16.16.1.m1.1c">{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(ArXiv24)}}}</annotation><annotation encoding="application/x-llamapun" id="A4.T7.16.16.16.1.m1.1d">start_FLOATSUBSCRIPT (ArXiv24) end_FLOATSUBSCRIPT</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center" id="A4.T7.16.16.16.2" style="padding:0.75pt 6.5pt;">3.86E-04</td>
<td class="ltx_td ltx_align_center" id="A4.T7.16.16.16.3" style="padding:0.75pt 6.5pt;">-</td>
<td class="ltx_td ltx_align_center" id="A4.T7.16.16.16.4" style="padding:0.75pt 6.5pt;">17.67</td>
<td class="ltx_td ltx_align_center" id="A4.T7.16.16.16.5" style="padding:0.75pt 6.5pt;">0.744</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T7.16.16.16.6" style="padding:0.75pt 6.5pt;">0.297</td>
<td class="ltx_td ltx_align_center" id="A4.T7.16.16.16.7" style="padding:0.75pt 6.5pt;">215.72</td>
</tr>
<tr class="ltx_tr" id="A4.T7.17.17.17">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A4.T7.17.17.17.1" style="padding:0.75pt 6.5pt;">MimicMotion&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Zhang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib82" title="">2024</a>)</cite> <math alttext="{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(ArXiv24)}}}" class="ltx_Math" display="inline" id="A4.T7.17.17.17.1.m1.1"><semantics id="A4.T7.17.17.17.1.m1.1a"><msub id="A4.T7.17.17.17.1.m1.1.1" xref="A4.T7.17.17.17.1.m1.1.1.cmml"><mi id="A4.T7.17.17.17.1.m1.1.1a" xref="A4.T7.17.17.17.1.m1.1.1.cmml"></mi><mtext id="A4.T7.17.17.17.1.m1.1.1.1" mathcolor="#808080" xref="A4.T7.17.17.17.1.m1.1.1.1a.cmml">(ArXiv24)</mtext></msub><annotation-xml encoding="MathML-Content" id="A4.T7.17.17.17.1.m1.1b"><apply id="A4.T7.17.17.17.1.m1.1.1.cmml" xref="A4.T7.17.17.17.1.m1.1.1"><ci id="A4.T7.17.17.17.1.m1.1.1.1a.cmml" xref="A4.T7.17.17.17.1.m1.1.1.1"><mtext id="A4.T7.17.17.17.1.m1.1.1.1.cmml" mathsize="70%" xref="A4.T7.17.17.17.1.m1.1.1.1">(ArXiv24)</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T7.17.17.17.1.m1.1c">{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(ArXiv24)}}}</annotation><annotation encoding="application/x-llamapun" id="A4.T7.17.17.17.1.m1.1d">start_FLOATSUBSCRIPT (ArXiv24) end_FLOATSUBSCRIPT</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center" id="A4.T7.17.17.17.2" style="padding:0.75pt 6.5pt;">5.85E-04</td>
<td class="ltx_td ltx_align_center" id="A4.T7.17.17.17.3" style="padding:0.75pt 6.5pt;">-</td>
<td class="ltx_td ltx_align_center" id="A4.T7.17.17.17.4" style="padding:0.75pt 6.5pt;">14.44</td>
<td class="ltx_td ltx_align_center" id="A4.T7.17.17.17.5" style="padding:0.75pt 6.5pt;">0.601</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T7.17.17.17.6" style="padding:0.75pt 6.5pt;">0.414</td>
<td class="ltx_td ltx_align_center" id="A4.T7.17.17.17.7" style="padding:0.75pt 6.5pt;">232.95</td>
</tr>
<tr class="ltx_tr" id="A4.T7.18.18.18">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A4.T7.18.18.18.1" style="padding:0.75pt 6.5pt;">ControlNeXt&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Peng et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib34" title="">2024</a>)</cite> <math alttext="{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(ArXiv24)}}}" class="ltx_Math" display="inline" id="A4.T7.18.18.18.1.m1.1"><semantics id="A4.T7.18.18.18.1.m1.1a"><msub id="A4.T7.18.18.18.1.m1.1.1" xref="A4.T7.18.18.18.1.m1.1.1.cmml"><mi id="A4.T7.18.18.18.1.m1.1.1a" xref="A4.T7.18.18.18.1.m1.1.1.cmml"></mi><mtext id="A4.T7.18.18.18.1.m1.1.1.1" mathcolor="#808080" xref="A4.T7.18.18.18.1.m1.1.1.1a.cmml">(ArXiv24)</mtext></msub><annotation-xml encoding="MathML-Content" id="A4.T7.18.18.18.1.m1.1b"><apply id="A4.T7.18.18.18.1.m1.1.1.cmml" xref="A4.T7.18.18.18.1.m1.1.1"><ci id="A4.T7.18.18.18.1.m1.1.1.1a.cmml" xref="A4.T7.18.18.18.1.m1.1.1.1"><mtext id="A4.T7.18.18.18.1.m1.1.1.1.cmml" mathsize="70%" xref="A4.T7.18.18.18.1.m1.1.1.1">(ArXiv24)</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T7.18.18.18.1.m1.1c">{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(ArXiv24)}}}</annotation><annotation encoding="application/x-llamapun" id="A4.T7.18.18.18.1.m1.1d">start_FLOATSUBSCRIPT (ArXiv24) end_FLOATSUBSCRIPT</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center" id="A4.T7.18.18.18.2" style="padding:0.75pt 6.5pt;">6.20E-04</td>
<td class="ltx_td ltx_align_center" id="A4.T7.18.18.18.3" style="padding:0.75pt 6.5pt;">-</td>
<td class="ltx_td ltx_align_center" id="A4.T7.18.18.18.4" style="padding:0.75pt 6.5pt;">13.83</td>
<td class="ltx_td ltx_align_center" id="A4.T7.18.18.18.5" style="padding:0.75pt 6.5pt;">0.615</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T7.18.18.18.6" style="padding:0.75pt 6.5pt;">0.416</td>
<td class="ltx_td ltx_align_center" id="A4.T7.18.18.18.7" style="padding:0.75pt 6.5pt;">326.57</td>
</tr>
<tr class="ltx_tr" id="A4.T7.18.18.19.1" style="background-color:#F0F0F0;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r" id="A4.T7.18.18.19.1.1" style="padding:0.75pt 6.5pt;"><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="A4.T7.18.18.19.1.1.1" style="background-color:#F0F0F0;">Animate-X</span></th>
<td class="ltx_td ltx_align_center ltx_border_b" id="A4.T7.18.18.19.1.2" style="padding:0.75pt 6.5pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="A4.T7.18.18.19.1.2.1" style="background-color:#F0F0F0;">2.70E-04</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A4.T7.18.18.19.1.3" style="padding:0.75pt 6.5pt;"><span class="ltx_text ltx_font_bold" id="A4.T7.18.18.19.1.3.1" style="background-color:#F0F0F0;">30.78</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A4.T7.18.18.19.1.4" style="padding:0.75pt 6.5pt;"><span class="ltx_text ltx_font_bold" id="A4.T7.18.18.19.1.4.1" style="background-color:#F0F0F0;">20.77</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A4.T7.18.18.19.1.5" style="padding:0.75pt 6.5pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="A4.T7.18.18.19.1.5.1" style="background-color:#F0F0F0;">0.806</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="A4.T7.18.18.19.1.6" style="padding:0.75pt 6.5pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="A4.T7.18.18.19.1.6.1" style="background-color:#F0F0F0;">0.232</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A4.T7.18.18.19.1.7" style="padding:0.75pt 6.5pt;"><span class="ltx_text ltx_font_bold" id="A4.T7.18.18.19.1.7.1" style="background-color:#F0F0F0;">139.01</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span>
Quantitative comparisons with existing methods on TikTok dataset.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="A4.T8">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A4.T8.16" style="width:433.6pt;height:152.4pt;vertical-align:-0.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-117.4pt,41.1pt) scale(0.648659274401098,0.648659274401098) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A4.T8.16.16">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A4.T8.5.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" id="A4.T8.5.5.5.6" style="padding:0.75pt 8.5pt;">Method</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A4.T8.1.1.1.1" style="padding:0.75pt 8.5pt;">PSNR <math alttext="\uparrow" class="ltx_Math" display="inline" id="A4.T8.1.1.1.1.m1.1"><semantics id="A4.T8.1.1.1.1.m1.1a"><mo id="A4.T8.1.1.1.1.m1.1.1" stretchy="false" xref="A4.T8.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A4.T8.1.1.1.1.m1.1b"><ci id="A4.T8.1.1.1.1.m1.1.1.cmml" xref="A4.T8.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T8.1.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A4.T8.1.1.1.1.m1.1d">↑</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A4.T8.2.2.2.2" style="padding:0.75pt 8.5pt;">PSNR* <math alttext="\uparrow" class="ltx_Math" display="inline" id="A4.T8.2.2.2.2.m1.1"><semantics id="A4.T8.2.2.2.2.m1.1a"><mo id="A4.T8.2.2.2.2.m1.1.1" stretchy="false" xref="A4.T8.2.2.2.2.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A4.T8.2.2.2.2.m1.1b"><ci id="A4.T8.2.2.2.2.m1.1.1.cmml" xref="A4.T8.2.2.2.2.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T8.2.2.2.2.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A4.T8.2.2.2.2.m1.1d">↑</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A4.T8.3.3.3.3" style="padding:0.75pt 8.5pt;">SSIM <math alttext="\uparrow" class="ltx_Math" display="inline" id="A4.T8.3.3.3.3.m1.1"><semantics id="A4.T8.3.3.3.3.m1.1a"><mo id="A4.T8.3.3.3.3.m1.1.1" stretchy="false" xref="A4.T8.3.3.3.3.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A4.T8.3.3.3.3.m1.1b"><ci id="A4.T8.3.3.3.3.m1.1.1.cmml" xref="A4.T8.3.3.3.3.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T8.3.3.3.3.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A4.T8.3.3.3.3.m1.1d">↑</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A4.T8.4.4.4.4" style="padding:0.75pt 8.5pt;">LPIPS <math alttext="\downarrow" class="ltx_Math" display="inline" id="A4.T8.4.4.4.4.m1.1"><semantics id="A4.T8.4.4.4.4.m1.1a"><mo id="A4.T8.4.4.4.4.m1.1.1" stretchy="false" xref="A4.T8.4.4.4.4.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A4.T8.4.4.4.4.m1.1b"><ci id="A4.T8.4.4.4.4.m1.1.1.cmml" xref="A4.T8.4.4.4.4.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T8.4.4.4.4.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="A4.T8.4.4.4.4.m1.1d">↓</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A4.T8.5.5.5.5" style="padding:0.75pt 8.5pt;">FVD <math alttext="\downarrow" class="ltx_Math" display="inline" id="A4.T8.5.5.5.5.m1.1"><semantics id="A4.T8.5.5.5.5.m1.1a"><mo id="A4.T8.5.5.5.5.m1.1.1" stretchy="false" xref="A4.T8.5.5.5.5.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A4.T8.5.5.5.5.m1.1b"><ci id="A4.T8.5.5.5.5.m1.1.1.cmml" xref="A4.T8.5.5.5.5.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T8.5.5.5.5.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="A4.T8.5.5.5.5.m1.1d">↓</annotation></semantics></math>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A4.T8.6.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A4.T8.6.6.6.1" style="padding:0.75pt 8.5pt;">MRAA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Siarohin et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib44" title="">2021a</a>)</cite> <math alttext="{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(CVPR21)}}}" class="ltx_Math" display="inline" id="A4.T8.6.6.6.1.m1.1"><semantics id="A4.T8.6.6.6.1.m1.1a"><msub id="A4.T8.6.6.6.1.m1.1.1" xref="A4.T8.6.6.6.1.m1.1.1.cmml"><mi id="A4.T8.6.6.6.1.m1.1.1a" xref="A4.T8.6.6.6.1.m1.1.1.cmml"></mi><mtext id="A4.T8.6.6.6.1.m1.1.1.1" mathcolor="#808080" xref="A4.T8.6.6.6.1.m1.1.1.1a.cmml">(CVPR21)</mtext></msub><annotation-xml encoding="MathML-Content" id="A4.T8.6.6.6.1.m1.1b"><apply id="A4.T8.6.6.6.1.m1.1.1.cmml" xref="A4.T8.6.6.6.1.m1.1.1"><ci id="A4.T8.6.6.6.1.m1.1.1.1a.cmml" xref="A4.T8.6.6.6.1.m1.1.1.1"><mtext id="A4.T8.6.6.6.1.m1.1.1.1.cmml" mathsize="70%" xref="A4.T8.6.6.6.1.m1.1.1.1">(CVPR21)</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T8.6.6.6.1.m1.1c">{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(CVPR21)}}}</annotation><annotation encoding="application/x-llamapun" id="A4.T8.6.6.6.1.m1.1d">start_FLOATSUBSCRIPT (CVPR21) end_FLOATSUBSCRIPT</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T8.6.6.6.2" style="padding:0.75pt 8.5pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T8.6.6.6.3" style="padding:0.75pt 8.5pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T8.6.6.6.4" style="padding:0.75pt 8.5pt;">0.749</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A4.T8.6.6.6.5" style="padding:0.75pt 8.5pt;">0.212</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T8.6.6.6.6" style="padding:0.75pt 8.5pt;">253.6</td>
</tr>
<tr class="ltx_tr" id="A4.T8.7.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A4.T8.7.7.7.1" style="padding:0.75pt 8.5pt;">TPS&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Zhao &amp; Zhang (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib83" title="">2022a</a>)</cite> <math alttext="{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(CVPR22)}}}" class="ltx_Math" display="inline" id="A4.T8.7.7.7.1.m1.1"><semantics id="A4.T8.7.7.7.1.m1.1a"><msub id="A4.T8.7.7.7.1.m1.1.1" xref="A4.T8.7.7.7.1.m1.1.1.cmml"><mi id="A4.T8.7.7.7.1.m1.1.1a" xref="A4.T8.7.7.7.1.m1.1.1.cmml"></mi><mtext id="A4.T8.7.7.7.1.m1.1.1.1" mathcolor="#808080" xref="A4.T8.7.7.7.1.m1.1.1.1a.cmml">(CVPR22)</mtext></msub><annotation-xml encoding="MathML-Content" id="A4.T8.7.7.7.1.m1.1b"><apply id="A4.T8.7.7.7.1.m1.1.1.cmml" xref="A4.T8.7.7.7.1.m1.1.1"><ci id="A4.T8.7.7.7.1.m1.1.1.1a.cmml" xref="A4.T8.7.7.7.1.m1.1.1.1"><mtext id="A4.T8.7.7.7.1.m1.1.1.1.cmml" mathsize="70%" xref="A4.T8.7.7.7.1.m1.1.1.1">(CVPR22)</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T8.7.7.7.1.m1.1c">{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(CVPR22)}}}</annotation><annotation encoding="application/x-llamapun" id="A4.T8.7.7.7.1.m1.1d">start_FLOATSUBSCRIPT (CVPR22) end_FLOATSUBSCRIPT</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center" id="A4.T8.7.7.7.2" style="padding:0.75pt 8.5pt;">-</td>
<td class="ltx_td ltx_align_center" id="A4.T8.7.7.7.3" style="padding:0.75pt 8.5pt;">-</td>
<td class="ltx_td ltx_align_center" id="A4.T8.7.7.7.4" style="padding:0.75pt 8.5pt;">0.746</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T8.7.7.7.5" style="padding:0.75pt 8.5pt;">0.213</td>
<td class="ltx_td ltx_align_center" id="A4.T8.7.7.7.6" style="padding:0.75pt 8.5pt;">247.5</td>
</tr>
<tr class="ltx_tr" id="A4.T8.8.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A4.T8.8.8.8.1" style="padding:0.75pt 8.5pt;">DPTN&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Zhang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib79" title="">2022a</a>)</cite> <math alttext="{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(CVPR22)}}}" class="ltx_Math" display="inline" id="A4.T8.8.8.8.1.m1.1"><semantics id="A4.T8.8.8.8.1.m1.1a"><msub id="A4.T8.8.8.8.1.m1.1.1" xref="A4.T8.8.8.8.1.m1.1.1.cmml"><mi id="A4.T8.8.8.8.1.m1.1.1a" xref="A4.T8.8.8.8.1.m1.1.1.cmml"></mi><mtext id="A4.T8.8.8.8.1.m1.1.1.1" mathcolor="#808080" xref="A4.T8.8.8.8.1.m1.1.1.1a.cmml">(CVPR22)</mtext></msub><annotation-xml encoding="MathML-Content" id="A4.T8.8.8.8.1.m1.1b"><apply id="A4.T8.8.8.8.1.m1.1.1.cmml" xref="A4.T8.8.8.8.1.m1.1.1"><ci id="A4.T8.8.8.8.1.m1.1.1.1a.cmml" xref="A4.T8.8.8.8.1.m1.1.1.1"><mtext id="A4.T8.8.8.8.1.m1.1.1.1.cmml" mathsize="70%" xref="A4.T8.8.8.8.1.m1.1.1.1">(CVPR22)</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T8.8.8.8.1.m1.1c">{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(CVPR22)}}}</annotation><annotation encoding="application/x-llamapun" id="A4.T8.8.8.8.1.m1.1d">start_FLOATSUBSCRIPT (CVPR22) end_FLOATSUBSCRIPT</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center" id="A4.T8.8.8.8.2" style="padding:0.75pt 8.5pt;">-</td>
<td class="ltx_td ltx_align_center" id="A4.T8.8.8.8.3" style="padding:0.75pt 8.5pt;">24.00</td>
<td class="ltx_td ltx_align_center" id="A4.T8.8.8.8.4" style="padding:0.75pt 8.5pt;">0.907</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T8.8.8.8.5" style="padding:0.75pt 8.5pt;">0.060</td>
<td class="ltx_td ltx_align_center" id="A4.T8.8.8.8.6" style="padding:0.75pt 8.5pt;">215.1</td>
</tr>
<tr class="ltx_tr" id="A4.T8.9.9.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A4.T8.9.9.9.1" style="padding:0.75pt 8.5pt;">NTED&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Ren et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib38" title="">2022</a>)</cite> <math alttext="{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(CVPR22)}}}" class="ltx_Math" display="inline" id="A4.T8.9.9.9.1.m1.1"><semantics id="A4.T8.9.9.9.1.m1.1a"><msub id="A4.T8.9.9.9.1.m1.1.1" xref="A4.T8.9.9.9.1.m1.1.1.cmml"><mi id="A4.T8.9.9.9.1.m1.1.1a" xref="A4.T8.9.9.9.1.m1.1.1.cmml"></mi><mtext id="A4.T8.9.9.9.1.m1.1.1.1" mathcolor="#808080" xref="A4.T8.9.9.9.1.m1.1.1.1a.cmml">(CVPR22)</mtext></msub><annotation-xml encoding="MathML-Content" id="A4.T8.9.9.9.1.m1.1b"><apply id="A4.T8.9.9.9.1.m1.1.1.cmml" xref="A4.T8.9.9.9.1.m1.1.1"><ci id="A4.T8.9.9.9.1.m1.1.1.1a.cmml" xref="A4.T8.9.9.9.1.m1.1.1.1"><mtext id="A4.T8.9.9.9.1.m1.1.1.1.cmml" mathsize="70%" xref="A4.T8.9.9.9.1.m1.1.1.1">(CVPR22)</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T8.9.9.9.1.m1.1c">{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(CVPR22)}}}</annotation><annotation encoding="application/x-llamapun" id="A4.T8.9.9.9.1.m1.1d">start_FLOATSUBSCRIPT (CVPR22) end_FLOATSUBSCRIPT</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center" id="A4.T8.9.9.9.2" style="padding:0.75pt 8.5pt;">-</td>
<td class="ltx_td ltx_align_center" id="A4.T8.9.9.9.3" style="padding:0.75pt 8.5pt;">22.03</td>
<td class="ltx_td ltx_align_center" id="A4.T8.9.9.9.4" style="padding:0.75pt 8.5pt;">0.890</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T8.9.9.9.5" style="padding:0.75pt 8.5pt;">0.073</td>
<td class="ltx_td ltx_align_center" id="A4.T8.9.9.9.6" style="padding:0.75pt 8.5pt;">278.9</td>
</tr>
<tr class="ltx_tr" id="A4.T8.10.10.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A4.T8.10.10.10.1" style="padding:0.75pt 8.5pt;">PIDM&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Bhunia et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib4" title="">2023</a>)</cite> <math alttext="{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(CVPR23)}}}" class="ltx_Math" display="inline" id="A4.T8.10.10.10.1.m1.1"><semantics id="A4.T8.10.10.10.1.m1.1a"><msub id="A4.T8.10.10.10.1.m1.1.1" xref="A4.T8.10.10.10.1.m1.1.1.cmml"><mi id="A4.T8.10.10.10.1.m1.1.1a" xref="A4.T8.10.10.10.1.m1.1.1.cmml"></mi><mtext id="A4.T8.10.10.10.1.m1.1.1.1" mathcolor="#808080" xref="A4.T8.10.10.10.1.m1.1.1.1a.cmml">(CVPR23)</mtext></msub><annotation-xml encoding="MathML-Content" id="A4.T8.10.10.10.1.m1.1b"><apply id="A4.T8.10.10.10.1.m1.1.1.cmml" xref="A4.T8.10.10.10.1.m1.1.1"><ci id="A4.T8.10.10.10.1.m1.1.1.1a.cmml" xref="A4.T8.10.10.10.1.m1.1.1.1"><mtext id="A4.T8.10.10.10.1.m1.1.1.1.cmml" mathsize="70%" xref="A4.T8.10.10.10.1.m1.1.1.1">(CVPR23)</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T8.10.10.10.1.m1.1c">{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(CVPR23)}}}</annotation><annotation encoding="application/x-llamapun" id="A4.T8.10.10.10.1.m1.1d">start_FLOATSUBSCRIPT (CVPR23) end_FLOATSUBSCRIPT</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center" id="A4.T8.10.10.10.2" style="padding:0.75pt 8.5pt;">-</td>
<td class="ltx_td ltx_align_center" id="A4.T8.10.10.10.3" style="padding:0.75pt 8.5pt;">-</td>
<td class="ltx_td ltx_align_center" id="A4.T8.10.10.10.4" style="padding:0.75pt 8.5pt;">0.713</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T8.10.10.10.5" style="padding:0.75pt 8.5pt;">0.288</td>
<td class="ltx_td ltx_align_center" id="A4.T8.10.10.10.6" style="padding:0.75pt 8.5pt;">1197.4</td>
</tr>
<tr class="ltx_tr" id="A4.T8.11.11.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A4.T8.11.11.11.1" style="padding:0.75pt 8.5pt;">DBMM&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Yu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib72" title="">2023</a>)</cite> <math alttext="{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(ICCV23)}}}" class="ltx_Math" display="inline" id="A4.T8.11.11.11.1.m1.1"><semantics id="A4.T8.11.11.11.1.m1.1a"><msub id="A4.T8.11.11.11.1.m1.1.1" xref="A4.T8.11.11.11.1.m1.1.1.cmml"><mi id="A4.T8.11.11.11.1.m1.1.1a" xref="A4.T8.11.11.11.1.m1.1.1.cmml"></mi><mtext id="A4.T8.11.11.11.1.m1.1.1.1" mathcolor="#808080" xref="A4.T8.11.11.11.1.m1.1.1.1a.cmml">(ICCV23)</mtext></msub><annotation-xml encoding="MathML-Content" id="A4.T8.11.11.11.1.m1.1b"><apply id="A4.T8.11.11.11.1.m1.1.1.cmml" xref="A4.T8.11.11.11.1.m1.1.1"><ci id="A4.T8.11.11.11.1.m1.1.1.1a.cmml" xref="A4.T8.11.11.11.1.m1.1.1.1"><mtext id="A4.T8.11.11.11.1.m1.1.1.1.cmml" mathsize="70%" xref="A4.T8.11.11.11.1.m1.1.1.1">(ICCV23)</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T8.11.11.11.1.m1.1c">{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(ICCV23)}}}</annotation><annotation encoding="application/x-llamapun" id="A4.T8.11.11.11.1.m1.1d">start_FLOATSUBSCRIPT (ICCV23) end_FLOATSUBSCRIPT</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center" id="A4.T8.11.11.11.2" style="padding:0.75pt 8.5pt;">-</td>
<td class="ltx_td ltx_align_center" id="A4.T8.11.11.11.3" style="padding:0.75pt 8.5pt;">24.07</td>
<td class="ltx_td ltx_align_center" id="A4.T8.11.11.11.4" style="padding:0.75pt 8.5pt;">0.918</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T8.11.11.11.5" style="padding:0.75pt 8.5pt;">0.048</td>
<td class="ltx_td ltx_align_center" id="A4.T8.11.11.11.6" style="padding:0.75pt 8.5pt;">168.3</td>
</tr>
<tr class="ltx_tr" id="A4.T8.12.12.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A4.T8.12.12.12.1" style="padding:0.75pt 8.5pt;">DreamPose&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Karras et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib26" title="">2023</a>)</cite> <math alttext="{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(ICCV23)}}}" class="ltx_Math" display="inline" id="A4.T8.12.12.12.1.m1.1"><semantics id="A4.T8.12.12.12.1.m1.1a"><msub id="A4.T8.12.12.12.1.m1.1.1" xref="A4.T8.12.12.12.1.m1.1.1.cmml"><mi id="A4.T8.12.12.12.1.m1.1.1a" xref="A4.T8.12.12.12.1.m1.1.1.cmml"></mi><mtext id="A4.T8.12.12.12.1.m1.1.1.1" mathcolor="#808080" xref="A4.T8.12.12.12.1.m1.1.1.1a.cmml">(ICCV23)</mtext></msub><annotation-xml encoding="MathML-Content" id="A4.T8.12.12.12.1.m1.1b"><apply id="A4.T8.12.12.12.1.m1.1.1.cmml" xref="A4.T8.12.12.12.1.m1.1.1"><ci id="A4.T8.12.12.12.1.m1.1.1.1a.cmml" xref="A4.T8.12.12.12.1.m1.1.1.1"><mtext id="A4.T8.12.12.12.1.m1.1.1.1.cmml" mathsize="70%" xref="A4.T8.12.12.12.1.m1.1.1.1">(ICCV23)</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T8.12.12.12.1.m1.1c">{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(ICCV23)}}}</annotation><annotation encoding="application/x-llamapun" id="A4.T8.12.12.12.1.m1.1d">start_FLOATSUBSCRIPT (ICCV23) end_FLOATSUBSCRIPT</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T8.12.12.12.2" style="padding:0.75pt 8.5pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T8.12.12.12.3" style="padding:0.75pt 8.5pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T8.12.12.12.4" style="padding:0.75pt 8.5pt;">0.885</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A4.T8.12.12.12.5" style="padding:0.75pt 8.5pt;">0.068</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T8.12.12.12.6" style="padding:0.75pt 8.5pt;">238.7</td>
</tr>
<tr class="ltx_tr" id="A4.T8.13.13.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A4.T8.13.13.13.1" style="padding:0.75pt 8.5pt;">DreamPose <em class="ltx_emph ltx_font_italic" id="A4.T8.13.13.13.1.1">w/o Finetune</em>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Karras et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib26" title="">2023</a>)</cite> <math alttext="{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(ICCV23)}}}" class="ltx_Math" display="inline" id="A4.T8.13.13.13.1.m1.1"><semantics id="A4.T8.13.13.13.1.m1.1a"><msub id="A4.T8.13.13.13.1.m1.1.1" xref="A4.T8.13.13.13.1.m1.1.1.cmml"><mi id="A4.T8.13.13.13.1.m1.1.1a" xref="A4.T8.13.13.13.1.m1.1.1.cmml"></mi><mtext id="A4.T8.13.13.13.1.m1.1.1.1" mathcolor="#808080" xref="A4.T8.13.13.13.1.m1.1.1.1a.cmml">(ICCV23)</mtext></msub><annotation-xml encoding="MathML-Content" id="A4.T8.13.13.13.1.m1.1b"><apply id="A4.T8.13.13.13.1.m1.1.1.cmml" xref="A4.T8.13.13.13.1.m1.1.1"><ci id="A4.T8.13.13.13.1.m1.1.1.1a.cmml" xref="A4.T8.13.13.13.1.m1.1.1.1"><mtext id="A4.T8.13.13.13.1.m1.1.1.1.cmml" mathsize="70%" xref="A4.T8.13.13.13.1.m1.1.1.1">(ICCV23)</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T8.13.13.13.1.m1.1c">{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(ICCV23)}}}</annotation><annotation encoding="application/x-llamapun" id="A4.T8.13.13.13.1.m1.1d">start_FLOATSUBSCRIPT (ICCV23) end_FLOATSUBSCRIPT</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center" id="A4.T8.13.13.13.2" style="padding:0.75pt 8.5pt;">34.75</td>
<td class="ltx_td ltx_align_center" id="A4.T8.13.13.13.3" style="padding:0.75pt 8.5pt;">-</td>
<td class="ltx_td ltx_align_center" id="A4.T8.13.13.13.4" style="padding:0.75pt 8.5pt;">0.879</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T8.13.13.13.5" style="padding:0.75pt 8.5pt;">0.111</td>
<td class="ltx_td ltx_align_center" id="A4.T8.13.13.13.6" style="padding:0.75pt 8.5pt;">279.6</td>
</tr>
<tr class="ltx_tr" id="A4.T8.14.14.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A4.T8.14.14.14.1" style="padding:0.75pt 8.5pt;">Animate Anyone&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Hu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib21" title="">2023</a>)</cite> <math alttext="{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(CVPR24)}}}" class="ltx_Math" display="inline" id="A4.T8.14.14.14.1.m1.1"><semantics id="A4.T8.14.14.14.1.m1.1a"><msub id="A4.T8.14.14.14.1.m1.1.1" xref="A4.T8.14.14.14.1.m1.1.1.cmml"><mi id="A4.T8.14.14.14.1.m1.1.1a" xref="A4.T8.14.14.14.1.m1.1.1.cmml"></mi><mtext id="A4.T8.14.14.14.1.m1.1.1.1" mathcolor="#808080" xref="A4.T8.14.14.14.1.m1.1.1.1a.cmml">(CVPR24)</mtext></msub><annotation-xml encoding="MathML-Content" id="A4.T8.14.14.14.1.m1.1b"><apply id="A4.T8.14.14.14.1.m1.1.1.cmml" xref="A4.T8.14.14.14.1.m1.1.1"><ci id="A4.T8.14.14.14.1.m1.1.1.1a.cmml" xref="A4.T8.14.14.14.1.m1.1.1.1"><mtext id="A4.T8.14.14.14.1.m1.1.1.1.cmml" mathsize="70%" xref="A4.T8.14.14.14.1.m1.1.1.1">(CVPR24)</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T8.14.14.14.1.m1.1c">{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(CVPR24)}}}</annotation><annotation encoding="application/x-llamapun" id="A4.T8.14.14.14.1.m1.1d">start_FLOATSUBSCRIPT (CVPR24) end_FLOATSUBSCRIPT</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center" id="A4.T8.14.14.14.2" style="padding:0.75pt 8.5pt;"><span class="ltx_text ltx_font_bold" id="A4.T8.14.14.14.2.1">38.49</span></td>
<td class="ltx_td ltx_align_center" id="A4.T8.14.14.14.3" style="padding:0.75pt 8.5pt;">-</td>
<td class="ltx_td ltx_align_center" id="A4.T8.14.14.14.4" style="padding:0.75pt 8.5pt;">0.931</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T8.14.14.14.5" style="padding:0.75pt 8.5pt;">0.044</td>
<td class="ltx_td ltx_align_center" id="A4.T8.14.14.14.6" style="padding:0.75pt 8.5pt;">81.6</td>
</tr>
<tr class="ltx_tr" id="A4.T8.15.15.15">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A4.T8.15.15.15.1" style="padding:0.75pt 8.5pt;">Unianimate&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Wang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib61" title="">2024b</a>)</cite> <math alttext="{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(ArXiv24)}}}" class="ltx_Math" display="inline" id="A4.T8.15.15.15.1.m1.1"><semantics id="A4.T8.15.15.15.1.m1.1a"><msub id="A4.T8.15.15.15.1.m1.1.1" xref="A4.T8.15.15.15.1.m1.1.1.cmml"><mi id="A4.T8.15.15.15.1.m1.1.1a" xref="A4.T8.15.15.15.1.m1.1.1.cmml"></mi><mtext id="A4.T8.15.15.15.1.m1.1.1.1" mathcolor="#808080" xref="A4.T8.15.15.15.1.m1.1.1.1a.cmml">(ArXiv24)</mtext></msub><annotation-xml encoding="MathML-Content" id="A4.T8.15.15.15.1.m1.1b"><apply id="A4.T8.15.15.15.1.m1.1.1.cmml" xref="A4.T8.15.15.15.1.m1.1.1"><ci id="A4.T8.15.15.15.1.m1.1.1.1a.cmml" xref="A4.T8.15.15.15.1.m1.1.1.1"><mtext id="A4.T8.15.15.15.1.m1.1.1.1.cmml" mathsize="70%" xref="A4.T8.15.15.15.1.m1.1.1.1">(ArXiv24)</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T8.15.15.15.1.m1.1c">{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(ArXiv24)}}}</annotation><annotation encoding="application/x-llamapun" id="A4.T8.15.15.15.1.m1.1d">start_FLOATSUBSCRIPT (ArXiv24) end_FLOATSUBSCRIPT</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center" id="A4.T8.15.15.15.2" style="padding:0.75pt 8.5pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="A4.T8.15.15.15.2.1">37.92</span></td>
<td class="ltx_td ltx_align_center" id="A4.T8.15.15.15.3" style="padding:0.75pt 8.5pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="A4.T8.15.15.15.3.1">27.56</span></td>
<td class="ltx_td ltx_align_center" id="A4.T8.15.15.15.4" style="padding:0.75pt 8.5pt;"><span class="ltx_text ltx_font_bold" id="A4.T8.15.15.15.4.1">0.940</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T8.15.15.15.5" style="padding:0.75pt 8.5pt;"><span class="ltx_text ltx_font_bold" id="A4.T8.15.15.15.5.1">0.031</span></td>
<td class="ltx_td ltx_align_center" id="A4.T8.15.15.15.6" style="padding:0.75pt 8.5pt;"><span class="ltx_text ltx_font_bold" id="A4.T8.15.15.15.6.1">68.1</span></td>
</tr>
<tr class="ltx_tr" id="A4.T8.16.16.16">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A4.T8.16.16.16.1" style="padding:0.75pt 8.5pt;">MimicMotion&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Zhang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib82" title="">2024</a>)</cite> <math alttext="{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(ArXiv24)}}}" class="ltx_Math" display="inline" id="A4.T8.16.16.16.1.m1.1"><semantics id="A4.T8.16.16.16.1.m1.1a"><msub id="A4.T8.16.16.16.1.m1.1.1" xref="A4.T8.16.16.16.1.m1.1.1.cmml"><mi id="A4.T8.16.16.16.1.m1.1.1a" xref="A4.T8.16.16.16.1.m1.1.1.cmml"></mi><mtext id="A4.T8.16.16.16.1.m1.1.1.1" mathcolor="#808080" xref="A4.T8.16.16.16.1.m1.1.1.1a.cmml">(ArXiv24)</mtext></msub><annotation-xml encoding="MathML-Content" id="A4.T8.16.16.16.1.m1.1b"><apply id="A4.T8.16.16.16.1.m1.1.1.cmml" xref="A4.T8.16.16.16.1.m1.1.1"><ci id="A4.T8.16.16.16.1.m1.1.1.1a.cmml" xref="A4.T8.16.16.16.1.m1.1.1.1"><mtext id="A4.T8.16.16.16.1.m1.1.1.1.cmml" mathsize="70%" xref="A4.T8.16.16.16.1.m1.1.1.1">(ArXiv24)</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T8.16.16.16.1.m1.1c">{}_{\color[rgb]{.5,.5,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,.5,.5}%
\pgfsys@color@gray@stroke{.5}\pgfsys@color@gray@fill{.5}{\text{(ArXiv24)}}}</annotation><annotation encoding="application/x-llamapun" id="A4.T8.16.16.16.1.m1.1d">start_FLOATSUBSCRIPT (ArXiv24) end_FLOATSUBSCRIPT</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center" id="A4.T8.16.16.16.2" style="padding:0.75pt 8.5pt;">-</td>
<td class="ltx_td ltx_align_center" id="A4.T8.16.16.16.3" style="padding:0.75pt 8.5pt;">27.06</td>
<td class="ltx_td ltx_align_center" id="A4.T8.16.16.16.4" style="padding:0.75pt 8.5pt;">0.928</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T8.16.16.16.5" style="padding:0.75pt 8.5pt;">0.036</td>
<td class="ltx_td ltx_align_center" id="A4.T8.16.16.16.6" style="padding:0.75pt 8.5pt;">118.48</td>
</tr>
<tr class="ltx_tr" id="A4.T8.16.16.17.1" style="background-color:#F0F0F0;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r" id="A4.T8.16.16.17.1.1" style="padding:0.75pt 8.5pt;"><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="A4.T8.16.16.17.1.1.1" style="background-color:#F0F0F0;">Animate-X</span></th>
<td class="ltx_td ltx_align_center ltx_border_b" id="A4.T8.16.16.17.1.2" style="padding:0.75pt 8.5pt;"><span class="ltx_text" id="A4.T8.16.16.17.1.2.1" style="background-color:#F0F0F0;">36.73</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A4.T8.16.16.17.1.3" style="padding:0.75pt 8.5pt;"><span class="ltx_text ltx_font_bold" id="A4.T8.16.16.17.1.3.1" style="background-color:#F0F0F0;">27.78</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A4.T8.16.16.17.1.4" style="padding:0.75pt 8.5pt;"><span class="ltx_text ltx_font_bold" id="A4.T8.16.16.17.1.4.1" style="background-color:#F0F0F0;">0.940</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="A4.T8.16.16.17.1.5" style="padding:0.75pt 8.5pt;"><span class="ltx_text ltx_font_bold" id="A4.T8.16.16.17.1.5.1" style="background-color:#F0F0F0;">0.030</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A4.T8.16.16.17.1.6" style="padding:0.75pt 8.5pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="A4.T8.16.16.17.1.6.1" style="background-color:#F0F0F0;">79.4</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 8: </span>
Quantitative comparisons with existing methods on the Fashion dataset.
“<em class="ltx_emph ltx_font_italic" id="A4.T8.18.1">w/o Finetune</em>” represents the method without additional finetuning on the fashion dataset.
</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="A4.F14"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="609" id="A4.F14.g1" src="./animate-x_files/x13.png" width="789">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 14: </span>Visualization comparison on TikTok dataset and <math alttext="A^{2}" class="ltx_Math" display="inline" id="A4.F14.2.m1.1"><semantics id="A4.F14.2.m1.1b"><msup id="A4.F14.2.m1.1.1" xref="A4.F14.2.m1.1.1.cmml"><mi id="A4.F14.2.m1.1.1.2" xref="A4.F14.2.m1.1.1.2.cmml">A</mi><mn id="A4.F14.2.m1.1.1.3" xref="A4.F14.2.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="A4.F14.2.m1.1c"><apply id="A4.F14.2.m1.1.1.cmml" xref="A4.F14.2.m1.1.1"><csymbol cd="ambiguous" id="A4.F14.2.m1.1.1.1.cmml" xref="A4.F14.2.m1.1.1">superscript</csymbol><ci id="A4.F14.2.m1.1.1.2.cmml" xref="A4.F14.2.m1.1.1.2">𝐴</ci><cn id="A4.F14.2.m1.1.1.3.cmml" type="integer" xref="A4.F14.2.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.F14.2.m1.1d">A^{2}</annotation><annotation encoding="application/x-llamapun" id="A4.F14.2.m1.1e">italic_A start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_typewriter" id="A4.F14.4.1">Bench</span>.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="A4.F15"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="333" id="A4.F15.g1" src="./animate-x_files/x14.png" width="789">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 15: </span>Comparison with more SOTAs on <math alttext="A^{2}" class="ltx_Math" display="inline" id="A4.F15.2.m1.1"><semantics id="A4.F15.2.m1.1b"><msup id="A4.F15.2.m1.1.1" xref="A4.F15.2.m1.1.1.cmml"><mi id="A4.F15.2.m1.1.1.2" xref="A4.F15.2.m1.1.1.2.cmml">A</mi><mn id="A4.F15.2.m1.1.1.3" xref="A4.F15.2.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="A4.F15.2.m1.1c"><apply id="A4.F15.2.m1.1.1.cmml" xref="A4.F15.2.m1.1.1"><csymbol cd="ambiguous" id="A4.F15.2.m1.1.1.1.cmml" xref="A4.F15.2.m1.1.1">superscript</csymbol><ci id="A4.F15.2.m1.1.1.2.cmml" xref="A4.F15.2.m1.1.1.2">𝐴</ci><cn id="A4.F15.2.m1.1.1.3.cmml" type="integer" xref="A4.F15.2.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.F15.2.m1.1d">A^{2}</annotation><annotation encoding="application/x-llamapun" id="A4.F15.2.m1.1e">italic_A start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_typewriter" id="A4.F15.4.1">Bench</span>.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
</section>
<section class="ltx_appendix" id="A5">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix E </span>Discussion</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="A5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">E.1 </span>Limitation and Future Work</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A5.SS1.p1">
<p class="ltx_p" id="A5.SS1.p1.1">Although our method has made remarkable progress, it still has certain limitations. Firstly, its ability to model hands and faces remains insufficient, a limitation commonly faced by most current generative models. While our <span class="ltx_text ltx_font_bold" id="A5.SS1.p1.1.1">IPI</span> leverages CLIP features to extract implicit information such as motion patterns from the driving video, mitigating the reliance on potentially inaccurate hand and face detection by DWPose, there is still a gap between our results and the desired realism. Secondly, due to the multiple denoising steps in the diffusion process, even though we replace the transformer with a more efficient Mamba model for temporal modeling, <span class="ltx_text ltx_font_typewriter" id="A5.SS1.p1.1.2">Animate-X</span> still cannot achieve real-time animation. In future work, we aim to address these two limitations. Additionally, we will focus on studying interactions between the character and the surrounding environment, such as the background, as a key task to resolve.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="A5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">E.2 </span>Ethical Considerations</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A5.SS2.p1">
<p class="ltx_p" id="A5.SS2.p1.1">Our approach focuses on generating high-quality character animation videos, which can be applied in diverse fields such as gaming, virtual reality, and cinematic production. By providing body movement, our method enables animators to create more lifelike and dynamic characters. However, the potential misuse of this technology, particularly in creating misleading or harmful content on digital platforms, is a concern. While greatly progress has been made in detecting manipulated animations&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Boulkenafet et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib6" title="">2015</a>); Wang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib64" title="">2020</a>); Yu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10306v1#bib.bib73" title="">2020</a>)</cite>, challenges remain in accurately identifying increasingly sophisticated forgeries. We believe that our animation results can contribute to the development of better detection techniques, ensuring the responsible use of animation technology across different domains.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</article>
</div>

</div>


<button type="button" class="btn btn-primary hover-rp-button" id="openForm">Report Issue</button><div class="modal" id="myForm" role="dialog" aria-labelledby="modal-title"><div class="modal-dialog"><form class="modal-content" id="myFormContent" enctype="multipart/form-data"><div class="modal-header" id="modal-header"><h5 class="modal-title">Report Github Issue</h5><button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button></div><div class="modal-body"><label for="form_title" id="modalTitle">Title:</label><input class="form-control" id="form_title" name="form_title" required="required" placeholder="Enter title"><label for="description" id="selectedTextModalDescription" style="display: none;">Content selection saved. Describe the issue below:</label><label for="description" id="nomralModalDescription">Description:</label><textarea class="form-control" id="description" name="description" required="required" style="height: 80px;" maxlength="500" placeholder="500 characters maximum"></textarea></div><div class="modal-footer d-flex justify-content-end"><button type="submit" class="sr-only button" id="modal-submit-sr">Submit without Github</button><button type="submit" class="btn btn-primary" id="modal-submit">Submit in Github</button></div></form></div></div><button id="small-report-button" type="button" class="btn btn-secondary btn-sm" style="background-color: rgb(179, 27, 27); position: fixed; display: none; left: 507.098px; top: 181.5px; transform: translate(-50%, -100%);">Report Issue for Selection</button><div class="ltx_page_footer">
        <div class="ltx_page_logo">
            Generated by
            <a href="https://math.nist.gov/~BMiller/LaTeXML/" class="ltx_LaTeXML_logo">
                <span style="letter-spacing: -0.2em; margin-right: 0.1em;">
                    L
                    <span style="font-size: 70%; position: relative; bottom: 2.2pt;">A</span>
                    T
                    <span style="position: relative; bottom: -0.4ex;">E</span>
                </span>
                <span class="ltx_font_smallcaps">xml</span>
                <img alt="[LOGO]" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==">
            </a>
        </div></div><footer id="footer" class="ltx_document">
        <div class="keyboard-glossary">
            <h2>Instructions for reporting errors</h2>
            <p>We are continuing to improve HTML versions of papers, and your feedback helps enhance accessibility and mobile support. To report errors in the HTML that will help us improve conversion and rendering, choose any of the methods listed below:</p>
            <ul>
                <li>Click the "Report Issue" button.</li>
                <li>Open a report feedback form via keyboard, use "<strong>Ctrl + ?</strong>".</li>
                <li>Make a text selection and click the "Report Issue for Selection" button near your cursor.</li>
                <li class="sr-only">You can use Alt+Y to toggle on and Alt+Shift+Y to toggle off accessible reporting links at each section.</li>
            </ul>
            <p>Our team has already identified <a class="ltx_ref" href="https://github.com/arXiv/html_feedback/issues" target="_blank">the following issues</a>. We appreciate your time reviewing and reporting rendering errors we may not have found yet. Your efforts will help us improve the HTML versions for all readers, because disability should not be a barrier to accessing research. Thank you for your continued support in championing open access for all.</p>
            <p>Have a free development cycle? Help support accessibility at arXiv! Our collaborators at LaTeXML maintain a <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/wiki/Porting-LaTeX-packages-for-LaTeXML" target="_blank">list of packages that need conversion</a>, and welcome <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/issues" target="_blank">developer contributions</a>.</p>
        </div>
    </footer></body></html>